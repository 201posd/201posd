
207 PRINCIPLES OF SOFTWARE DEVELOPMENT
Alan M.Davis
University of Colorado
at Colorado Springs
McGraw-Hill, Inc.
New York San Francisco Washington, D.C. Auckland Bogota Caracas Lisbon London Madrid Mexico City Milan Montreal New Delhi San Juan Singapore
————
Sydney Tokyo Toronto
Library of Congress

Cataloging-in-Publication Data
Davis, Alan M. (Alan Mark) 201 principles of software development / Alan M. Da pcm Includes bibliographical references andindex. ISBN 0-07-015840-1 (acid-free paper) 1. Computer software—Development. I. Title. II. Title: Two hundred one principles of software development. QA76.76.D47D377 1995 005.1—<e20 94-47075 cp

Copyright © 1995 by McGraw-Hill, Inc. All rights reserved. Printed in the United States of America. Except as permitted underthe United States Copyright Act of 1976, no part of this publication may be reproducedor distributed in any form or byany means, or stored in a data base or retrieval system, without the prior written permissionofthe publisher.
67890 DOC/DOC 90098
ISBN 0-07-015840-1
The sponsoring editor for this book was Marjorie Spencer, the editing supervisor was Fred Dahl, and the production supervisor was Donald Schmidt. It was set in Palatino by Inkwell Publishing Services.
Printed

and bound by R. R. Donnelley & Sons Company.
Informationcontainedin this work has been obtained by McGraw-Hill, Inc. from sourcesbelieved to be reliable. However, neither McGraw-Hill norits authors guaranteesthe accuracy or completeness of any information published herein and neither McGraw-Hill nor its authors shall be responsible for any errors, omissions, or damages arising out of use of this information. This work is published with the understanding that McGraw-Hill andits authors are supplying informationbut are not attempting to
render engineering or other professional services. If such services are required, the assistance of an appropriate professional should be sought

This book is printed on recycled, acid-free paper containing a minimum of 50% recycled de-inkedfiber.
To onder or receive additional informationonthese or any other
Od4. Ber Sf COLA2?
aol, /
D-fz
LITE
CONTENTS
Preface xi
Acknowledgments xv
Chapter1. Introduction 3
Chapter 2. General Principles 7
Principle 1. Quality Is#1 8
Principle 2. Quality Is in the Eyes of the Beholder 9
Principle 3. Productivity and Quality Are Inseparable 10
Principle 4. High-Quality Software Is Possible 11
Principle 5. Don’t Try to Retrofit Quality 12
Principle 6. Poor Reliability Is Worse Than PoorEfficiency 13
Principle 7. Give Products to Customers Early 14
Principle 8. Communicate with Customers/Users 15
Principle 9. Align Incentives for Developer and Customer 16
Principle 10. Plan to Throw One Away 17 Principle 11. Build the Right Kind of Prototype 18 Principle 12. Build the RightFeatures into a Prototype 19
Principle 13. Build ThrowawayPrototypes Quickly 20


Principle 14. GrowSystems Incrementally 27

Principle 15.
Principle 16.
Principle 17.
Principle 18.
Principle 19.
Principle 20.
Principle 21.
Principle 22.
Principle 23.
Principle 24.
Principle 25.
Principle 26.
Principle 27.
Principle 28.
Principle 29.
Principle 30.
Principle 31.
Principle 32.
Principle 33.
Principle 34.
Principle 35.
Principle 36.
Principle 37.
The MoreSeen, the More Needed 22
Change During DevelopmentIs Inevitable 23
If Possible, Buy Instead of Build 24
Build Software So That It Needs a Short Users’ Manual
Every Complex Problem Has a Solution 26
Record Your Assumptions 27
Different Languagesfor Different Phases 28
Technique Before Tools 29
Use Tools, but Be Realistic 30
Give Software Tools to Good Engineers 31
CASETools Are Expensive 32
“Know-When”Is as Important as Know-How 33
Stop When You Achieve Your Goal 34
Know Formal Methods 35
Align Reputation With Organization 36
Follow the Lemmings With Care 37
Don’t Ignore Technology —38
Use Documentation Standards 39
Every Document Needs Glossary 40
Every Software Document Needs an Index 41
Use the Same Namefor the Same Concept 42
Research-Then-Transfer Doesn’t Work 43
Take Responsibility 44
Chapter 3. Requirements Engineering Principles 47
Principle 38.
Principle 39.
Principle 40.
Principle 41.
Principle 42.
Principle 43.
Principle 44.
Principle 45.
Poor Requirements Yield Poor Cost Estimates 48
Determine the Problem Before Writing Requirements 4
Determine the Requirements Now 50
Fix RequirementsSpecification Errors Now 51
Prototypes Reduce Risk in Selecting User Interfaces 52
Record Why Requirements Were Included 53
Identify Subsets 54


Review the Requirements 55
Principle 46.
Principle 47.
Principle 48.
Principle 49.
Principle 50.
Principle 51.
Principle 52.
Principle 53. Principle 54.
Principle 55.
Principle 56.
Principle 57.
Principle 58.
Behavior
Principle 59.
Principle 60.

Avoid Design in Requirements 56
Use the Right Techniques 57
Use Multiple Views of Requirements 58
Organize Requirements Sensibly 59
Prioritize Requirements 60
Write Concisely 61
Separately Number Every Requirement 62
Reduce Ambiguity in Requirements 63
Augment, Never Replace, Natural Language 64
Write Natural Language Before a More Formal Model
Keep the Requirements Specification Readable 66
Specify Reliability Specifically 67
Specify When EnvironmentViolates “Acceptable”
68
Self-Destruct TBDs 69
Store Requirements in a Database 70
Chapter 4, Design Principles 73
Principle 61.
Principle 62.
Principle 63.
Principle 64.
Principle 65.
Principle 66.
Principle 67.
Principle 68.
Principle 69.
Principle 70.
Principle 71.
Principle 72.
Errors
Principle 73.
Principle 74.
Transition from Requirements to Design Is Not Easy 7
Trace Design to Requirements 75
Evaluate Alternatives 76
Design Without Documentation Is Not Design 77
Encapsulate 78
Don’t Reinvent the Wheel 79
Keep ItSimple 80
Avoid NumerousSpecial Cases 81
MinimizeIntellectual Distance 82
Keep Design Under Intellectual Control 83
Maintain Conceptual Integrity 84
Conceptual Errors Are MoreSignificant Than Syntactic
85
Use Coupling and Cohesion 86

Design for Change 87
Principle 75.
Principle 76.
Principle 77.
Principle 78.
Principle 79.
Principle 80.
Design for Maintenance 88
Design for Errors 89
Build Generality into Software 90
Build Flexibility into Software 91
Use Efficient Algorithms 92
Module Specifications Provide All the Information the User
Needs and Nothing More 93
Principle 81.
Principle 82.
Principle 83.
Principle 84.
Principle 85.
Principle 86.
Design Is Multidimensional 94
Great Designs Come from Great Designers 95
Know Your Application —_-96
You Can Reuse Without a Big Investment 97
“Garbage In, Garbage Out”Is Incorrect 98
Software Reliability Can Be Achieved Through
Redundancy 99
Chapter 5. Coding Principles 101
Principle 87.
Principle 88.
Principle 89.
Principle 90.
Principle 91.
Principle 92.
Principle 93. Principle 94.
Principle 95.
Principle 96.
Principle 97.
Principle 98.
Principle 99.
Avoid Tricks 102
Avoid Global Variables 103
Write to Read Top-Down 104
Avoid Side-Effects 105
Use Meaningful Names 106
Write Programsfor People First 107
Use Optimal Data Structures 108
Get It Right Before You MakeIt Faster 109
CommentBefore You Finalize Your Code 110
DocumentBefore You Start Coding 111
Hand-Execute Every Component —112
Inspect Code 113
You Can Use Unstructured Languages m4
Principle 100. Structured Code Is Not Necessarily Good Code 115
Principle 101. Don’t Nest Too Deep 116


Principle 102. Use Appropriate Languages 17
UW

Principle 103. Programming Language Is Not an Excuse 118
Principle 104. Language Knowledge Is Not So Important 119
Principle 105. Format Your Programs 120
Principle 106. Don’t Code Too Soon 121
Chapter 6. Testing Principles 123
Principle 107. Trace Tests to Requirements 124
Principle 108. Plan Tests Long Before It Is Time to Test 125
Principle 109. Don’t Test Your Own Software 126
Principle 110. Don’t Write Your OwnTest Plans 127
Principle 111. Testing Exposes Presence of Flaws 128
Principle 112. Though Copious Errors Guarantee Worthlessness, Zer Errors Says Nothing Aboutthe Value of Software 129
Principle 113. A Successful Test Finds an Error 130
Principle 114. Half the Errors Found in 15 Percent of Modules 1:
Principle 115. Use Black-Box and White-BoxTesting 132
Principle 116. A Test Case Includes Expected Results 133
Principle 117. Test Invalid Inputs —134
Principle 118. Always Stress Test 135
Principle 119. The Big Bang Theory Does Not Apply 136
Principle 120. Use McCabe Complexity Measure 137
Principle 121. Use Effective Test Completion Measures 138
Principle 122. Achieve Effective Test Coverage 139
Principle 123. Don’t Integrate Before Unit Testing 140
Principle 124. Instrument Your Software 141
Principle 125. Analyze Causes for Errors 142
Principle 126. Don’t Take Errors Personally 143
Chapter 7. ManagementPrinciples 145
Principle 127. Good ManagementIs More Important Than Good
Technology 146

Principle 128. Use Appropriate Solutions 147
Ul
Principle

129.
Principle 130.
Principle 131
Principle 132.
People
Principle 133.
Principle 134.
Principle 135.
Principle 136.
Principle 137.
Principle 138.
Principle 139.
Principle 140.
Principle 141.
Principle 142.
Principle 143.
Principle 144.
Principle 145.
Principle 146. Principle 147.
Principle 148.
Principle 149.
Principle 150.
Principle 151.
Principle 152.
Principle 153.
Principle 154.
Principle 155.
Principle 156.
Principle 157.
Principle 158.
Principle 159.
Principle 160.
. Don’t Believe Everything You Read 148
. Understand the Customers’ Priorities 149
. People Are the Key to Success 150
. A Few Good People Are Better Than ManyLessSkilled
151
Listen to Your People 152
Trust Your People 153
Expect Excellence 154
Communication Skills Are Essential 155
Carry the Water 156
People Are Motivated by Different Things 157
Keep the Office Quiet 158
People and Time Are NotInterchangeable 159
There Are Huge Differences Among Software Engineers 160
You Can Optimize Whatever You Want 161
Collect Data Unobtrusively 162
Cost Per Line of Code Is Not Useful 163
There Is No Perfect Way to Measure Productivity 164
Tailor Cost Estimation Methods 165
Don’t Set Unrealistic Deadlines 166
Avoid the Impossible 167
KnowBefore You Count 168
Collect Productivity Data 169
Don’t Forget Team Productivity 170
LOC/PMIndependent of Language 171
Believe the Schedule 172
APrecision-Crafted Cost Estimate Is Not Foolproof 173
Reassess Schedules Regularly 174
Minor Underestimates Are Not Always Bad 175
Allocate Appropriate Resources 176
Plan a Project in Detail 177
Keep Your Plan Up-to-Date 178

Avoid Standing Waves 179
—SSaSSSSS—S—EE—E—EEEEE——————————————
Ui
$e
Principle 161.
Principle 162.
Principle 163.
Principle 164.
Principle 165.
Principle 166.
Principle 167.
Principle 168.
Principle 169.
Principle 170.
Principle 171.
Disaster
Principle 172.
Knowthe Top 10 Risks 180
Understand Risks Up Front 181
Use an Appropriate Process Model 182
The Method Won’t Save You —-183
NoSecrets for Miraculous Productivity Increases 184
Know What Progress Means 185
Manageby Variance 186
Don’t Overstrain Your Hardware 187
Be Optimistic About Hardware Evolution 188
Be Pessimistic About Software Evolution 189 The ThoughtThat Disaster Is Impossible Often Leads to
190
Doa Project Postmortem 191
Chapter 8. Product AssurancePrinciples 193
Principle 173.
Principle 174.
Principle 175.
Principle 176.
Product AssuranceIs Not a Luxury 194
Establish SCM Procedures Early 195
Adapt SCM to Software Process 196
Organize SCM to Be Independentof Project
Management 197
Principle 177.
Principle 178.
Principle 179.
Principle 180.
Principle 181.
Principle 182.
Principle 183.
Principle 184.
Rotate People Through Product Assurance 198
Give Every Intermediate Product a Name and Version —_199 Control Baselines 200
Save Everything 201
Keep Track of Every Change 202
Don’t Bypass Change Control 203
Rank and Schedule Change Requests 204
Use Validation and Verification (V&V) on Large
Developments 205
Chapter 9. Evolution Principles 207
Principle 185.
Principle 186.
Software Will Continue to Change 208
 ———
Software’s Entropy Increases 209
Ih

Principle 187. If It Ain’t Broke, Don’tFix It 210
Principle 188. Fix Problems, Not Symptoms 211
Principle 189. Change Requirements First 212
Principle 190. Prerelease Errors Yield Postrelease Errors 213
Principle 191. The Older a Program,the MoreDifficultIt Is to
Maintain 214
Principle 192. Language Affects Maintainability 215
Principle 193. SometimesItIs Better to Start Over 216
Principle 194. Renovate the WorstFirst 217
Principle 195. Maintenance Causes More Errors Than Development
Principle 196. Regression Test After Every Change 219
Principle 197. Belief That a ChangeIs Easy MakesIt Likely It Will Be
MadeIncorrectly 220
Principle 198. Structuring Unstructured Code Does Not Necessarily
Improve It 221
Principle 199. Use Profiler Before Optimizing 222
Principle 200. Conserve Familiarity 223
Principle 201. The System’s Existence Promotes Evolution 224
References Index
=
225
Subject Index 235
 

PREFACE
If software engineeringis really an engineering discipline,it is the intelli- gent application of provenprinciples, techniques, languages, and tools to the cost-effective creation and maintenanceof softwarethatsatisfies users’ needs. This bookis the first collection of software engineering principles
ever written in one volume.* Aprincipleis a basic truth, rule, or assumption aboutsoftware engineering that holds regardless of the technique,tool, or language selected. With few exceptions, the principles published here are not original. They have been extracted from the writings of many software engineering practitioners and researchers. These individuals have been unselfish enough to share their experiences, ideas, and wisdom withall of us. I make noclaim that these 201 principles are mutually exclusive. Unlike Boehm’s seven “basic” software engineering principles, a combination of someof these principles may imply another. I also make no claim that these 201 principles are 100 percent compatible. The adages, “Absence makesthe heart grow fonder” and “Outofsight, out of mind”are each true, and each can be appliedto life, but they cannotboth be usedto justify the samedeci- sion. The principles contained in this volumeareall valid, and they can all be used to improvesoftware engineering, but it may be impossible to apply
some combinations of them on anyoneproject.
*Winston Royce and Barry Boehm published the first two papers onsoftware engineering

principles with five and sevenprinciples, respectively [ROY70, BOE83].
————————S=
Hl

Manny Lehman [LEH80] hasstated eloquently why principles underlying software engineering are inherently different from principles underlying other areas of human exploration. He states there is no reason to
expect such principles to have the same “precision and predictability of
[say] the lawsof physics.” The reasonforthisis that, unlike physicsor biology, the process of software developmentis “managed and implemented
by people; thus in the long term [its behavior should] be expected to be
unpredictable, dependent on the judgments, whims, and actions of [people].” On the other hand, software does seem to exhibit many regular and
predictable traits [LEH80]. These lead to manybasic principles that can be
enumerated and used by inexperienced and experienced software engineers and managers to enhancethe quality of both the software engineering process and software products.
Thepurpose ofthis bookis to presentin one volumetheprinciples of software engineeringasa reference guide. It is aimedatthreeclasses of readers:
1. Software engineers and managers. In this book you can find out whatis
good and whatis not. If you are newatsoftware engineering or software
management, hereis a place to find out what you need to know.
2. Students of software engineering. For students, there are two primary uses of
this book.First, here are the basic, nondogmatic tenets that every software
engineer should know. Second,the references in these pages point to some
of the best papers and booksever written on software engineering.If you
do nothing otherthan read theitemsreferenced,this book will have been
successful, and you will have been exposed to a wealth of knowledge.
3. Software researchers. Researchers mayoften find it difficult to find the
original sourceof an idea. I have provided referencesto publications that
reflect either the original source or an alternative, excellent work that
refers to the original source.
Isincerely hope that everybody who buysthis book attemptsto read as
manyofthe referenced worksas possible. Mybrief description of the principleis intendedto befriendly, easy-to-read, and insightful. But for real appre-

ciation you need to read the referenced works. These works are not neces-
————————————_—_—_—_—————————————_—_—
il


Chapter2: General Software Engineering
Chapter 7: Management
Chapter 3: Requirements|_gyp- Chapter 4: [3] Chapter 5: [| Chapter 6: || Chapter9: Engineering || Design FET Coding FOF] Testing
["
Fr Evolution
Chapter8: Product Assurance


Figure P-1. Organizationof the book.
sarily the original source of the idea (although in manycasestheyare). Nor
is the given principle necessarily a primarypointofthe reference. In every
case, however, the referenced work contains a wealth of helpful background,
insight,justification, backup data, or information related to the principle. In summary,this book shouldbethefirst place for you to look up any
software engineering idea. However, this is a book of principles, not tech- niques, languages, or tools. You will not find out howto use any tech- niques, languages, or tools which the principles described here transcend. Furthermore, this booktries to avoid all fads, good or bad! For the most part, fads are popularfor three to ten years, then lose favor. The underly- ing principles that might be behind a fad can be foundin this volume, but
notthefaditself. Thus, for example, you won't see any reference to object- orientation per se here, but youwill find many referencesto the principles
underlying object-orientation, such as encapsulation.
Theprinciples are organized into general categoriesto aid in finding
them andtoaid in relating similar principles. These categories correspond to primary phases of software development(thatis, requirements, design,
etc.) and to other critical “support”activities, such as management, product assurance, and so on, as shownin Fig. P-1.


Alan M. Davis
all

REFERENCES
[BOE83] Boehm,B., “SevenBasic Principles of Software Engineering,” Journal of Systenis
and Software, 3, 1 (March 1983), pp. 3-24.
[LEH80] Lehman, M., “On Understanding Laws, Evolution, and Conservation in the Large-Program Life Cycle,” Journal of Systems and Software, 1, 3 July 1980), pp. 213-221.
[ROY70] Royce, W., “Managing the Development of Large Software Systems,” WESCON ‘70, 1970; reprinted in 9th International Conference on Software
Engineering, Washington, D.C.: IEEE ComputerSociety Press, 1987, pp. 328-338.

i

ACHNOWLEDGMENTS
Stephen Andriole of Drexel University unknowingly inspired me to write this book duringa class we werecoteaching.I had just mentionedthatsoft- ware engineering, like all engineering disciplines, is driven by a set of underlying principles. My statement seemed quite logical. However, Steve challenged me: “Name one,Al. Just name one!” Luckily I think well on my
feet and came up with one. Hesaid, “Okay, namejust one more, andI’il
believe that there really are software engineering principles.” I thought of
another, and another.
Kerry Baugh wasresponsiblefor creating and maintaining the physi- cal quality of the manuscript. Steve Andriole, Manny Lehman, and Jawed Siddiqi madecontributions by reviewing early versions of the manuscript.
Dr. Siddiqi was instrumental in providing advice on howto organize the principles.
Last, but notleast, I want to thank my wife, Ginny, our children,
Marsha and Michael, and my parents, Barney and Hannah Davis,forall
their love and support and willingness to live without husband,father, or

son while | spent hours writing.
W
 
261 PRINCIPLES OF SOFTWARE DEVELOPMENT
 

INTRODUCTION
This bookcontainsa collection of principles of software engineering. These
principles representthe state-of-the-art of whatwebelieveis “right” when
engineering software. Other engineering disciplines have principles based
on the laws of physics, or biology, or chemistry, or mathematics. Because
the productof software engineering is nonphysical, the laws of the physical do noteasily form a solid foundation.
The software industry has been flooded by hundreds of books that
discuss techniques, languages, and tools. Nonehasattempted to compile
the list of underlying principles. As shownin Fig. 1-1, principles are the rules
to live by; they represent the collected wisdom of many dozensof people
whohavelearned through experience. They tend to be stated as absolute
truths (this is always true) or as inferences (when X occurs, Y will occur).
Techniques are step-by-step proceduresthat aid a software developer
in performinga part of the software engineering process. Techniques tend
to enforce a subset of the underlying principles. Most techniques create either documents and/or programs. Manytechniques also analyzeexisting
documents and/or programs, or they transform existing documents
and/or programsinto the products.
Languages consist of a set of primitive elements (such as words or
graphical symbols) anda set of rules by which one can construct more

complex entities (such as sentences, diagrams, models) from those primi-

Supported by
Languages
Supported by
Use
Techniques Enforced By


Enforced By
Principles

Figure 1-1. Principles, techniques, languages,tools.
tive elements, as well as semantics that endoweach combinationofentities
with meaning. Languagesare used to expressall products of software engineering, whether intermediate orfinal. The documents and programscre- ated or analyzed by techniquesare typically represented in somelanguage.
Tools are software programsthat assist a software engineer in per- forming somestep of software engineering. They may:
= Serve in an advisory capacity to the engineer(like the Knowledge-Based
RequirementsAssistant).
= Analyze something for conformity to a technique(a data-flow diagram checker, for example) or a subsetof principles.
= Automate someaspectof software engineering (such as any compiler).

aan
= Aid the engineer in doing some aspectof the job (as an editor).
4
The set of principles for a discipline evolve as the discipline grows.
Existing principles are modified. New ones are added. Old onesare discarded.It is the practice and experience gained through that practice that
cause us to evolve those principles. If we were to examine the set of software engineering principles from 1964 they would look downrightsilly
today (for example, always use short variable names, or do whateverit
takes to make your program smaller). Today’s principles will look equally
silly in thirty years.
And now,today’s principles of software engineering.
 
 
) GENERAL PRINCIPLES

PRINCIPLE 1
QUALITY 1S #1
Acustomerwill not tolerate a product with poorquality, regardless of the definition of quality. Quality must be quantified and mechanisms put into place to motivate and rewardits achievement.It may seem politically correct to deliver a product on time, even thoughits quality is poor, but it is
politically correct in the short term only;it is political suicide in the middle
and long term. Thereis no trade-off to be made. Thefirst requirement must be quality. Edward Yourdon suggests that you “Just say no” whenyou're
askedto speed uptesting, ignore a few bugs, or code before agreeing on a
design or a set of requirements.
Ref: Yourdon, E., Decline and Fall of the American Programmer, Englewood Cliffs, N.J.


Prentice Hall, 1992 (Chapter 8).

PRINCIPLE 2
QUALITY 15 IN THE EYES OF THE BEHOLDER
There is no one definition of software quality. To developers,it might be an
elegantdesign or elegant code. To users who workin stress environments,
it might be response time or high capacity. For cost-sensitive projects, it
mightbe low developmentcost. For some customers,it mightbesatisfying
all their perceived and not-yet-perceived needs. The dilemmais that these
maynotbeall compatible. Optimizing one person’s quality mightbe detrimental to another’s. (This is Weinberg’s “Political Dilemma”principle.) A
project must decideonits priorities and articulate them to all parties.
Ref: Weinberg, G., Quality Software Management, Vol. 1: Systems Thinking, New York:
ee

Dorset House, 1992, Section 1.2.
J

PRINCIDLE 3
PRODUCTIVITY AND QUALITY ARE INSEDARABLE
Thereis a clearrelationship between productivity (measured by numbers of widgits—whether they belines of code or function points—per person- month)and quality. The higher the demandfor quality, the lower yourproductivity becomes. The lower the demandfor quality, the higher your pro- ductivity becomes. The more you emphasize increased productivity, the loweryourresulting quality. Bell Labs has foundthat, to achieve oneto two
bugsper thousandlines of code, productivities of 150 to 300 lines of code
per person-month are common[see Fleckenstein, W., “Challenges in Software Development,” IEEE Computer, 16, 3 (March 1983), pp. 60-64]. As attempts are madeto drive productivity up, the density of bugs increases.
Ref: Lehman, M., “Programming Productivity—A Life Cycle Concept,” COMPCON81,

Sea
Washington, D.C.: IEEE ComputerSociety Press, 1981, Section 1.1.
i

PRINCIPLE 4
HIGH-QUALITY SOFTWARE /S POSSIBLE
Althoughourindustryis saturated with examples of software systems that
perform poorly, that are full of bugs,or that otherwisefail to satisfy users’
needs, there are counter examples. Large-scale software systems can be
built with very high quality, but for a steep price tag: on the order of $1000
perline of code. One such exampleis IBM’s on-boardflight software for
NASA‘sspace shuttle. Totaling approximatelythree million lines of code,
the rigorous software developmentprocessresulted in less than one error found perten thousandlines of code after product release.
As a developer, be aware of the techniques that have been demonstrated to increase quality considerably. These include involving the customer(Principle 8), prototyping (to verify requirements prior tofull-scale
development; Principles 11 through 13), keeping the design simple
(Principle 67), inspections (Principle 98), and hiring the best people
(Principles 130 and 131). As a customer, demandexcellence but be aware of the highcosts involved.

Ref: Joyce, E., “Is Error-Free Software Achievable?” Datamation (February 15, 1989).
1

PRINCIPLE 5
DON'T TRY TO RETROFIT QUALITY
Quality cannot beretrofit into software. This applies to any definition of quality: maintainability, reliability, adaptability, testability, safety, and so
on. We have a verydifficult time building quality into software during
development whenwetry to. How can wepossibly expect to achieve quality when we don’t try? This is primarily why you mustnottry to convert a
throwawayprototypeinto a product (Principle 11).
Ref: Floyd, C., “A Systematic Lookat Prototyping,” in Approaches to Prototyping, R.

Budde,et al., Berlin, Germany:SpringerVerlag, 1983, pp. 1-18, Section 3.1.
0

PRINCIPLE 6
DOOR RELIABILITY 15 WORSE THAN POOR EFFICIENCY
Whensoftware is notefficient, it is generally possible toisolate the sections
of the program that consume mostofthe execution time and redesign or
recode them for increased efficiency (Principle 194). Poorreliability is not
only moredifficult to detect,it is also more difficult to fix. Asystem’s poor reliability may not become apparent until years after the system is
deployed—andit kills somebody. Once the poorreliability manifestsitself,
it is often difficultto isolate its cause.
Ref: Sommerville, 1., Software Engineering, Reading, Mass.: Addison-Wesley, 1992,
SS

Section 20.0.
B

PRINCIPLE 7
IVE PRODUCTS 10 CUSTOMERS EARLY
Nomatter how hardyoutryto learn users’ needs during the requirements
phase, the mosteffective meansto ascertain their real needs is to give them a productandlet them play withit. If you follow a conventionalinterpretation of the waterfall model,the first delivery of a product to the customer occurs after 99 percent of the developmentresources are already expend- ed. Thus, the majority of customer feedbackon their needs occurs after the resources are expended.
Contrastthat with an approach, for example, of constructing a quick and dirty prototype early in the developmentprocess. Deliver this to the customer, gather feedback, and then write a requirements specification and
proceedwitha full-scale development.In this scenario, only 5 to 20 percent of the developmentresources are expendedby the time customers experiencetheirfirst product.If the appropriate features were built into the pro- totype, the highest-risk user needs will becomebetter known andthefinal product is more likely to be user-satisfactory. This helps ensure that the remainderof the resources are spent building the right system.
Ref: Gomaa, H., and D.Scott, “Prototyping as a Tool in the Specification of User Requirements,” Fifth International Conference on Software Engineering, Washington,

eee
D.C.: IEEE ComputerSociety Press, 1981, pp. 333-342.
4
RINCOL

8
COMMUNICATE WITH CUSTOMERS /USERS
Neverlose sightof whysoftwareis being developed: to satisfy real needs,
to solve real problems. The only wayto solve real needsis to communicate
with those whohave the needs. The customeroruseris the most important
person involved with your project.
If you are a commercial developer, talk often with the clients. Keep
them involved. Sure,it is easier to develop software in a vacuum,but will
the customerlike the result? If you’re a producer of shrinkwrapsoftware, “customers” are harder to locate during development. So role-play.
Designate three or four individuals in your organization as prospective customers and tap them for ideas that will keep them as customers or make
them happy.If you’re a governmentcontractor, talk often with the contracting officers, their technical representatives, and, if possible, the users. People and situations change often in the government. The only way to
keep up with the change is communication. Ignoring the changes may make
life seem easier in the short term, but the final system will not be useful.

Ref: Farbman,D., “Myths That Miss,” Datamation (November1980), pp. 109-112.
———————————
5

PRINCIPLE 9
ALIGN INCENTIVES FOR DEVELODER AND CUSTOMER
Projects often fail because customers and developers havedifferent (and
perhaps incompatible) goals. For example, take the simple case in which
the customer wantsfeatures 1, 2, and 3 by a specific date and the developer wants to maximize revenueorprofit. To maximize revenue, the developer mayattemptto build all three features in their entirety eveniflate.
Meanwhile, the customer may havepreferred to be missing part of one of
the featuresif only it could have the others on time.
To help align the two organizations’ goals: (1) Prioritize requirements
(Principle 50) so that developers understandtheir relative importance,(2) reward the developer based ontherelative priorities (for example,all highpriority requirements mustbesatisfied, each mediumpriority requirement
earns the developera small additional bonus of some kind, and each low
priority requirementsatisfied earns a very small bonus), and(3)usestrict
penalties for late delivery.

i

PRINCIPLE 10
PLAN TO THROW ONE AWAY
Oneof the most importantcritical success factors for a project is whetherit is entirely new. Programsthat tread on brand new territory (whetherit be with respect to application, architecture, interface, or algorithm) rarely workthefirst time. Fred Brooks,in his Mythical Man Month, makesthis per- fectly clear with his advice, “Plan to throw one away;you will anyway.” This advice wasoriginally presented by Winston Royce in 1970, when he said one should planforthefirst fully deployed system to be the second one created.Thefirst should at least check out the critical design issues and the operational concept. Furthermore, Royce recommended that such a
prerelease version should be developed with approximately 25 percentof the total system developmentresources. As a developer of a new custom product, plan to build a series of throwawayprototypes(Principles 11, 12, and 13) before embarking on the full-scale product development. As a commercial high-volume developer,
expectthat yourfirst productversion will be able to be modified for a cer- tain period of years, after which it will need to be fully replaced (related Principles 185, 186, 188, and 201). As a maintainer of a product, be aware that you can fiddle with the program just so muchbefore it becomes unstable and mustbe replaced (see related Principles 186, 191, 195, and 197).
Ref: Royce, W., “Managing the Developmentof Large Software Systems,” WESCON ‘70, 1970; reprinted in 9th International Conference on Software Engineering,

Washington, D.C.: IEEE ComputerSociety Press, 1987, pp. 328-338.
V

PRINCIDLE TI
BUILD THE RIGHT RIND OF PROTOTYPE
There are two types of prototypes: throwaway and evolutionary.
Throwaway prototypesare built in a quick and dirty manner, are given to
the customerfor feedback, and are thrown awayoncethe desired information is learned. The desired informationis captured in a requirements specification for a full-scale product development. Evolutionary prototypes are
built in a quality manner, are given to the customer for feedback, and are
modified once the desired informationis learned to moreclosely approximate the needsofthe users. This process is repeated until the product convergesto the desired product.
Throwawayprototypes should be built when critical features are
poorly understood. Evolutionary prototypes should be built whenthe critical functions are well understood but many other features are poorly
understood. Build a throwaway prototype followed by a “from-scratch”
evolutionary prototype if most functions are poorly understood.
Ref: Davis, A., “Operational Prototyping: A New Development Approach,” IEEE

Software, 9, 5 (September1992), pp. 70-78.

i

PRINCIPLE 12
BUILD THE RIGHT FEATURES INTO A DROTOTYDE
Whenconstructing a throwawayprototype,build only features that are
poorly understood. After all, if you build well understood features, you
will learn nothing, and youwill have wasted resources. Whenconstructing an evolutionary prototype (Principle 13), build the features that are best
understood. (Note that these may have become“best understood” because they wereverified previously using throwawayprototypes.) Your hopeis
that, by experiencing these features, users will be able to better determine
additional needs.If you build a poorly understood requirement(in a quality fashion) into an evolutionary prototype, you may be wrong, you will
have to discard “quality” software, and you will have wasted resources.
Ref: Davis, A., “Operational Prototyping: A New Development Approach,” IEEE


Software, 9, 5 (September 1992), pp. 70-78.
0

PRINCIPLE 13
BUILD THROWAWAY PROTOTYPES QUICKLY
If you've decided to build a throwawayprototype, build it as quickly as you can. Don’t worry aboutquality. Use a one-page requirements specifi- cation. Don’t worry about design or code documentation. Use any available tool. Use any language that facilitates the quick developmentofsoftware applicable to your application. Do not worry about the inherent
maintainability of the language.

Ref: Andriole, S., Rapid Application Prototyping, Wellesley, Mass.: QED,1992.
0

PRINCIPLE T1
GROW SYSTEMS INCREMENTALLY
Oneof the mosteffective techniquesto reducerisk in building softwareis to grow it incrementally. Start small, with a working system that imple- ments only a few functions. Then growitto coverlarger and larger subsets
of the eventual functionality. The advantages are (1) lower risk with each build, and (2) seeing a version of the product often helps users envision other functions they would like. The disadvantageis that, if an inappropriate architecture is selected early, a complete redesign may be necessary to accommodate later changes. Reducethis risk by building throwaway
prototypes (Principles 11, 12, and 13) prior to starting the incremental
development.
Ref: Mills, H., “Top-Down Programmingin Large Systems,” in Debugging Techniques in

_—
Large Systems, R. Ruskin, ed., EnglewoodCliffs, N.J.: Prentice Hall, 1971.
1

PRINCIPLE 15
THE MORE SEEN, THE MORE NEEDED
It has been witnessed over and over again in the software industry: The
more functionality (or performance) that is provided to a user, the more functionality (or performance)that the user will want. This, of course, supports Principles 7 (Give Products to Customers Early), 14 (Grow
Incrementally), 185 (Software Will Continue to Change), and 201 (System’s
Existence Promotes Evolution). But more importantly, you must prepare
yourself for the inevitable. Every aspect of both management and engineering processes should be awarethat, as soon as the customerssee the
product, they will want more.
This means that every document produced should be stored and
organized in a fashion conducivefor change.It means configuration managementprocedures(Principle 174) mustbein place long before delivery.
It means you should be prepared for an onslaught of oral or written
requests from users soon after deployment. It means that your design should beselected so that capacities, rates of inputs, and functionality can
all be changedeasily.
Ref: Curtis, B., H. Krasner, and N. Iscoe, “A Field Study of the Software Design Process for Large Systems,” Communicationsofthe ACM,31, 11 (November1988),

pp. 1268-1287.
2

PRINCIPLE 16
CHANGE DURING DEVELOPMENT 15 INEVITABLE
Edward Bersoffet al. define the first law of system engineering as, “No matter where you are in the system [development]life cycle, the system will change, and the desire to changeit will persist throughout the life cycle.” Unlike Principles 185 and 201, which emphasize that software requirements will change dramatically once deployed, this principle says software will change dramatically during development. These changes may reflect writing new code, newtest plans, or new requirements specifica tions. They may mean makingrepairs to an intermediate productthat has been found to be incorrect. Or they can reflect the natural process of per- fecting or improving the product.
To prepare yourself for these changes, be sure that all products of a
software development are appropriately cross-referenced to each other (Principles 43, 62, and 107), that change managementproceduresare in place (Principles 174 and 178 through 183), and that budgets and schedules have enough leeway so that you are not tempted to ignore necessary changesjust to meet budgets and schedules (Principles 147, 148, and 160).
Ref: Bersoff, E., V. Henderson, and S. Siegel, Software Configuration Management,

EnglewoodCliffs, N.J.: Prentice Hall, 1980, Section 2.2.
————————
B

PRINCIDLE 17
IF POSSIBLE, BUY INSTEAD OF BUILD
Thesingle mosteffective technique to reduce escalating software developmentcosts and risk is to buy software off the shelf instead of building it
from scratch. It is true that off-the-shelf software may solve only 75 percent
of your problems. But considerthe alternative: Pay at least ten times as
much,taketherisk that the software is 100 percent over budgetandlate(if
finished at all!), and, whenitis all done, accept thatit still may meet only
75 percent of your expectations.
As a consumer, new software development projects always seem
exciting at first. The team is “optimistic,” full of hope for the “ultimate”
solution. Few software development projects run smoothly. Escalating
costs usually cause requirements to be scaled back,resulting in a system
that maysatisfy just as many needs asan off-the-shelf system could have.
As a developer, you should reuse as muchsoftware as possible. Reuseis
“buying instead of building” ona less grandscale.See related Principle 84.
Ref: Brooks, F, “No Silver Bullet: Essence and Accidents of Software Engineering,”

IEEE Computer, 20, 4 (April 1987), pp. 10-19.
———————
h

PRINCIPLE 18
BUILD SOFTWARE SO THAT IT NEEDS A SHORT USERS” MANUAL
One wayto measurethe quality of a software system is to lookatthe size of its users’ manual. The shorter the manual,the better the softwareis. The use of well-designed software should be mostly self-evident. Unfortunately, too many software designers fashion themselves as experts in humaninterface design as well. The voluminous manualsthatresult are sufficient evidence that mostinterface designers are not as great as they proclaim themselves to be. (By the way, when I say “users’ manual” I
include on-line help text. Thus, software does not suddenly becomebetter overnightby putting the users’ manualon-line.)
Use standard interfaces. Use industry experts to design self-evident
icons, commands, protocols, and user scenarios. And remember: Just because software developers “like” an interface, it doesn’t mean that your customerswill have any idea of how to use it. Many software developers
like interfaces with built-in tricks that serve as short-cuts. Usually, cus- tomers wantsimple, clean,clear interfaces—nottricks.
Ref: Hoare, C.A.R., “Programming: Sorcery or Science?” IEEE Software, 1, 2 (April

an
1984), pp. 14-15.
5

PRINCIPLE 19
EVERY COMPLEX PROBLEM HAS A SOLUTION
Wlad Turski said, “To every complex problem,thereis a simple solution...
andit is wrong!” Be highly suspicious of anybody who offers you something like, “Just follow these 10 simple steps and your software quality
problemswill disappear.”

Ref: Turski, W., oral comments madeata conferencein thelate 1970s.
ry

PRINCIPLE 20
RECORD YOUR ASSUMPTIONS
The environments weplace systemsinto are by their very nature infinite and impossibleto fully comprehend. Whenwebuild a system,allegedly to solve a problem in that environment we make assumptions aboutthe envi- ronment. Manny Lehman hypothesizesthat “we make approximately one assumption every 10 lines of code, or evenif I’m off by a factor of 2 or 3, one assumption every 20 to 30 lines of code.” These finite assumptions aboutaninfinite world can get you into trouble. Lehmandescribesa linear accelerator that was not behaving as expected. One physicist suggested that perhapsthe phasesof the moon were havinganeffect, to which every- body responded,“You have gotto be kidding!” However, after factoring in the moon, the resulting equations accounted for a large majority of the seemingly “incorrect” behavior. This is an example of an assumption that was made(that there were no lunar effects) that was invalid.
It is impossible to be consciousofall the assumptions you make dur- ing requirements engineering, design, coding, and testing. Nonetheless,I
recommend you maintain a diary of assumptions that you make con- sciously. Do this evenif the assumption seemsobviousorif the alternatives seem preposterous. Also record their implications, that is, where in the product does the assumption manifestitself? Ideally, you wouldlike to iso- late such implications by encapsulating each assumption (Principle 65).
Ref: Lehman, M., “Software Engineering, the Software Process and Their Support,”
eee
Software Engineering Journal, 6, 5 (September 1991), pp. 243-258, Section 3.6.
q

PRINCIPLE 21
DIFFERENT LANGUAGES FOR DIFFERENT DHASES
The industry’s eternal thirst for simple solutions to complex problems
(Principle 19) drives manyto declare that the best software development
method would usethe same notations for software representation throughout the entire developmentlife cycle. Since this is not the case in any other
engineeringdiscipline, why shouldit be in software engineering?Electrical
engineers use different notations for different design activities: block dia- grams, circuit diagrams, logic diagrams,timing diagrams, state transition
tables, stick diagrams, and so on. Notations provide us with models that
can be manipulated in our minds. The morenotations and the richer and
more diverse the representations used, the better we can visualize the
productunderconstruction. Why would software engineers wantto use,
say, Ada for requirements, design, and codeunlessit were optimalforall?
Whywould they wantto use, say, object-orientation for all phases unlessit
wereoptimalforall?
For requirements engineering,select a set of optimal techniques and
languages(Principles 47 and 48). For design, select a set of optimal techniques and languages(Principles 63 and 81). For coding,select an optimal
language (Principles 102 and 103). Transitions between phasesare difficult.
Using the samelanguagedoesn’t help. On the other hand,if a languageis
optimalfor certain aspects of two phases, by all meansuseit.
Ref: Matsubara, T,, “Bringing upSoftware Designers,” American Programmer, 3, 7 (July-
—
August 1990), pp. 15-18.
B

PRINCIDLE 22
TECHNIQUE BEFORE TOOLS
An undisciplined carpenter with a powertool becomes a dangerous undis- ciplined carpenter. An undisciplined software engineer with a tool becomes a dangerous undisciplined software engineer. Before you use a
tool, you should havediscipline (that is, understand and beable to follow an appropriate software technique). Of course, you also need to know how to use the tool, but that is secondary to having good discipline. I strongly recommendfollowing a technique by hand and convincing yourself and your managementthatthe technique worksbefore investing in tools to “automate” the technique. In mostcases, if a technique doesn’t
work without automation,it won’t work with automation.
Ref: Kemerer, C,, “Howthe Learning Curve Affects Tool Adoption,” IEEE Software, 9,3
eee
(May 1992), pp. 23-28.

y
PRINCIPLE

23
USE TOOLS, BUT BE REALISTIC
Software tools (such as CASE) make their users moreefficient. By all
means,use them. Just as a word processoris an essential aid to an author,
a CASEtoolis an essential aid to a software engineer. Each enhancesits
users’ initial productivity by 10 to 20 percent. Each enhancesits users’ ability to modify and evolve their product by 25 to 50 percent, but in both cases
the hard work(thinking) is not done by the tool. Use CASEbutberealistic concerningits effect on productivity. Be aware that 70 percent of all CASE
tools purchased are never used.I believe the primary reasonforthis is
overoptimism andthe resulting disappointment, rather than theineffectiveness ofthe tools.
Ref: Kemerer, C., “How the Learning Curve Affects Tool Adoption,” IEEE Software, 9,3

(May 1992), pp. 23-28.
————————
0

PRINCIPLE 24
IVE SOFTWARE TOOLS TO GOOD ENGINEERS
Users of software tools (such as CASE) become more productive just as
writers become more productive using word processors (Principle 23).
However,just as a word processorcannot convert a poornovelist (one that
writes novels that don’t sell) into a good one, a CASEtool cannot convert a poor software engineer (one that produces software that is unreliable, fails to satisfy user needs, and so on) into a good one. Thus, you want to give CASEtools only to the good engineers. Thelast thing you wantto do is to provide CASEtools to the poor engineers: You want them to produce
less, not more, poor-quality software.

i

PRINCIDLE 25
CASE TOOLS ARE EXPENSIVE
Workstationsor high-end personal computersto host a CASE environment
cost between $5000 and $15,000 per seat. CASE tools themselves range
from $500 to $50,000 per copy. The annual licensing and maintenancefees
for tools generally cost 10 to 15 percentof their purchaseprice. Also, expect
to pay salaries for twoto three days for each employeeto betrained. Thus,
total expected set-up costs can exceed $17,000 per seat (for a moderately
priced CASEtool) and recurring annualcosts can exceed $3000 perseat.
CASEtools are essential for software development. They should be
consideredpartof the costof being in the business. When doing a payback
analysis, take into consideration the high costs of buying the tools, but also
take into accountthe highercosts of not buying the tools (lower productivity, higher probability of customerdissatisfaction, delayed productrelease,
increased rework, poorer productquality, increased employee turnover).
Ref: Huff, C., “Elements of a Realistic CASE Tool Adoption Budget,” Communications of


the ACM, 35, 4 (April 1992), pp. 45-54.
5H

DRINCIDLE 26
“KNOW-WHEN" 1S AS IMPORTANT AS RNOW-HOW
All too often in our industry, a software engineer learns a new technique
and decides that it is the be-all and end-all of techniques. Meanwhile,
anothersoftware engineer on the sameteam learns a different new technique and an emotionalbattle ensues. Thefactis that neither engineer is right. Knowing how to use a technique well does not makeit a good technique,nor doesit make you a good engineer. Knowing howto use a wood
lathe well does not make you a good carpenter. The good engineer knows
dozensof diverse techniques well and knows wheneachis appropriate for
a project or a segmentofa project. The good carpenter knows howto use
dozensoftools, knowslots of diverse techniques, and, most importantly,
knows when to employ each.
When doing requirements engineering, understand which techniques
are most useful for which aspects of your problem (Principle 47). When
doing design, understand which techniques are most useful for which
aspects of your system (Principle 63). When coding, pick the most appropriate language(Principle 102).

3

PRINCIDLE 27
STOD WHEN YOU ACHIEVE YOUR GOAL
Softwareengineersfollow many dozensof methods(alsocalled techniques or procedures). Each of these has a purpose, usually corresponding to a
subgoalof software development. For example, structured (or object-ori- ented) analysis has the goal of understanding the problem beingsolved, DARTShasthegoalof a processarchitecture, and structured design has the goal ofa calling hierarchy. In each case the methodconsists ofa series of steps. Do not beso takenin by the methodthat you forget your goal. Don’t be guilty of goals displacement.If, for example, you understand your prob- lem after doing only half the steps of a method, stop. On the other hand, you need to have a good view of theentire software process becausea later step of a method that appears discardable by this principle may generate somethingcritical for later use.

4
PRINCIPLE

28
ANOW FORMAL METHODS
Formal methodsare not easy withoutstrong discrete mathematicalskills.
On the other hand,their use (even on the back of an envelope)can aid significantly in uncovering problems in manyaspects of software development.Atleast one person on every project should be comfortable with formal methods to ensure that opportunities for building quality into the
productarenotlost.
Manypeople think that the only way to use formal methods is to
specify a system completely using them.Thisis nottrue. In fact, one of the
mosteffective methodsis to write a natural language specification first.
Then attempt to write parts using formal methods.Just trying to write
things more formally will help you find problemsin the natural language.
Fix the natural language and you nowhavea better document. Discard the
formalism if desired after it has helped you.
Ref: Hall, A., “Seven Mythsof Formal Methods,” IEEE Software, 7, 5 (September 1990),

————
pp. 11-19,
3

DRINCIDLE 29
ALIGN REPUTATION WITH ORGANIZATION
It is generally recognized that Japanese software engineers view software bugsdifferently than American software engineers. Although manyfactors
influence this, onerelates to the perception in Japan that an error ina prod- uctis a disgrace to the company,anda disgrace to the company caused by a software engineeris a disgrace to the engineer. This works moreeffectively in Japan than in the United States because Japanese workerstend to remain in one companyfortheir entire careers. The mind-set, however, is importantregardless of employmentlongevity.
In general, when anybody finds an error in a software engineer’s product, that engineer should be thankful, not defensive. To err is human.
To accept, divine! When an engineeringerror is found, the person causing
it should broadcastit, not hide it. The broadcasting has two effects: (1) It helps other engineers avoid the sameerror, and (2) it sets the stage for future nondefensiveerror repair.
Ref: Mizuno,Y., “Software Quality Improvement,” IEEE Computer, 16, 3 (March 1983),

pp. 66-72.
————————————
4

PRINCIDLE 30
FOLLOW THE LEMMINGS WITH CARE
If 50 million people say a foolish thing, it is still a
foolish thing.
Anatole France
Just because everybodyis doing something does not makeit right for you. It may be right, but you need to carefully assess its applicability to your
environment. Some examples are object-orientation, software measurement(Principles 142, 143, 149, 150, and 151), software reuse (Principle 84),
process maturity (Principle 163), computer-aided software engineering (CASE,Principles 22 through 25), and prototyping(Principles 11, 12, 13, and 42). In all cases, these offer very positive opportunities for increased quality, decreased cost, or increasedusersatisfaction. However, the advan- tages are available only to those organizations in which it makessense.
Although the rewardsaresignificant, their potentials are often oversold
and are by no meansguaranteed or universal.
Whenyoulearn about a “new”technology, don’t readily accept the inevitable hypeassociated withit (Principle 129). Read carefully. Berealistic with respect to payoffs and risks. Run experiments before making major
commitments. But by no meanscan you afford to ignore “new” technologies (see related Principle 31).
Ref: Davis, A., “Software Lemmingineering,” IEEE Software, 10, 6 (September 1993), pp.


79-81, 84.
3}

PRINCIPLE 31
DON'T VGNORE TECHNOLOGY
Software engineering technologyis evolving rapidly. You cannotafford to
sit around for a few years without keeping abreast of new developments. Software engineering appears to grow by waves. Each wavebrings withit
a largecollection of “fads” and buzzwords. Although each wave appears
to last just five to seven years, the wave does not simply disappear. Instead
each subsequent wavestands uponthe best features ofall previous waves.
(Hopefully “best” means “mosteffective,” but unfortunately it often means
“most popular.”)
I know oftwo waysto keep abreastofthe technology:readingthe right
magazines andtalking to the right people. IEEE Software magazineis a
goodplaceto learn about what's likely to be usefulin the zero-to-five-year
timeframe. PC Week, MacWorld, and the like are good places to learn about
hardware platforms and commercially available tools and languages. To learn from talking to people, you must meetthe right people. Although talking to folks in your ownorganizationis necessary,it isn’t sufficient. Try
attending one or two key conferencesperyear. The presentations are probably not as importantas the conversations youhavein the hallways.
 

PRINCILE 32
USE DOCUMENTATION STANDARDS
If your project, organization, or customer demandsthat a documentation
standard be followed,then, of course, follow it. However, never blame a
standard for doing a badjob. All the standardsI’m familiar with, whether governmentor commercial, provide organizational and content guidance.
Innovate! Follow the standard and do it intelligently. That means including what you know needsto be included regardless of whatthe stan- dard says. It means writing in clear language. It means adding additional
levels of organization that makesense.If you are not required to follow a
standard,atleast use oneas a checklist to verify that you don’t have major
omissions. IEEE publishes one of the most extensive volumes of useful software documentation standards that I know.
Ref: IEEE Computer Society, Software Engineering Standards Collection, Washington,

D.C.: IEEE ComputerSociety Press, 1993.
8

PRINCIPLE 33
EVERY DOCUMENT NEEDS A GLOSSARY
All of us becomefrustrated when we read a document and come across a
term wedo not understand. The frustration is short-lived, however, when
we turn to the back and find the term defined in a glossary.
Thedefinitions of all terms should be written in a manner that minimizesthe needto look up in the glossary anyof the words used in the definitions. One techniqueis first to explain the term in common,everyday terminology, and then add a second definition that uses other glossary
terms. Terms used within definitions that are themselves defined elsewhere should beitalicized. For example:
Data-flow diagram:Agraphical notation that showstheflowsof information amongthe functions and databases of a system andparts of the environmentthatinterface to the system. A notation used extensively in structured analysis, consisting oftransforms (bubbles), data flows (arrows),
data stores (two parallel lines), and external entities (rectangles).

0

PRINCIDLE 34
EVERY SOFTWARE DOCUMENT NEEDS AN INDEX
This principle is self-evident toall readers of software documents.It is sur- prising that authors do not realize this (considering the fact that every
author wearsthe hat of a reader on occasion). An indexisa list of all terms
and concepts used in the document, together with one or more page numbers where the term or conceptis defined, used, or referenced.Thisis true
for requirements, design, code,test, users’, and maintenance documents. The index is used when a reader wantsto find information quickly, andit
is essential during later maintenance or enhancementof the document. Modern word processorsfacilitate index creation by providing commandsto embedindexreferencesin the text. Then the word processor does
the workof compiling, alphabetizing, and printing the results. Most CASE
tools generate useful indexes as well.

4]

PRINCIPLE 35
USE THE SAME KAME FOR THE SAME. CONCEPT
Unlike writing fiction where maintaining the readers’ interest is the number one goal, technical documentation mustalways use the same words to
refer to the same concept and the samesentencestructure for similar messages. To do otherwise would confuse the reader, causing the reader to
spendtime trying to determineif there was a technical message in the
rewordingitself. Apply this principleto all technical writing: requirements
specifications, users’ manuals, design documentation, in-line comments,
and so on.
For example,
THERE ARE THREE TYPES OF SPECIAL COMMANDS. REGULAR COMMANDS COME
IN FOURVARIETIES.
is not as good as:
THERE ARE THREE TYPES OF SPECIAL COMMANDS. THERE ARE FOUR TYPES OF
REGULAR COMMANDS.
Ref: Meyer, B., “On Formalism in Specifications,” IEEE Software, 2, 1 (January 1985),

pp. 6-26.
———SEEEE_—_—EE_—E—e
2

DRINCIDLE 36
RESEARCH-THEN-TRANSFER DOESN'T WORK
Theliteratureis full of reports of incredible technical achievementsin software engineering research laboratories. Few of these ever makeit to software developmentfacilities. The reasonsare that:
1. In general, software researchers havelittle experience developing real
systems.
2. Software researchers mayfindit easier to solve sometechnical problem
quickly without taking the exorbitant amountof time necessary to make
sureit “fits” the real world.
. Researchers and practitioners often have such divergent vocabularies
that each party finds it difficult to communicate with the other.
wo
The result is that researchers tend to demonstrate their ideas on an ever
increasing numberof “toy problems.”
The mostsuccessfultransfers of ideas from the research laboratory to
the developmentfacility have resulted from close ties between the two facilities—from the beginning. They have used the industrial environment as
the laboratory in which the ideas germinate and are demonstrated to be
effective, rather than trying to do technologytransferafter idea formulation.
Ref: Basili, V., and J. Musa, “The Future Engineering of Software: A Management Perspective,” IEEE Computer, 24, 9 (September1991), pp. 90-96.
 

DRINCIDLE 37
TARE RESPONSIBILITY
In all engineering disciplines, when a design fails, the engineers are blamed. Thus, when bridge collapses, we ask, “What did the engineers do wrong?” Whensoftware fails, the engineers are rarely blamed. If they
are, the engineers respond with, “The compiler must have made a mis- take,” or “I wasjust following the 15 steps of this method,” or “My manager made medoit,” or “The scheduleleft insufficient time to do it right.” Thefactis that the best methods can beutilized in any engineering disci- pline to produce awful designs. And the most antiquated methods can be utilized in any engineeringdiscipline to produceelegantdesigns.
There are no excuses.If you are the developer of a system,it is your responsibility to doit right. Take that responsibility. Doit right, or don’t do it at all.
Ref: Hoare, C.A.R,, “Software Engineering: A Keynote Address,” IEEE 3rd International
 a
Conference onSoftware Engineering, 1978, pp. 1-4.
4

 

REQUIREMENTS ENGINEERING
PRINCIPLES
Requirements engineering is the set of activities including(1) eliciting or
learning about a problem that needs a solution, and (2) specifying the
external (black box) behavior of a system that can solve that problem. The
final product of requirements engineering is a requirements specification.

i]

PRINCIPLE 36
POOR REQUIREMENTS YIELD DOOR COST ESTIMATES
The top five causes for poorcost estimation all relate to the requirements
process:
1. Frequent requirements changes
2. Missing requirements
3. Insufficient communication with users
4. Poorspecification of requirements
5. Insufficient analysis
Use prototyping to reducetherisk of incorrect requirements. Use configuration management to control change. Plan new requirements for
future releases. Use more formal approachesfor requirements analysis and
specification.
Ref: Lederer, A., and J. Prasad, “Nine Management Guidelines for Better Cost


Estimating,” Communications of the ACM,35, 2 (February 1992), pp. 51-59.
8

PRINCIPLE 39
DETERMINE THE PROBLEM BEFORE WRITING REQUIREMENTS
Whenfaced with what they believe is a problem, most engineers rush into offering solutions. If the engineer’s perception of the problem is accurate, the solution may work. However, problemsare often elusive. For example,
Donald Gause and Gerald Weinberg describe a “problem”in a high-rise office building in which the occupants are complaining about long waits
for elevators. Is this really the problem? And whoseproblemis it? From the
occupants’ perspective, the problem might be that they waste too much time. From the building owner’s perspective, the problem mightbe that
occupancy(and thusrental income) may decrease.
The obvioussolution is to increase the speed of the elevators. But
other ideas mightinclude(1) adding newelevators,(2) staggering working
hours, (3) reserving someelevators for express service, (4) increasing the
rent (so that the owner can tolerate reduced occupancylevels), and (5) refining the “homingalgorithm”used bythe elevators so that they move
to high-demandfloors whenidle. The rangeofcosts,risks, and time delay
associated with these solutions is enormous. Yet any one could work
dependingonthe exactsituation. Before trying to solve a problem, be sure
to exploreall alternative options for who really has the problem and what
the problem really is. When solving the problem, don’t be blinded by the
potential excitementof the first solution. Procedural changes are always
less expensive than system construction.
—
Ref: Gause, D., and G. Weinberg, Are Your Lights On? NewYork: Dorset House, 1990.
9

PRINCIPLE 40
DETERMINE THE REQUIREMENTS HOW
Requirements are hard to understand and harder to specify. The wrong,
solution to this problem is to doa slipshodjob of requirements specification, and rush ahead to design and codein the vain hope that:
1. Any system is better than no system.
2. The requirements will work themselves out soonerorlater.
3. Orthe designerswillfigure out whatcan be built as they are buildingit.
The right solution is to do whateverit takes to learn as many of the
requirements as possible now. Do prototyping. Talk with more customers. Work for a month with a customerto get to knowhisor herjobfirsthand.
Collect data. Do whateverit takes. Now documentthe requirements that
you understand and plan to build a system to meet those requirements.If
you expect requirements to changesignificantly, that’s okay; plan to build
incrementally (Principle 14), but that is no excuse for doing a poor job of
requirements specification on any one increment.
Ref: Boehm, B., “Verifying and Validating Software Requirements and Design

Specifications,” IEEE Software, 1, 1 (January 1984), pp. 75-88.
0

PRINCIPLE 4]
FTA REQUIREMENTS SPECIFICATION ERRORS AOU
If you haveerrors in the requirementsspecification, they will cost you:
= Five times moreto find andfix if they remain until design.
= Ten times more if they remain until coding.
= Twenty times moreif they remain until unit testing. = Two hundredtimes moreif they remain until delivery.
That is more than convincing evidenceto fix them during the requirements phase!
Ref: Boehm, B., “Software Engineering,” IEEE Transactions on Computers, 25, 12 (December1976), pp. 1226-1241.

I
PRINCIPLE

42
DROTOTYDES REDUCE RISK IN SELECTING USER INTERFACES
Thereis nothing as useful as a prototypefor taking a low-risk, high-payoff
approach for reaching agreementon a user interface prior to full-scale
development. There are myriad tools to assist in creating screen displays
quickly. These so-called “storyboards”give the users the impression of a
real system. Not only do they help nail down requirements, they also win
the hearts of the customers and users.
Ref: Andriole, S., “Storyboard Prototyping for Requirements Verification,” Large Scale

a
Systems, 12 (1987), pp. 231-247.
2

PRINCIPLE 43
RECORD WHY REQUIREMENTS WERE INCLUDED
Manyactivities culminate in the creation of a requirements specification: interviews, debates, discussions,architectural studies, statements of work, questionnaires, JAD/RADsessions, requirements specifications of other systems,earlier system-level requirements. The requirements specification states the requirements that have resulted from such activities. Let us assumethat a user subsequently requests a change to a requirement. We need to knowthe motivationfor the original requirement to know whether we can safely changeit. Similarly, when a system fails to satisfy a require- ment, we need to know the background of the requirementbefore we can decide if we should modify the system to meet it or modify the require- mentto match the system.
When a requirements decision is made (such as a two-second
response time), record a pointerto its origin. For example,if the decision was made duringan interview with a customer, record the day andtime, as well as the participants in the interview.Ideally,refer explicitly to a tran- script, tape recording,or videorecording.It is only with such documentation that one can (1) evolve requirementslater or (2) respondto situations wherethe as-built system fails to satisfy the requirements.
Ref: Gilb, T., Principles of Software Engineering Management, Reading, Mass.: Addison-

Wesley, 1988, Section 9.11.
3

PRINCIPLE 44
IDENTIFY SUBSETS
When writing a requirementsspecification, clearly identify the minimal
subset of requirements that might be useful. Also identify the minimal
increments that might make the minimal subset more and more useful.
Suchidentification provides software designers with insight into optimal
software design. For example,it will enable designers to:
1. Moreeasily embedjust one function per component.
2. Select architectures that are more contractible and extendible.
3. And understand how to reduce functionality in the case of a schedule or
budgetcrunch.
Oneveryeffective techniqueofrecording subsets is to includea set of
columnsin the margin of the SRS beside each requirement. Each column
correspondsto a different version. These versions can represent multiple
flavors of a product, each tailored to a different customer or situation, or
they can representincreasinglevels of enhancementthroughtime.In either case, place an “X” in the appropriate columnsto indicate which versions
will have which features.
Ref: Paras, D., “Designing Software for Ease of Extension and Contraction,” IEEE

Transactions on Software Engineering, 5, 2 (March 1979), pp. 128-138.
—————————————
H

PRINCIPLE 4)
REVIEW THE REQUIREMENTS
Manyparties havea stake in the success of a product development:users,
customers, marketing personnel, developers, testers, quality assurance
personnel, and so on. All of them also have a stake in the correctness and
completenessof the requirements specification. A formal review of the SRS
should be conducted prior to a major investmentin the design or code. Giventhat the SRS has been written in natural language, there is no
easy wayto reviewit; however, advice given by Barry Boehm on whatto look for can smooththe path. Of course,if parts of the SRS have been written in more formallanguages (Principles 28, 54, and 55), these parts lend
themselves to manualreview (dueto their lack of ambiguity) and to “execution” in some cases. Executable requirements [such as Pamela Zave's
PAISLey (“An Insider’s Evaluation of PAISLey,” IEEE Transactions on
Software Engineering, 17, 3 (March 1991), pp. 212-225)] can be given to an
appropriatetool for interpretation. With such interpretation, stakeholders
can “see” how the system performsrather thanjust “reading” about how
the system performs.
Ref: Boehm, B., “Verifying and Validating Software Requirements and Design


Specifications,” IEEE Software, 1, 1 January 1984), pp. 75-88.
5S

PRINCIPLE
AVOID DESIGN
46
IN REQUIREMENTS

The purposeof the requirements phaseis to specify external behavior of the
solution system. This behavior should be specific enough to ensurethatall
designers will reach the same conclusion about intended behavior when they use the specification as an oracle. It should not, however, specify a
software architecture or algorithm, for this is the realm of the designer.
Designerswill later select architectures and algorithms for optimalsatisfaction of requirements.
If requirements writers find it difficult or impossible to specify external behavior unambiguously withoutlooking like a design (for example,
using finite state machine to describe system behavior), then the requirements writer should include a messagelike this:
WARNING:THE “DESIGN” CONTAINED HEREIN IS SUPPLIED AS AN AID IN
UNDERSTANDINGTHE PRODUCTS’ EXTERNAL BEHAVIOR ONLY. THEDES MAY SELECT ANY DESIGN THEY WISH PROVIDED IT BEHAVES EXTERNALLY IN A
MANNERIDENTICALTO THE EXTERNAL BEHAVIOR OF THE ABOVESYSTEM.

Ref: Davis, A., Software Requirements: Objects, Functions and States NJ.: Prentice Halll, 1993, Section 3.1.


, Englewood Cliffs,
6

PRINCIPLE 47
USE THE RIGHT TECHNIQUES
No requirements technique works for all applications. The requirements for complex applications can be understood only when multiple tech- niquesare used. Use a techniqueorsetof techniques most appropriate for yourapplication.
For example, use entity-relation diagramsfor data-intensive applica- tions, finite state machines orstatecharts for reactive (real-time) systems, Petri nets for applications with synchronychallenges, decision tables for decision-intensive applications, and so on.
Ref: Davis A., “A Comparison of Techniquesfor the Specification of External System
——————
Behavior,” Communications of the ACM, 31, 9 (September 1988), pp. 1098-1115.
eee

I
PRINCIPLE

4B
USE MULTIPLE VIEWS OF REQUIREMENTS
Any one “view”of requirementsis insufficient to understand or describe
the desired external behavior of a complex system.Instead of using structured analysis, or object-oriented analysis, or statecharts, select a combination that make sense—and use them.
For example, on a complex system, you may wantto use object-oriented analysis to assess the primary real-world entities relevant to the
application. OOAwill help identify them and understandtheir interrelationships and relevant attributes. You may want to use finite-state
machinesto describe the desired behaviorof the user interface. You may
wantto use decision trees to describe the desired system’s behavior in
response to a complex combination of external conditions, and so on.
Ref: Yeh, R, P. Zave, A. Conn, and G. Cole, Jr, “Software Requirements: New Directions and Perspectives,” in Handbook of Software Engineering, C. Vick and C. Ramamoorthy, eds., New York: Van Nostrand Reinhold, 1984, pp. 519-543.


———
eee
8

PRINCIPLE 49
ORGANIZE REQUIREMENTS SENSIBLY
Weusually organize requirements hierarchically. This helps readers understand the system’s functions and helps requirements writers locate sections
whenneeds change. There are many waysto organize requirements; selec- tion of the most appropriate way is dependenton the specific product.
Organize requirements in a way most natural for the customers,
users, or marketing personnel. Here are some examples:by(class of) user,
by (class of) stimulus, by (class of) response, by (class of) object, by (class of) feature, by system mode. Since complex systems have many require- ments, use multiple organizations. For example, for a telephone switching
system, organize byclass of feature, then feature, then user:
1. Single-party calls 2.2 Long distance call 11 Call forwarding 2.2.1 Calling party view 1.2 Call park 2.2.2 Called party view 2. Two-party calls 3. Multiparty calls
2.1 Local call 3.1 Conferencecall 2.1.1 Calling party view 3.2 Operator-assisted call *
2.1.2 Called party view
Ref: Davis, A., Software Requirements: Objects, Functions, and States, Englewood Cliffs,
EES
NJ. Prentice Hall, 1993, Section 3.4.11.
9
PRINCIPLE

50
PRIORITIZE REQUIREMENTS
Notall requirements are equal. Requirements for a human-piloted space
vehicle mightincludethe presence of both instant orangejuice and a functioninglife support system.Butclearly the formeris not as importantas the
latter. You probably would not abort a launch if the orange juice was absent, but you would abortif the life support wasnot functioning. One waytoprioritize requirementsis to suffix every requirementin
the specification with an M,D, or O to connote mandatory, desirable, and
optional requirements. Althoughthis creates the oxymoronic conceptof an
optional requirement,it expresses clearly and precisely the relative priori- ties. An even better wayis to rate the importanceof every requirement on
a scale from 0 to 10.
Ref: Davis, A., Software Requirements: Objects, Functions, and States, EnglewoodCliffs,


NJ. Prentice Hall, 1993, Section 3.4.11
it}

PRINCIPLE 51
WRITE CONCISELY
1 often see requirements specifications with sentenceslike:
THE TARGET TRACKING FUNCTION SHALL PROVIDE THE CAPABILITY TO DISPLAY THE CURRENT TRACKING COORDINATES OF ALL ACTIVE TARGETS.
Contrast this with:
WHEN TRACKING,THE SYSTEM SHALL DISPLAY THE CURRENTPOSITIONS OF ALL ACTIVE TARGETS.
 
PRINCIDLE

52
SEPARATELY NUMBER EVERY REQUIREMENT
It is essential that every requirementin the requirements specification be
easily referenceable.This is necessary to enable latertracing to the requirementsfrom design (Principle 62) and from test (Principle 107).
The easiest way to dothis is to tag every requirement with a unique
identifier (such as “[Requirement R27]”). An alternativeis to numberevery
paragraphand thenreferto a requirementin sentencek of paragraphi.j as
“requirementij-sk.” A third alternative is to follow the rule that every
requirement contains the word “shall” (or any other suitable, but reserved,
word), such as, “The system shall emit a dial tone within .5 secondsof...”
Thenuse a simple text-matching program to extract, number,andlist in an
appendix all requirements.
Ref: Gilb, T., Principles of Software Engineering Management, Reading, Mass.: Addison-

—————
Wesley, 1988, Section 8.10.
a

PRINCIPLE 53
REDUCE AMBIGUITY IN REQUIREMENTS
Mostrequirements specifications are written in natural language. Natural languagessuffer from inherent ambiguity due to the imprecision of the semantics of words, phrases, and sentences. Although the only way to removeall ambiguity from the requirementsis to use a formallanguage,it is possible to reduce ambiguity somewhat bycarefully reviewing for and rewriting any sections of text with obvious or subtle ambiguity. Al Davis provides numerous examples of ambiguity and their consequences. Three effective techniques at reducing ambiguity are:
1. Performing Fagan-type inspections on the SRS.
2. Trying to construct more formal models of the requirements and rewrit- ing the natural languageas problemsare found(Principle 28).
3. Organizing the SRS so that facing pages contain natural language and more formal models,respectively.
Ref: Davis, A., Software Requirements: Objects, Functions, and States, Englewood Cliffs,
 _———
N.J.: Prentice Hall, 1993, Section 3.4.2.
8

PRINCIPLE 54
AUGMENT, NEVER REPLACE, NATURAL LANGUAGE
In aneffort to reduce ambiguity in requirements, software developers often
decideto usea notationthatis more precise than natural language.Thisis, of course, commendable in that ambiguity is reduced (Principle 53) by
using finite state machines, predicatelogic, Petri nets, statecharts, and the
like. However, in such aneffort, the specification is rendered less understandable by others (Principle 56) who mayhaveless computerscience or
mathematical backgroundthan the requirements writer.
To alleviate this problem whenusingaformalnotation,retain the natural languagespecification. In fact, one goodideais to keepthe naturallan- guage and moreformalspecification side-by-side on opposing pages. Do a
manualcheck between the twoto verify conformity. The results will be that
all readers can understand something and that some nonmathematical
readers may learn something useful.
Ref: Meyer, B., “On Formalism in Specifications,” IEEESoftware, 2, 1 (January 1985), pp.

6-26.
—————————————————
iy

PRINCIPLE 55
WRITE NATURAL LANGUAGE BEFORE A MORE FORMAL MODEL
Principle 54 says to create requirements specifications that contain both
natural language and formal models. Always create the natural language
first. If you write the formal modelfirst, the tendency will be to write nat- ural language that describes the model instead of the solution system.
Contrast these two segmentsto see what I mean:
TO MAKE A LONG DISTANCE CALL, THE USER SHOULD LIFT THE PHONE. THE
SYSTEMSHALL RESPONDWITH A DIAL TONE WITHIN 10 SECONDS. THE USER
SHOULDDIAL A “9.” THE SYSTEM SHALLRESPONDWITHA DISTINCTIVE DIAL
TONE WITHIN 10 SECONDS.

THE SYSTEM CONSISTS OF FOURSTATES:IDLE, DIAL TONE, DISTINCTIVE DIAL
TONE, AND CONNECTED. TO GET FROMTHE IDLE STATE TO THE DIAL TONE
STATE, LIFT THE PHONE. TO GET FROM THE DIAL TONE STATE TO THE DISTINCTIVE DIAL TONESTATE, DIAL A “9.”
Notethat,in the latter example,the text does not help the readeratall. The
best approach is to (1) write the natural language, (2) write the formal
model, and (3) adapt the natural language to reduce ambiguities that become apparent when writing the formal model.

6

PRINCIPLE 56
KEEP THE REQUIREMENTS SPECIFICATION READABLE
Arequirementsspecification must be read and understood by a wide range of individuals and organizations: users, customers, marketing personnel, requirements writers, designers, testers, managers, and others. The docu- ment must be written in a manner that enables all these people to fully appreciate the system neededand beingbuilt so that there are no surprises. Creation of multiple requirements specifications (each for a subset of the stakeholders) works only if you can guarantee consistency across the versions. A more effective method is to maintain the natural language (Principle 54) while incorporating multiple views of a more formal nature (Principles 48 and 53).
Ref: Davis, A., Software Requirements: Objects, Functions, and States, Englewood Cliffs, NJ.: Prentice Hall, 1993, Section 3.4.6.
_————eeeeeeeeeeeeeNNNNNNeNeeeeeee
6

PRINCIDLE 57
SPECIFY RELIABILITY SPECIFICALLY
Softwarereliability is difficult to specify. Don’t make the problem even
moredifficult by being vague. For example, “THE SYSTEM SHALL BE 99.999
PERCENT RELIABLE” meansnothing. Doesit mean that the system cannot be
“down” moreoften than 5 minutes every year but that it is okay to occasionally make a mistake (for example, a telephone system may occasionally misdirect a phonecall). Or does it meanthatit must make no more than
one mistake every 100,000 transactions (for instance, a patient monitoring
system cannot“kill” more than one out of every 100,000 patients)?
Whenwritingreliability requirements, differentiate between:
1. Failure on demand. Whatis the likelihood, measured as a percentage of
requests, that the system will fail to respond correctly? For example,
“THE SYSTEM SHALL CORRECTLY REPORT 99.999 PERCENTOF PATIENT VITAL SIGN
ANOMALIES.”
2. Rateoffailure. This is the sameas“failure on demand”butit is measured
as a percentage of time. For example, “THE SYSTEM MAYFAIL TO REPORT A
PATIENT VITAL SIGN ANOMALY NO MORE OFTEN THAN ONCEPER YEAR.”
3. Availability. What percentage of time may the system be unavailable for
use? For example, “THE TELEPHONE SYSTEM SHALLBE AVAILABLE 99.999 PERCENTOF THE TIME IN ANY GIVEN CALENDARYEAR.”
Ref: Sommerville, L., Software Engineering, Reading, Mass.: Addison-Wesley, 1992,

————
Section 20.1
@

PRINCIPLE 58
SDECIEY WHEN ENVIRONMENT VIOLATES “ACCEPTABLE” BEHAVIOR
Requirements specifications often define characteristics of the system’s environment.This information is used in makingintelligent design deci- sions. It also often implies that the developeris contractually obligated to accommodate such characteristics. What happens after deployment when the environmentexceedsthe specified limits?
Suppose the requirements for an airtraffic controller system specify that the system shall handle up to 100 aircraft in a sector simultaneously. The system is built and correctly satisfies this requirement. Three years later 101 aircraft accidentally enter a sector. What should the software do? Thepossibilities are:
1. Print an error message, “Environmentis violating the requirements.”
2. Crash (the software stops). 3. Ignorethe 101st aircraft.
4. Process all 101 aircraft but perhaps not satisfy some other timing constraint (such as howoften thescreenis updated).
Obviously, options 1, 2, and 3 are unacceptable. Yet they are valid system
responsesas(not)stated in the requirements. The right solutionis to explic- itly state in the SRS the expected system response when the environment exceeds anyof the constraints defined for it.
Ref: Davis, A., Software Requirements: Objects, Functions and States, EnglewoodCliffs,
—
NJ.: Prentice Hall, 1993, Section 5.3.2.
8

PRINCIDLE 59
SELE-DESTRUCT 1BD'S
It is often preached that a requirements specification should contain no
TBDs(To Be Determined). Obviously, a specification with a TBD is not complete, but there may be very good reasons for approving and perhaps
baselining the documentwith the TBD.Thisis particularly true for requirements whoseprecision are not critical to fundamental design decisions.
Whenyoucreate a TBD,besure to footnoteit with a “self-destruction
note,”that is, specify whowill resolve the TBD and by when. For example, such a footnote might say, “The software development managerwill
replace this TBD nolater than December 1995.” This assures that the TBD
does not remain forever.
Ref: IEEE, ANSI/IEEE Guide to Software Requirements Specifications, Standard 830-1994,

Washington, D.C.: IEEE ComputerSociety Press, 1994.
9

PRINCIPLE 60
STORE REQUIREMENTS IN A DATABASE
Requirements are complex and highly volatile. For these reasons, storing
them in electronic media, preferably a database,is a good idea. This will
facilitate making changes, finding implications of changes, recording
attributes of specific requirements, and so on.
Someof the things you wantto store in the database are unique identifier (Principle 52), the text of the requirement, its relationship to other
requirements (such as moreabstract or more detailed descriptions of the
requirement), importance(Principle 50), expected volatility, pointers to its
sources(Principle 43), applicable product versions (Principles 44 and 178),
and so on. Ideally, the requirementsspecification itself is nothing but an organized “dump”ofthe entire database.

nN

 

DESIGN PRINCIPLES
Designis thesetofactivities including (1) defining an architecture for the
softwarethatsatisfies the requirements and (2) specifying an algorithm for
each software componentin the architecture. The architecture includes a
specification of all the building blocks of the software, how theyinterface
with each other, how they are composed of one another, and howcopies
of componentsare instantiated (that is, copies made in memory of components and executed) and destroyed. The final product of design is a
design specification.

B

PRINCIPLE 61
TRANSITION FROM REQUIREMENTS TO DESIGN 1S NOT EASY
Requirements engineering culminates in a requirements specification, a
detailed description of the external behavior of a system. Thefirst step of design synthesizes an optimal software architecture. There is no reason whythe transition from requirements to design should be any easier in software engineering than in any other engineering discipline. Design is hard. Converting from an external view to an internal optimal design is fundamentally a difficult problem. Some methodsclaim transition is easy by suggesting that we use the “architecture” of the requirements specification as the architecture. Since designis difficult there are three possibilities:

1. No thoughtwentinto selecting an optimal design during requirements.
In this case, you cannotafford to accept the designas the design.
2. Alternative designs were enumerated and analyzed and bestselected,all during requirements. Organizations cannotafford the effort to do a thor- ough design(typically 30 to 40 percentof total developmentcosts) prior to baselining requirements, making a make/buy decision, and making a
developmentcost estimate.
3. The method assumes that somearchitecture is optimal for all applica- tions. This is clearly not possible.
Ref: Cherry, G., Software Construction by Object-Oriented Pictures, Canadaigua, New

York: ThoughtTools, 1990, p. 39.
h

PRINCIPLE 62
TRACE DESIGN 10 REQUIREMENTS
Whendesigning software, the designer must know which requirements are beingsatisfied by each component. Whenselecting a softwarearchitecture,
it is important that all requirements are “covered.” After deployment,
whena failure is detected, maintainers need to quickly isolate the software
components mostlikely to contain the causeof the failure. During maintenance, when a software componentis repaired, maintainers need to know
what other requirements mightbe adverselyaffected.
All these needs can besatisfied by the creation of a large binary table
with rowscorrespondingtoall software components and columnscorresponding to every requirementin the SRS. A1 in anyposition indicates that
this design componenthelpsto satisfy this requirement. Notice that a row
void of 1’s indicates that a componenthas no purpose anda columnvoid of
1's indicates an unfulfilled requirement. Some people arguethatthis table is verydifficult to maintain. I would arguethat youneed this table to design
or maintain software. Withoutthe table, you are likely to design a software
componentincorrectly, spending exorbitant amounts of time during maintenance. The successful creation of such a table dependson yourability to
refer uniquely to every requirement (Principle 52).
Ref: Glass, R., Building Quality Software, Englewood Cliffs, N.J.: Prentice Hall, 1992,

Section 2.2.2.5.
5

DRINCIDLE 63
EVALUATE ALTERKATIUES
Acritical aspectofall engineering disciplines is the elaboration of multiple
approaches,trade-off analyses among them, and the eventual adoption of
one. After requirements are agreed upon, you must examinea variety of
architectures and algorithms. You certainly do not wantto use an architecture simply becauseit wasused inthe requirementsspecification (Principle
46). After all, that architecture was selected to optimize understandability
of the system’s external behavior. The architecture you wantis the one that
optimizes conformance with the requirements contained in the requirements specification.
For example, architectures are generally selected to optimize throughput, response time, modifiability, portability, interoperability, safety, or
availability, while also satisfying the functional requirements. The best way to do this is to enumerate a variety of software architectures, analyze (or
simulate) each with respect to the goals, and select the best alternative.
Somedesign methodsresult in specific architectures; so one way to generate a variety of architectures is to use a variety of methods.
Ref: Weinberg, G., Rethinking Systems Analysis and Design, New York: Dorset House,

1988,Part V.
I

PRINCIPLE 64
DESIGN WITHOUT DOCUMENTATION 1S HOP DESIGN
I have often heard software engineers say, “I have finished the design. All that's left is its documentation.” This makes no sense. Can you imagine a
buildingarchitect saying, “I have completed the design of your new home.
All that’sleft is to drawa pictureofit,” or a novelist saying “I have completed the novel. All that’s left is to write it’? Design is the selection,
abstraction, and recording of an appropriate architecture and algorithm
onto paper or other medium.
Ref: Royce, W., “Managing the Development of Large Software Systems,” WESCON 70, 1970; reprinted in 9th International Conference on Software Engineering,


Washington, D.C.: IEEE Computer SocietyPress, 1987, pp. 328-338.
7

PRINCIDLE 65
ENCAPSULATE
Information hidingis a simple, proven conceptthatresults in software that
is easier to test and easierstill to maintain. Most software modules should
hide someinformation from all other software. This information could be
the structure of data, the contents of data, an algorithm,a design decision,
or an interface to hardware, to a user, or to another piece of software.
Information hiding aidsin isolating faults because, when the hidden information becomes unacceptable in some manner(such as whenitfails or it must be changed to accommodate a new requirement), only the piece of
software hiding that information need be examined or altered.
Encapsulation refers to a uniform setof rules about which types of information should be hidden. For example, encapsulation in object-oriented
design usually refers to the hiding of attributes (data) and methods(algorithms) inside each object. No other objects may effect the values of the attributes except via requests to the methods.
Ref: Parnas, D., “On the Criteria to Be Used in Decomposing Systems into Modules,”


Communications of the ACM,15, 12 (December1972), pp. 1053-1058.
B

PRINCIDLE 66
DON'T REINVENT THE WHEEL
Whenelectrical engineers design new printed circuit boards, they go to a
catalog of available integrated circuits to select the most appropriate com- ponents. Whenelectrical engineers design newintegratedcircuits, they go
to a catalog of standardcells. When architects design new homes,they go
to catalogsof prefabricated doors, windows, moldings, and other components. All this is called “engineering.” Software engineers usually reinvent components over and over again; theyrarely salvage existing software
components.It is interesting that the software industrycalls this rare practice “reuse” rather than “engineering.”
Ref: Ramamoorthy, C. V., V. Garg, and A. Prakash, “Programmingin the Large,” IEEE

Transactions on Software Engineering, 12, 7 (July 1986), pp. 769-783.
v

PRINCIPLE 67
HEED IT SIMPLE
A simple architecture or a simple algorithm goes a long way toward
achieving high maintainability. Remember KISS. Also, as you decompose
software into subcomponents, rememberthat a humanhasdifficulty comprehending more than seven (plus or minus two)things at once. C. A. R.
Hoarehassaid:
There are two waysof constructing a software design. One way is to
makeit so simple that there are obviously no deficiencies and the other
is to makeit so complicated that there are no obvious deficiencies.
Ref: Miller, G., “The Magical Number Seven, Plus or Minus Two,” The Psychological

Review, 63, 2 (March 1956), pp. 81-97.
a

PRINCIPLE 68
AVOID NUMEROUS SPECIAL CASES
Asyou design youralgorithms, you will undoubtedly realize that there are exceptional situations. Exceptional situations cause special cases to be addedto youralgorithm. Every special case makesit moredifficult for you to debug and for others to modify, maintain, and enhance.
If you find too manyspecialcases, you probably have an inappropri- ate algorithm. Rethink and redesign the algorithm.Seerelated Principle 67.
Ref: Zerouni, C., as reported by Bentley, J., More Programming Pearls, Reading, Mass.: Addison-Wesley, 1988, Section 6.1.
——————————————
]

PRINCIPLE 69
AMINIMIZE INTELLECTUAL DISTANCE
Edsger Dijkstra defined intellectual distance as the distance between the
real-world problem and the computerized solution to that problem.
Richard Fairley arguesthat the smallertheintellectual distance, the easier
it will be to maintain the software.
To dothis, the structure of the software should as closely as possible
mimic the structureof the real world. Design approachessuchasobject-oriented design and Jackson System Development have minimalintellectual
distance as primary design drivers. But you can minimizeintellectualdistance using any design approach. Be aware,of course, that the “structure of
the real world”is not unique. As pointed out so well by Jawed Siddiqi in
his March 1994article in IEEE Software, entitled “Challenging Universal
Truths of Requirements Engineering,” different humansoften perceive different structures when examiningthe samereal world and thus construct
quite diverse “constructed realities.”

Ref: Fairley, R., Software Engineering Concepts, NewYork: McGraw-Hill, 1985.
————eeee————eeeeEeEeEeee a

PRINCIPLE 70
REED DESIGN UNDER INTELLECTUAL CONTROL
A design is underintellectual controlif it has been created and documented in a mannerthatenablesits creators and maintainers to fully understandit.
An essential attribute of such a designis that it is constructed hierarchically and with multiple views. Hierarchies enable readers to comprehendthe entire system abstractly, and then comprehendfiner and finerlevels of details as they move downthehierarchy. At each level the component
should be described from an external point of view only (Principle 80).
Furthermore, any single component(at anylevel in the hierarchy) should exhibit simplicity and elegance.
Ref: Witt, B., F. Baker, and E. Merritt, Software Architecture and Design, New York: Van


Nostrand Reinhold, 1994, Section 2.5.

PRINCIDLE 71
MAINTAIN CONCEPTUAL INTEGRITY
Conceptualintegrity is an attribute ofa quality design. It implies that a limited numberofdesign “forms” are used and that they are used uniformly. Design formsinclude the way componentsinform their callers of error conditions, how the software informs users of error conditions, how data
structures are organized, mechanisms for component communication, documentation standards, and so on.
Whena design is complete, it should look as if one person created it
all, even though it is the product of many devoted people. During the
design process, there are often temptations to diverge from the accepted forms. It is okay to give in to such temptationsif thejustificationis for additionalintegrity, elegance, simplicity, or performanceof the system.It is not
okayto give in solely to ensure that designerx hasleft his or her mark on
the design. Egosatisfaction is not as important as conceptualintegrity.

Ref: Witt, B., F. Baker, and E. Merritt, Software Architecture and Design, New York: Van


Nostrand Reinhold, 1994, Section 2.6.

PRINCIPLE 72
CONCEPTUAL ERRORS ARE MORE SIGNIFICANT THAN SYNTACTIC ERRORS
When creating software, whether writing requirements specifications,
design specifications, code, or tests, we spend considerable effort to
remove syntactic errors. This is laudable. However, the real difficulty in constructing software arises from conceptual errors. Most developers
spend moretime looking for and correcting syntactic errors because, when
found,theselooklikesilly errors that in some way amusethedeveloper. In
contrast to these, developers often feel in some wayflawed, or incompetent, whentheylocate a conceptualerror. No matter how goodyou are, you will make conceptualerrors. Lookfor them.
Ask yourself key questions at each phase of development. During requirements ask yourself, “Is this what the customer wants?” During
design, “Will this architecture behave appropriately understress conditions?” or “Does this algorithm really workin all situations?” During coding, “Doesthis code do whatI think it does?” or “Does this code correctly implement the algorithm?” Duringtest, “Does the execution of this text convince me of anything?”
Ref: Brooks, F, NoSilver Bullet: Essence and Accidents of Software Engineering,”

IEEE Computer, 20, 4 (April 1987), pp. 10-19
5
PRINCIPLE

73
USE COUPLING AND COHESION
Coupling and cohesion were defined in the 1970s by Larry Constantine and
Edward Yourdon. Theyarestill the best ways we know of measuring the
inherent maintainability and adaptability of a software system. In short,
coupling is a measure of how interrelated two software components are.
Cohesionis a measure of how related the functions performed by a software component are. We wantto strive for low coupling and high cohesion. High coupling implies that, when we change a component,changesto other componentsare likely. Low cohesion implies difficulty in isolating the causes of
errors or places to adapt to meet new requirements. Constantine and
Yourdon even provided us with a simple-to-use way to measure the two
concepts. Most books on software design since 1979 describe these measures. Learn them. Use them to guide your design decisions.
Ref: Constantine, L., and E. Yourdon, Structured Design, Englewood Cliffs, NJ.:

Prentice Halll, 1979.
8

PRINCIPLE 74
DESIGN FOR CHANGE
During software development, weregularly uncovererrors, new requirements, or the results of earlier miscommunication. All these cause the design to change even before it is baselined (see related Principle 16).
Furthermore,after baselining the design anddelivering the product, even
more newrequirements will appear (see related Principle 185). All this
means that you mustselect architectures, components, and specification
techniques to accommodate majorand incessant change.
To accommodate change, the design should be:
= Modular, that is, it should be composedof independentparts that can be
easily upgraded or replaced with a minimum ofimpact onotherparts
(see related Principles 65, 70, 73, and 80).
= Portable, that is, it should be easily altered to accommodate new host machines and operating systems.
= Malleable, that is, flexible to accommodate new requirements that had not been anticipated.
= Of minimalintellectual distance (Principle 69).
= Underintellectual control (Principle 70).
= Such that it exhibits conceptual integrity (Principle 71).
Ref: Witt, B., F Baker, and E. Merritt, Software Architecture and Design, New York: Van


Nostrand Reinhold, 1994, Section 1.3.
ty

PRINCIDLE 75
DESIGN FOR MAINTENANCE
The largest postdesign cost risk for nonsoftware products is manufacturing. Thelargest postdesign cost risk for software products is maintenance.
In the formercase, design for manufacturability is a major design driver.
Unfortunately, design for maintainability is not the standardfor software.
It should be.
A designer has the responsibility to select an optimal software architecture to satisfy the requirements. Obviously, the appropriatenessof this
architecture will have a profoundeffect on system performance. However,
the selection of this architecture also has a profound effect on the main- tainability of the final product. Specifically, architecture selection is more
significant than algorithmsor codeasfarasits effect on maintainability.
Ref: Rombach,H. D., “Design Measurement: SomeLessonsLearned,” IEEE Software, 7,


2 (March 1990), pp. 17-25.
8

PRINCIPLE 76
DESIGN FOR ERRORS
No matter how much you work on yoursoftware,it will have errors. You should make design decisions to optimize the likelihood that:
1. Errors are not introduced.
2. Errors that are introducedareeasily detected.
3. Errors that remain in the software after deploymentare either noncriti- cal or are compensated for during execution so that the error does not cause a disaster.
Such robustnessis not easy to incorporate into a design. Someof the ideas that help includethe following:
1. Never “fall out of a case statement.” For example,if there are four pos- sible values for a variable, don’t check just for three and assumethatthe fourth is the only remaining possibility. Instead, assumethe impossible; check forthefourth value andtrap theerror conditionearly.
2. Predict as many “impossible” conditions that you can and develop strategies for recovery.
. To eliminate conditions that may cause disasters, do fault tree analysis for predictable unsafe conditions [see Leveson, N., “Software Safety: What, Why, and How,” ACM Computing Surveys, 18, 2 (June 1986), pp. 125-163].
wo
Ref: Witt, B., F. Baker, and E. Merritt, Software Architecture and Design, NewYork: Van Nostrand Reinhold, 1994, Section 6.4.2.6.
 

PRINCIPLE 77
BUILD GENERALITY INTO SOFTWARE
A software componentexhibits generality if it can perform its intended functions without any changein
a
varietyofsituations. General software
components are more difficult to design than less general components.
Theyalso usually run slower when executing. However, such components:
1. Are ideal in complex systems where a similar function must be performedin a variety of places.
2. Are more potentially reusable in other systems with no modification.
3. Reduce maintenancecosts for an organization due to reduced numbers
of unique orsimilar components.
When decomposing a system into its subcomponents,stay cognizant
of the potential for generality. Obviously, when a similar function is needed in multiple places, constructjust one general function rather than multiple similar functions. Also, when constructing a function neededinjust
oneplace, build in generality where it makes sense—for future enhancements.
Ref: Parnas, D., “Designing Software for Ease of Extension and Contraction,” IEEE

ee
Transactions on Software Engineering, 5, 2 (March 1979), pp. 128-138.
eee
5

PRINCIDLE 78
BUILD FLERIBILITY INTO SOFTWARE
Asoftware componentexhibitsflexibility if it can be easily modified to perform its function (or a similar function) in a different situation. Flexible software components are moredifficult to design than lessflexible components. However, such components(1) are more run-time-efficient than general components(Principle 77) and (2) are moreeasily reused thanlessflex- ible componentsin diverse applications.

Ref: Parnas, D., “Designing Software for Ease of Extension and Contraction,” IEEE

a
Transactions onSoftware Engineering, 5, 2 (March 1979), pp. 128-138
i]

PRINCIPLE 79
USE EFFICIENT ALGORITHMS
Knowledgeof the theory of algorithm complexity is an absolute prerequi- site for being a good designer. Givenanyspecific problem, you could specify an infinite numberofalternative algorithmsto solve it. The theory of
“analysis of algorithms” provides us with the knowledge of howtodifferentiate between algorithmsthat will be inherently slow (regardless of how
well they are coded) and those that will be orders of magnitude faster.
Dozensofexcellent books exist on this subject. Every good undergraduate
computerscience program will offer a course onit.
Ref: Horowitz, E., and S. Sahni, Fundamentals of Computer Algorithms, Potomac, Md.:


ComputerScience Press, 1978.
2

PRINCIPLE 80
MODULE SPECIFICATIONS PROVIDE ALL THE INFORMATION THE
USER NEEDS AND NOTHING MORE
Akeypart of the design processis the precise definition of each and every software componentin the system.This specification will becomethe “vis- ible” or “public” part of the component.It must include everything a user* needs, such as its purpose,its name, its method of invocation, and details of how it communicates with its environment. Anythingthat the user does not need should bespecifically excluded. In mostcases, the algorithms and internal data structures used should be excluded. For if these were “visi- ble,” users might utilize this information. Subsequent enhancement or modification then becomes profoundly moredifficult because any change to the componenthasa cascadingeffect on all componentsthatuseit. See related Principle 65 on encapsulation.
Ref: Parnas, D., “A Technique for Software Module Specification with Examples,”
Communications of the ACM, 15, 5 (May 1972), pp. 330-336.
“Inthis case, a “user” means another software componentor a programmer of another
 ———
component.
3

PRINCIPLE 81
DESIGN 1S MULTIDIMENSIONAL
When designing a home, architects represent it in many ways to fully understand and conveyits essence to builders, buyers of materials, and
homebuyers: elevations, floor plans, framing,trusses, electrical routing,
plumbing routing, concrete shape, door and window framing details, and
other points of view. The sameis true for software design.
Acomplete software design includesatleast:
1. Packaging. Often drawnasa hierarchy chart, this captures “whatis part
of what?” It often implies data visibility. It also shows encapsulation,
such as data and functions within objects.
2. Needs hierarchy. This captures “who needs whom?” Drawnas a network
of components, arrowsindicate which components need something. The
needs might be data, logic, or any other information.
3. Invocation. This captures “who invokes whom?” Drawnas a network of components,arrows indicate which components “call,” “interrupt,” or
“send messages to” others.
4. Processes. Sets of components are packaged together as asynchronous
processes, These are copies of components that are running simultaneously with other processes. Zero, one, or more copies mayexist at one
time. This should also specify conditions that cause a processto be created, executed, stopped, and destroyed.
Ref: Witt, B., F. Baker, and E. Merritt, Software Architecture and Design, NewYork: Van
EEE
Nostrand Reinhold, 1994, Section 1.1.
K

PRINCIPLE 82
GREAT DESIGNS COME FROM GREAT DESIGNERS
Thedifference between a poor design and a good design maybetheresult
of a sound design method, superior training, better education,or other factors. However, a really great design is the brainchild of a really great
designer. Great designsare clean, simple, elegant, fast, maintainable, and
easy to implement. Theyarethe result of inspiration and insight, not just
hard work or following a step-by-step design method. Invest heavily in
yourbest designers. They are your future.
Ref: Brooks, F, “No Silver Bullet: Essence and Accidents of Software Engineering,”

IEEE Computer, 20, 4 (April 1987), pp. 10-19.
5

PRINCIDLE 83
ANOW YOUR APPLICATION
No matter how well the requirements have been written, the selection of
optimalarchitectures andalgorithms is very much a function of knowing
the unique characteristics of an application. Expected behavior understress
situations, expected frequency of inputs, life-critical nature of response times, likelihood of new hardware, impact of weather on expected system
performance, and so on areall application-specific and often demand a
specific subset of possible alternative architectures and algorithms.
Ref: Curtis, B., H. Krasner, and N. Iscoe, “A Field Study of the Software Design
Process for Large Systems,” Communications of the ACM,31, 11 (November 1988),


pp. 1268-1287.
%

PRINCIPLE Bh
YOU CAM REUSE WITHOUT A BIG INVESTMENT
Chancesare that the most effective way to reuse software components is
from
a
repository ofcrafted, hand-picked itemsthat weretailored specifically for reuse. However, this requires considerable investment in both
time and money.It is possible to reuse in the short term through a tech- nique called salvaging, Simply stated, salvaging is asking othersin the organization, “Have you ever built a software componentthat does x?” You
find it, you adaptit, you employit. This maynotbeefficient in the long
term, butit certainly works now; and then you have no more excuses not
to reuse.
Ref: Incorvaia, A. J., A. Davis, and R. Fairley, “Case Studies in Software Reuse,” Fourteenth IEEE International Conference on Computer Software and Applications,
Washington, D.C.: IEEE Computer Society Press, 1990, pp. 301-306.
 

PRINCIPLE 85
“GARBAGE IH, GARBAGE DUT” 15 INCORRECT
Manypeople quote the expression “garbage in, garbage out”as if it were acceptablefor software to behavelikethis. It isn’t. If a user provides invalid input data, the program should respond with an intelligent message that describes why the input wasinvalid. If a software componentreceives
invalid data, it should not processit, but instead should return an error code back to the componentthat transmitted the invalid data. This mind- set helps diminish the dominoeffect caused by software faults and makes it easier to determineerrorcauses by (1) catchingthe fault early and (2) pre- venting subsequent data corruption.
aS,
Ref: McConnell, S., Code Complete, Redmond, Wash.: Microsoft Press, 1993, Section 5.6.
5%

PRINCIPLE 86
SOFTWARE RELIABILITY (AN BE ACHIEVED THROWGH REDUNDANCY
In hardware systems, highreliability or availability (Principle 57)is often
achieved through redundancy. Thus,if a system componentis expected to
exhibit a mean-time-between-failures of x, we can manufacture two or
three such componentsand run them in either:
1. Parallel. For example, theyall doall the work and, when their responses
differ, one is turned off with no impacton overall system functionality.
2. Or cold standby. A backup computer might be powered on only when a
hardwarefailure is detected in the operational computer.
Manufacturing cost is slightly more than doubled. Design cost increases
slightly. Reliability increases exponentially.
In software systems, we cannot use the same approach. If we make
two copiesof the samesoftware, noincreaseinreliability will be achieved.
If onefails, the other will as well. What can be done, however,is to design
(using two different design teams) two versionsof the software from the
same requirements specification, and deploy them inparallel. Developmentcost doubles. Reliability increases exponentially. Notice that, in the
case of hardware, design increases in cost only slightly, whereas software
design cost (the primary cost of software) doubles. Ultrahighreliability in
softwareis very expensive. (Principle 4.)
Ref: Musa,J., A. Iannino, and K. Okumoto, Software Reliability, New York: McGraw-

Hill, 1987, Section 4.2.2.
—————————
—
9
 

CODING PRINCIPLES
Codingis thesetof activities including:
1. Translating the algorithmsspecified during design into programswritten in a computer language.
2. Translating, usually automatically, the programsinto a language directly executable by a computer.
The primary output of coding is a documented programlisting.

i

PRINCIPLE 87
AVOID TRICKS
Many programmers love to create programs withtricks. These are con- structs that perform a function correctly, butin a particularly obscure manner. Typically, they use a side-effect of a function to implement a primary
function. Programmerssee these as “clever,” but, as Allen Macro points
out, they “are often merely the stupid use of high intelligence.” There are many waysto explain whytricks are used so often:
1. Programmers are extremely intelligent and want to demonstrate that intelligence.
2. Maintainers, when theyfinally figure out how the trick works, will not
only recognize how smart the original programmer was, but also will
realize how smart they themselvesare.
3. Job security.
Bottom line: Show the world how smartyouare byavoidingtricky code!
Ref: Macro, A., Softeare Engineering: Concepts and Management, EnglewoodCliffs, N.J.

ell
Prentice-Hall International, 1990, p. 247.
m
PRINCIDLE 88
AVOID GLOBAL VARIABLES
Global variables make it convenient to write programs; after all, if you
need to access or change x, you just do it. Unfortunately, if x is ever
accessed and found to have an inappropriate value (say, -16.3 ships), it is
difficult to determine which software componentis at fault. “Global”
implies that anybody could havealtered its value incorrectly.
As an alternative, encapsulate important data in its own module
(Principle 65), so that anybody who wants to changeit or access it must do so by meansof that routine. Alternatively, explicitly pass parameters to
routines that need specific data. If you find an excessive numberof parameters, perhaps your design needsto be reworked.
Ref: Ledgard, H., Programming Practice, Vol. II, Reading, Mass.: Addison-Wesley, 1987,

Chap. 4.
1B

PRINCIPLE 89
WRITE 10 READ TOP-DOWK
People generally read a program from top(i.e., first line) to bottom (ie., last line). Write a program to help the reader understandit.
Amongtheimplicationsofthis principle are:
1. Include a detailed external specification up front to clearly define the
program purpose anduse. 2. Specify externally accessed routines, local variables, and algorithms up front.
3. Use the so-called “structured” programming constructs, which are
inherently easier to follow.
Ref: Kernighan, B., and P. Plauger, The Elements of Programming Style, New York:

McGraw-Hill, 1978, pp. 20-37.
Ih

PRINCIPLE 90
AVOID SIDE-EFFECTS
side-effect of a procedure is something the procedure doesthatis notits
main purpose andthatis visible (or whose results are perceivable) from
outside the procedure. Side-effects are the sources of many subtle errors in
software,thatis, the onesthat are the mostlatent and the ones that are most
difficult to discover once their symptoms manifest themselves.
Ref: Ledgard, H., Programming Proverbs, Rochelle Park, N.J.: Hayden Book Company,

EEE
1975, Proverb 8.
Is

PRINCIPLE 91
USE MEANINGFUL HAMES
Some programmersinsist on naming variables with nameslike N_FLT, or worse, like F. The usual argumentis that it makes programmers more pro- ductive because of reduced key presses. Good programmers should spend
a very small percentageoftheir time typing (maybe10 to 15 percent); most time should be spent thinking. So how muchtimeis really being saved? But an even better argument is that overly shortened names actually decrease productivity. There are tworeasons:(1) Testing and maintenance
costs rise because people spend time trying to decode names, and (2) more time could be spent typing when using shortened names! The second argumentis true because of the necessity to add comments. For example,
N_FLT = N_FLT+1
needs a comment“LOOKATNEXT FLIGHT” (32 keypresses), but
NEXT_FLIGHT = PREVIOUS_FLIGHT+1
needs no such comment(29 keypresses).
Ref: Ledgard, H., Programming Proverbs, Rochelle Park, N.J.: Hayden Book Company,

1975, pp. 94-98.
106

PRINCIPLE 92
WRITE PROGRAMS FOR PEOPLE FIRST
In the early days of computing, computers were relatively slow. Almost
anything that could be done to shaveoff a few instructions was worththe
effort. The mostefficient use of any of the resources on the very expensive
computer system wasthe major goal. Things have changed. The most valuable resource is now labor: labor to develop the software, labor to maintain
the software, and labor to enhance capability. With few application exceptions, programmersshould thinkfirst of the people whowill later attempt
to understand and adaptthe software. Anything that can be done to assist them should be done(Principles 87 through 91 offer somehelp). Efficiency
is also important (Principles 63, 79, and 94), but they are not mutually
exclusive. If you need efficiency, that’s fine, but upgrade the readability of
your program so that you don’t lose the humansin the process.


Ref: McConnell, S., Code Complete, Redmond, Wash.: Microsoft Press, 1993, Section 32.3.
0
PRINCIPLE

93
USE OPTIMAL DATA STRUCTURES
Thestructure of data and the structure of programs manipulatingthat data
are intimately interrelated. If youselect the right data structures, your algorithms (and thus your code) become easy to write, and easy to read, and
therefore easy to maintain. Read any book on algorithmsor on data structures (they’re one andthe same!). Whenpreparing to write a program, you should develop the algo- rithmsanddatastructures together. Try two orthree or moredifferent pairs
before you select the best one. And besure to encapsulate the data structure in one component(Principle 65) so that, when you later find a better
structure, you can changeit easily.
Ref: Kernighan, B, and P. Plauger, The Elements of Programming Style, New York:

McGraw-Hill, 1988, pp. 52, 67.
106

DRINCDLE 94
GET IT RIGHT BEFORE YOU MAKE IT FASTER
It is far easier to adapt a working program to makeit run faster than to
adapt a fast program to make it work. Don’t worry about optimization
whendoingyourinitial coding. [On the other hand, don’t use a ridiculously inefficient algorithm orset of data structures (Principles 79 and 93).]
Everysoftwareproject has tough schedule pressures. Some maynot
be very pressured during their early phases, but even they step up the pace
later. Given this situation, anytime a componentis produced on (or ahead
of) time and it worksreliably, it is cause for celebration. Try to be the reason for celebration rather than desperation.If you get your program work- ing (however slowly it runs), everybody on yourteam will appreciateit. See related Principle 34.
Ref: Kernighan, B., and P. Plauger, The Elements of Programming Style, New York:

McGraw-Hill, 1978, pp. 124-134.
——————
i

PRINCIPLE 95
COMMENT BEFORE YOU FINALIZE YOUR CODE
I've often heard programmerssay, “Why should I bother commenting my
code now?It'll only change!” We comment code to makethe software easi- er to debug,test, and maintain. By commenting your code while coding (or
beforehand,see Principle 96),it will be easier for you to debugthesoftware. As you debug yoursoftware, you will undoubtably find flaws. If a
flaw is in your conversion from the algorithm to the code, you'll need to
change only the code, not the comments.If the flaw is in your algorithm, you'll need to change both the comments and code. But how would you even know you had an algorithmicerror unless you had comments?
Ref: Kernighan, B., and P. Plauger, The Elements of Programming Style, New York:

McGraw-Hill, 1978, pp. 141-144.
1

DRINCIDLE 96
DOCUMENT BEFORE YOU START CODING
This advice will seem strange to somereaders, but it becomesnaturalafter
being practiced for a while. Principle 95 explained why you should documentyour code beforefinishingit. Principle 96 goes onestep further: You
should document your codebefore starting to code!
After performing detailed design on a component[that is, document- ing its externalinterface andits algorithm(s)], write your in-line comments.
Mostofthese in-line commentswill be nothing other than the previously documented interface and algorithm. Put these comments through the compiler to make sure you haven't done anythingsilly (like omitting a
comment delimiter). Then convert each line of comment into a corresponding program segment.(Note: If you end up with oneline of program
per comment, you probably specified your algorithm with too much detail.) You'll find debugging goesa lot smoother.
Ref: McConnell, S., Code Complete, Redmond, Wash.: Microsoft Press, 1993, Sections

eee
42-44,
Nl

PRINCIPLE 97
HAND-EXECUTE EVERY COMPONENT
It might take 30 minutesto execute a software componentby hand with a
few simpletest cases. Doit! 1 am suggestingthis in additionto,notin liew
of, the more thorough computer-based unit testing that is already being
performed. Whatis the cost? Just 30 minutes. What is the alternative? Save
30 minutes now, proceed with unit, integration, and system testing. The
system fails. Three to four person days are spenttrying to isolate the cause
of the failure. A half-dozen componentsareisolated as possible candidates.
Each is given to its developers for further examination. Each candidate spends 30 minutes executing the component by hand with a fewsimple test cases. In short, 30 minutesare less than three to four person days plus
6 x 30 minutes.
Ref: Ledgard, H., Programming Proverbs, Rochelle Park, N.J: Hayden Book Company,

1975, Proverb 21.
n

PRINCIPLE 98
INSPECT CODE
Inspection of software detailed design and code wasfirst proposed by Michael Fagan in his paper entitled “Design and Code Inspections to
ReduceErrors in Program Development”[IBM Systems Journal, 15, 3 (July
1976), pp. 182-211]. It can account for as many as 82 percentofall errors found in software. Inspection is much better than testing for findingerrors.
Define criteria for completing an inspection. Keep track of the types of errors found through inspection. Fagan’s inspections consume approximately 15 percent of developmentresources with a net reduction in total
developmentcostof 25 to 30 percent.
Your original project schedule should accountfor the time to inspect (and correct) every component. You might think that your project cannot
tolerate such “luxuries.” However, you should not consider inspection a
luxury. Data has shownthat you can even reducethe timeto test by 50 to
90 percent.If that’s not incentive, I don’t know what could be. By the way, there is a wealth of support data andtips on howto do inspections well in
the referenced book.
Ref: Grady, R., and T. VanSlack, “Key Lessons in Achieving Widespread Inspection

Use,” IEEE Software, 11, 4 (July 1994), pp. 46-57.
_——————
B

PRINCIPLE 99
YOU CAH USE UNSTRUCTURED LANGUAGES
Unstructured code violates Edsger Dijkstra’s guidanceto restrict control
structures to IF-THEN-ELSE, DO-WHILE, DO-UNTIL, and Case. Notice that it is
possible to write structured code in languages without these structures,
such as in assembly languages, by documenting the code with the structured control statements andrestricting the use of Goro’s to implementing these structures only.
To do this,first write your algorithmsusingthe control structures preceding. Next, convertthese into in-line comments. Next,translate the commentsinto their equivalent programminglanguage statements. GoTO’s will appear, but they will be implementingthe better constructs and will facilitate, not hamper, readability, maintainability, and provability.

Ref: McConnell, S., Code Complete,Redmond, Wash.: Microsoft Press, 1993, Section 17.6.
Ih

PRINCIPLE 100
STRUCTURED CODE 1S NOT NECESSARILY GOOD CODE
The original definition of structured programming presented by Edsger Dijkstra was providedto facilitate program proving. The constructs he rec- ommended(IF-THEN-ELSE, DO-WHILE, etc.) have now become so common- place (though program provinghas not) that their use is now called “pro- gramming”rather than “structured programming.”It is importantto note, however, that notall “structured” programs are good. One can write incredibly obscure programsthatare still structured. Structure is almost a
necessary, but far from a sufficient, condition for quality programming.
Ref: Yourdon, E., How to Manage Structured Programming, New York: Yourdon, Inc.,
———
1976, Section 5.2.2.
Ib

PRINCIDLE 101
DON'T NEST 100 DEEP
Nesting IF-THEN-ELSE statements greatly simplifies programming logic. On
the other hand, nesting them morethan,say, three levels decreases their
understandability considerably. The human mind is capable of remember- ingonly a certain amountoflogic before it becomes confused. A variety of
simple techniques can be used to reduce nesting. See the following reference for examples andtechniques.
—

Ref: McConnell, S., Code Complete, Redmond, Wash.: Microsoft Press, 1993, Section 17.4.
Ns

PRINCIPLE 102
USE APPROPRIATE LANGUAGES
Programming languagesvary greatlyintheir ability to help you do your job. Yourspecific project or productgoals will often dictate the appropriate language. The following guidelines are meantto be just that—guidelines, not gospel.
If your numberonegoalis portability, then use a language that has been demonstrated to be highly portable (such as C, FORTRAN, or COBOL).If your numberonegoalis fast development, then use a language that aids in such fast development (4GL’s, Basic, APL, C, C++, or SNOBOL). If your number onegoalis low maintenance, then use a lan- guage with manybuilt-in, quality-inducing features (such as AdaorEiffel). If your application requires a great use of characterstrings or complex data structures, select a language that supports them.If your product must be maintainedbyagroupofexisting maintainers who know languageX, then use language X. Finally, if your customer says, “Thou shalt use language Y,” then use language Y or you won'tbein business long.
Ref: McConnell, S., Code Complete, Redmond, Wash.: Microsoft Press, 1993, Section 3.5.
—————
eee
 

PRINCIPLE 103
PROGRAMMING LANGUAGE 15 KOT AN EXCUSE
Someprojects are forced to use a less-than-ideal programming language.
This might be caused by a desire to reduce maintenancecosts (“All our
maintainers know COBOL”), to program fast (“We have the highest productivity with C”), to ensure high reliability (“Ada programsare the most fail-safe”), or to achieve high execution speed (“Our applications are so
time-critical, we need to use assembly language”).It is possible to write
quality programsin any language.Infact, if you are a good programmer,
you should be a good programmerin any language(Principle 104); a lessthan-ideal language might make you work harder, though.
Ref: Yourdon, E., How to Manage Structured Programming, New York: Yourdon, Inc.,
eS
1976,

Section 5.2.5.
IB

PRINCIPLE 104
LANGUAGE HNOWLEDGE 1S NOT SO IMPORTANT
Good programmersare good regardless of the language used. Poor programmers are poor regardless of the language used. Nobodyis a “great C
programmer” and a “poor Ada programmer.” If they really are poor at
Ada, they probably were notgreat at C! In addition, a really good programmer should be able to learn any new languageeasily. This is because a really good programmerunderstands and appreciates the concepts of
quality programming,notjust the syntactic and semantic idiosyncrasies of
some programming language.
So the primary driver of language selection for a project should be
appropriateness (Principle 102), not the surge of programmers who whine,
“But all we know is C.” If some quit because the projectselected a different
language, the project is probably better off!
Ref: Boehm,B., Software Engineering Economics, EnglewoodCliffs, N.J.: Prentice Hall,

1981, Section 26.5.
Wy

PRINCIPLE 105
FORMAT YOUR PROGRAMS
The understandability of a program is greatly enhanced by using standard
indentation protocols. Which protocol you choose to follow matterslittle,
but, once youselectit, use it consistently.
I follow the rule of keeping THEN’s andELsk’s directly below their correspondingIF’s, END’s directly below the BEGIN’s or DO’s they correspondto,
andso on. Thus,
IF
THEN BEGIN


END
ELSE IF
THEN___ ELSE,
DO WHILE ()
END DO;
See lots more examplesin the reference. By the way, the only thing worse
than inconsistentindentationsis incorrect indentation(like aligning an ELSE
with the wrongIF or THEN)! To prevent accidental misalignments, use any
commercially available pretty printer.


Ref: McConnell, S., Code Complete, Redmond, Wash.: Microsoft Press, 1993, Chapter 18.
0

PRINCIPLE 106
DONT CODE TOO SOON
Codingsoftware is analogousto constructing a building. Both require much
preliminary work. Constructing a building withouta solid and stable concrete foundation will not work. Coding withouta solid and stable foundation of requirements and design will not work. Think about how much more difficult it is to modify a building after the foundation is poured!
Don’t be coerced into coding prematurely because management
wants to see “progress.” Be sure the requirements and design are correct and appropriate before baselining them andcertainly before coding the final product. Incidentally, don’t conclude from this principle that prototyping is bad (Principles5, 10, 11, 12, and 13). There is nothing wrong with
experimenting with coding long before requirements are baselined. Just
don’t considerit the final product. Manny Lehman addsa counterpoint to
this principle: Don’t code toolate!
Ref: Berzins, V., and Luqi, Software Engineering with Abstractions, Reading, Mass.:


Addison-Wesley, 1991, Section 1.5.
n
 

TESTING PRINCIPLES
Testing is a set of activities including:
1.NQO
Performingtests on individual software components(thatis, unit testing) to concludethatthey are sufficiently close to behavingas specified
in the component's design specification.
. Performingtests on sets of unit-tested components(integration testing)
to concludethat they behaveas a team in a mannerclose enough to how
they werespecified in the design.
. Performing tests on the entirely integrated set of software components
(software systems-level testing) to conclude that they behaveas a system
in a mannersufficiently close to that specified in the software requirementsspecification.
. Generatingtest plans for software systems-leveltesting.
. Generating test plansfor software integration testing.
. Generating test plans for unit testing.


. Building test harnesses and test environments.
B
PRINCIPLE 107
TRACE TESTS 10 REQUIREMENTS
It is important to understand whichtests verify which requirements. There
are two reasons:(1) Whengenerating tests, you'll find it useful to know if
all requirementsare being tested. (2) When performingtests, you'll find it
useful to know which requirements are being checked. Furthermore, if
your requirements have been prioritized (Principle 50), you can easily
derive therelativeprioritiesoftests; that is, the priority of a test is the maximum of the prioritiesofall its corresponding requirements. Maintainalarge binary table in which rowscorrespondto all software
tests and columnscorrespond to every requirement in the SRS. A1 in any
position indicates thatthis test helps to verify this requirement. Notice that
a row void of 1's indicates that a test has no purpose andthat a column
void of 1’s indicates an untested requirement. The successful creation of
such a table dependson yourability to refer uniquely to every requirement
(Principle 52).
Ref: Lindstrom, D., “Five Ways to Destroy a Development Project,” IEEE Softivare, 10, 5 (September 1992), pp. 55-58
th

PRINCIPLE 108
PLAN TESTS LONG BEFORE IT 15 TIME 10 TEST
Often software developerscreate their software product, thenscratch their heads and say, “Now, howare we goingto test this thing?” Test planning is a major task and mustoccurin parallel with product development so that test planning andinitial(thatis, pretesting) developmentactivities are completed in synchrony.
For software system testing, test planners should review the SRS for testability beforeit is baselined and provide feedback to requirements writ- ers. Serious developmentof the tests should start soon after baselining requirements.For integration testing, test planners should review the pre- liminary design before it is baselined. They should also provide feedback to the project managers and designers concerning(1) sensibleallocations of resources to ensure that the “right” components (from a testing point of view) are producedin the right order and (2) modificationsto the design to makeit inherently easier to test. Serious integration test development should start soonafter baselining the preliminary design. For unittesting, unit test plan developmentcanstart immediately after the completionof detailed design.
Ref: Goodenough,J., and S. Gethart, “Toward a Theory of Test Data Selection,” IEEE

Transactions on Software Engineering, 1, 2 (June 1975), pp. 156-173, Section IIIC.
———————
wb

PRINCIPLE 109
DON'T TEST YOUR OWN SOFTWARE
Software developers should never bethe primarytestersoftheir ownsoftware.It is certainly appropriate to doinitial debugging and unit testing. [For an opposing view, see Mills, H., et al., “Cleanroom Software
Engineering,” in IEEE Software, 4, 5 (September 1987), pp. 19-25.]
Independenttesters are necessary:
1. To check a unit for adequacy before starting integration testing.
2. Forall integration testing.
3. For all software system testing.
Thecorrectattitude duringtesting is that of wanting to expose bugs. How
can a developer possibly embracethat attitude? Testing is difficult enough
without burdeningit further with testers who have a bias toward not finding bugs.

Ref: Myers, G., The ArtofSoftware Testing, New York: John Wiley& Sons, 1979, p. 14.

PRINCIPLE 110
DON'T WRITE YOUR OWN TEST PLANS
Notonly should you not test your ownsoftware (Principle 109), but you
should also not be responsible for generating the test data, test scenarios, ortest plans for your software.If you are, you may make the same mistakes
in test generation that you madein softwarecreation. For example,if you madea false assumption aboutthe rangeoflegal inputs when engineering
the software, you would likely make the same assumption when generating test plans. If you are a programmer and/or designer and your manager has
asked you to write yourtest plans, I recommend you switch the test plan
generation responsibility with a fellow programmer and/or designer. If
you are a memberof a requirements engineering team, with responsibility
for system test generation as well, recommendthat membersof your team
subdivide the responsibilities so that no individual generates tests for requirementsthatsheor he wrote.
———
Ref: Lehman, M., private communication, Colorado Springs, Col.: (January 24, 1994),
W

PRINCIDLE THI
TESTING EXPOSES PRESENCE OF FLAWS
Nomatter how thorough,testing simply exposesthe presenceofflaws ina
program;it cannotbe used to verify the absenceofflaws. It can increase
your confidence that a program is correct, but it cannot prove correctness.
To gain true correctness, one must use completely different processes, that
is, correctness proofs.
Ref: Dijkstra, E., “Notes on Structured Programming,” in Structured Programming,

Dahl, O,, et al., eds., New York: Academic Press, 1972.
8

PRINCIPLE TI2
THOUGH COPIOUS ERRORS GUARANTEE WORTHLESSHESS, ZERO
ERRORS SAYS HOTHING ABOUT THE VALUE OF SOFTWARE
This is Gerald Weinberg’s “AbsenceofErrors Fallacy.” It really puts testing into perspective.It also puts all software engineering and management
into perspective. Thefirst part of the principle is obviously true; software
with manyerrorsis useless. The second part provides food for thought. It
says that, no matter howhard you workto removeerrors, you are wasting
yourtime unless you are building the right system. Akao’s Quality Function
Deployment (Cambridge, Mass.: Productivity Press, 1990) provides details on one methodofensuringthat you arebuildingthe right system through- out thelife cycle. Acorollary to this principle is that all the formal methods,
all the testing, andall the product assurancein the world won't helpif you
are building the wrong system.
Ref: Weinberg, G., Quality Software Management, Vol. 1: Systems Thinking, New York:
—
OOOO
Dorset House, 1992, Section 12.1.2.
w

PRINCIDLE 113
A SUCCESSFUL TEST AAAS AN ERROR
Thaveoften heard a tester gleefully declare, “Great news! My test was suc- cessful. The program ran correctly.” This is the wrongattitude to have when running a test. [It also supports the position that programmers should nevertest their own software (Principle 109).] A more constructive attitudeit that one is testing tofind errors. Thus,a successfultest is one that detects an error. Look at the analogoussituation with a medical test. Supposeyouarefeelingill. The physician sends a sample of your blood to laboratory. A few dayslater, the physician calls to tell you, “Great news! Your blood was normal.” That is not great news. You are sick or you wouldn’t have goneto the physician. A successfulblood test reports what’s wrong with you. The software has bugs (or you wouldn’tbetestingit). A
successful test reports how these bugs manifest themselves. Whengeneratingtestplans, you shouldselect tests based on the like- lihood that they will find faults. Whentesting software,the testing group should be evaluated on how well they find errors, not on how well they don’t.
Ref: Goodenough,J., and S. Gerhart, “Toward a Theoryof Test Data Selection,” IEEE
 Se
Transactions on Software Engineering, 1, 2 (June 1975), pp. 156-173.
Bo

PRINCIPLE T14
HALE THE ERRORS FOUND IN 15 PERCENT OF MODULES
Conservative estimates indicate that, in large systems, approximately half
of all software errors are found in 15 percent of the modules, and 80 percent ofall softwareerrorsare found in 50 percentof the modules. More dramatic results from Gary Okimoto and Gerald Weinberg indicate that 80
percentof all errors were foundinjust 2 percentof the modules (see Section 13.2.3 of Weinberg’s Quality Software Management,Vol. 1: Systems Thinking,
New York: Dorset House, 1992). Thus, whentesting software, you might
considerthat, where you find errors, you will probably find more.
Maintain logsnotonly of how manyerrorsare found per time period
for the project, but also how manyerrorsare found per module. Whenhistory shows a moduleto be highly error-prone, you are probably better off
rewriting it from scratch, with an emphasis on simplicity (Principle 67)
rather than cleverness.
Ref: Endres, A., “An Analysis of Errors and Their Causes in System Programs,” IEEE
Transactions onSoftware Engineering, 1, 2 (June 1975), pp. 140-149.
————
i
—™"
Bl

PRINCIPLE 115
USE BLACK BOK AND WHITE-BOX TESTING
Black-boxtesting usesthespecification of a component's external behavior as its only input. It is mandatory to determineif the software does whatit is supposed to do and doesn’t do whatit is not supposed to do. White-boxtest- ing usesthecodeitself to generatetest cases. Thus white-boxtesting might demand, for example,thatall paths through the program of length 50 instructions or less be taken (Principle 122). Be aware, however, that even with both black-box and white-box testing, testing can make useof only a
small subsetof possible data values from the input domain (Principle 111). To demonstrate how black-box and white-box testing complement each other, let’s look at an example. Let’s say a procedure’s specification statesthatit should print the sum of all numbersinan input list. When pro- grammed,it looksfor one inputof 213 and, if it finds it, sets the sum equal to zero. Since that was notin the specification, there is no waytofind the error by black-box testing except by accident(that is, selecting a random test case that happensto include a 213). White-box testing would demand that paths are more adequately tested, and thus would probably detect the “213”situation. By combining black-box and white-box, you maximize the effectivenessoftesting. Neither onebyitself does a thoroughtest.
Ref: Dunn,R., Software Defect Removal, New York: McGraw-Hill, 1984, Section 7.4.
Se
HH
_
B

PRINCIPLE 116
A TEST CASE INCLUDES EXPECTED RESULTS
Documentation for a test case mustincludethe detailed description of the
expectedcorrectresults.If these are omitted, there is no wayforthe tester
to determine whether the software succeeded or failed. Furthermore, a
tester may assess an incorrect result as correct becausethere is always a
subconsciousdesire to see a correct result. Even worse, a tester may S
a correct result as incorrect, causing a flurry of designer and coderactivity
to “repair” the correct code.
Develop an organization standard for test plans that demands the
documentation of expected intermediate andfinal test case results. Your
quality assurance organization should confirmthatall test plans conform
to the standard.



Ref: Myers, G., The Artof Software Testing, New York: John Wiley & Sons, 1979, p. 12.

PRINCIPLE 117
TEST INVALID INDUTS
It is natural and common to producetest cases for as many acceptable
input scenarios as possible. Whatis equally important—but also uncommon—is to produce an extensive set of test cases forall invalid or unex- pected inputs.
For a simple example,let us say weare writing a programtosortlists
of integers in the rangeof0 to 100. Testlists should include some negative numbers,all the same numbers, some nonintegral numbers, some alphabetic data, some null entries, and so on.
Ref: Myers, G., The Art of Software Testing, New York: John Wiley & Sons, 1979, p. 14.

Bh

PRINCIPLE 118
ALWAYS STRESS TEST
Software design often behavesjust fine when confronted with “normal” loadsofinputsorstimuli. Thetrue test of software is whetherit can stay operational when faced with severe loads. These severe loads are often stated in the requirements as “maximum of x simultaneous widgets” or “maximum of x new widget arrivals per hour.”
If the requirements state that the software shall handle up to x wid- gets per hour, you mustverify that the software can dothis. In fact, not only should you testthat it handles x widgets, you should also subject the
software to x+1 or x+2 (or more) widgets to see what happens (Principle 58). After all, the system may not be able to control its environment, and you do not want the software to crash when the environment “misbe- haves” in an unexpected manner.
Ref: Myers, G., The Art of Software Testing, New York: John Wiley & Sons, 1979, pp.
eee
113-114.
BS
PRINCIPLE

119
THE BIG BANG THEORY DOES HOT APPLY
Asa projectnearsits delivery deadline and the softwareis not ready, desperation often takes over. Suppose the schedule called for two monthsof
unit testing, two monthsofintegration testing, and two months of software
system testing.It is now one month from the scheduled delivery. Suppose
50 percent of the components have been unit-tested. A back-of-the-envelope calculation indicates that you are five months behind schedule. You
have twochoices:
1. Admit the five-month delay to your customer: Ask for a postponement.
2. Put all the components together (including the 50 percent not yet unittested) and hopeforthe best.
In thefirst case, you are admitting defeat, perhaps prematurely.In the eyes
of your managers, you mightbe giving up before you've done everything
in your powerto overcomethe problem.In the secondcase, there might be a .001 percent chancethat, when you putit all together, it will work and
you'll be back on schedule. Project managers often succumbto thelatter
becauseit looks like they are trying everything before admitting defeat.
Unfortunately, this will probably add six more months to your schedule.
You cannotsave time by omitting unit andintegration testing.
Ref: Weinberg, G., Quality Software Management, Vol. 1: Systems Thinking, NewYork:

——
Dorset House, 1992,Section 13.2.3.
36

PRINCIPLE 120
USE MCCABE COMPLERITY MEASURE
Although many metrics are available to report the inherent complexity of
software, none is as intuitive and as easy-to-use as Tom McCabe's cyclomatic number measureoftesting complexity. Althoughnotabsolutely foolproof, it results in fairly consistent predictionsoftesting difficulty. Simply
draw a graphof your program,in which nodes correspond to sequencesof
instructions and arcs correspond to nonsequential flow of control.
McCabe's metric is simply e-n+2p where e is the numberofarcs, n is the
number of nodes, and p is the number of independent graphs you are
examining (usually 1). This metric can also be “calculated” by the cookie cutter analogy: Imaginepressing a cookie cutter shapedlike the program
graph intorolled-out dough. The numberof cookies produced(the number
of regions in the graph)is the same as e-n+2p. This is so simple that there
is really no excuse nottouseit. Use McCabe on each moduleto help assess unit testing complexity.
Also,useit at the integration testing level where each procedureis a node
and each invocation path is an arc to help assess integration testing
complexity.
Ref: McCabe, T., “A Complexity Measure,” IEEE Transactions on Software Engineering, 2,

12 (December1976), pp. 308-320.
————————
B

PRINCIDLE 121
USE EFFECTIVE TEST COMPLETION MEASURES
Manyprojects proclaim the end of testing whenthey run out of time. This may makepolitical sense, but it is irresponsible. During test planning, define a measure that can be used to determine whentesting should be completed.If you have not met your goal when timeruns out, you canstill makethe choice of whetherto ship the productorslip the milestone, but at least you know whether you are shipping a quality product. Twoideasfor this effective measurement of test progress are:
1. Rate of new error detections per week.
2. After covertly seeding the software with known bugs(called bebugging by Tom Gilb), the percentageof these seeded bugs thus far found.
An ineffective measure of test progress is the percentageoftest cases cor- rectly passed (unless, of course, you knowthat the test cases are a superb coverof the requirements).

Ref: Dunn,R., Software Defect Removal, New York: McGraw-Hill, 1984, Section 10.3.

PRINCIPLE 122
ACHIEVE EFFECTIVE TEST COVERAGE
In spiteofthe fact that testing cannotprovecorrectness,it is still important
to do a thoroughjoboftesting. Metrics exist to determine how thoroughly
the code wasexercised during test plan generationortest execution. These
metrics are easy to use, and tools exist to monitor the coveragelevel of
tests. Some examples include:
1. Statement coverage, which measures the percentage of statements that
have beenexecutedatleast once.
2. Branch coverage, which measures the percentage of branchesin a program that have been executed.
3. Path coverage, which measures how well the possible paths (usually
infinite) have beenexercised.
Just rememberthat, although “effective” coverageis better than no coverageatall, do notfool yourself into thinking that the program is “correct”
by any definition (Principle 111).
Ref; Weiser, M., J. Gannon,and P. McMullin, “Comparisonof Structural Test Coverage
oO
i
Metrics,” IEEE Software, 2, 2 (March 1985), pp. 80-85.
eeSS
B

DRINCIDLE 123
DON'T INTEGRATE BEFORE UNIT TESTING
Under normal circumstances components are separately unit-tested. As they pass their unit tests, a separate organization integrates them into meaningfulsets to exercise their interfaces. Components that have not been separately unit-tested are often integrated into the subsystem in a vain attemptto recapture a lost schedule. Such attempts actually cause more schedule delays. This is becausea failure of a subsystem to satisfy an inte- gration test plan may be caused noweitherby a fault in the interface or by
a
faultin the previously untested component. And muchtimeis spenttry- ing to determine whichis the cause. If you are managing a project, you can doa variety of things to avoid this situation. First and foremostis to develop an integrationtest plan early (for example, very soon after high-level design is complete). This plan should specify which components are most importantto integratefirst and in whatorder components maybe integrated. Once you have written this down,allocate appropriate resources to coding and unit testing of specific high-priority componentsto ensurethatintegration testers don’t spend an inordinate amountoftimeidle. Second,as it becomesevidentthat impor- tant components for integration testing are going to be unavailable as needed, havethe integration testers start developing temporaryscaffolding software to simulate the missing components.
SS
Ref: Dunn,R,, Software Defect Removal, New York: McGraw-Hill, 1984, Section 7.2.

10

PRINCIPLE 124
INSTRUMENT YOUR SOFTWARE
Whentesting software,it is often difficult to determine why the software
failed. One wayof uncovering the reasonsis to instrumentyoursoftware,
that is, embedspecialinstructions in the software that report traces, anomalous conditions, procedurecalls, and the like. Of course, if your debugging system provides these capabilities, don’t instrument manually.
Ref: Huang, J., “Program Instrumentation and SoftwareTesting,” IEEE Computer, 11, 4

(April 1978), pp. 25-32.
4

PRINCIDLE 125
ANALYZE CAUSES FOR ERRORS
Errors are commonin software. We spend enormousamountsof resources
detecting and fixing them. It is far more cost-effective to reduce their
impactby preventing them from occurringin thefirst place. One way to do
this is to analyze the causes for errors as they are detected. The causes are
broadcastto all developers with the idea being that we areless apt to make
an errorof the sametype as one whose cause was thoroughly analyzed and
learned from.
Whenanerroris detected there are two things to do: (1) Analyzeits
cause and (2)fix it. Record everything you can aboutthe causeofthe error.
This is not just technical issues like, “I should have checked the passed
parameter for validity before using it” or “I should have found outif I
neededto execute the loop 1 or 1-1 timesbeforeI gave it to integration testing.”It is also managementissueslike, “I should have desk-checked before
unit testing” or “If I had let Ellen check the designto seeifit satisfied all
the requirements when she wantedto, ...” After collectingall this information, broadcastit, letting everybody know whatcausedtheerrors, so that
such knowledge can become more widespreadandsucherrors can become
less widespread.
Ref: Kajihara, J, G. Amamiya, and T. Saya, “Learning from Bugs,” IEEE Software, 10, 5


(September 1993), pp. 46-54.
nh

PRINCIPLE 126
DON'T TAKE ERRORS PERSONALLY
Writing software requires a level of detail and perfection that no human
can reach. We should dedicate ourselves to constantimprovement, not perfection. Whenanerroris detected in your codeeither by you or by others,
discuss it openly. Instead of castigating yourself, use it as a learning experience for yourself and others (see more on this in Principle 125).
Ref: Gerhart, S., and L. Yelowitz, “Observationsof Fallibility in Applications of Modern Programming Methodologies,” [EEE Transactions on Software Engineering, 2, 3
EEE

(September1976), pp. 195-207, Section I.
B
 

] MANAGEMENT PRINCIPLES
Managementis the set of activities for planning, controlling, monitoring,
and reporting on all the engineering activities that encompass software
development.

i)

PRINCIPLE 127
GOO) MANAGEMENT 15 MORE IMPORTANT THAN
COO) TECHNOLOGY
Good management motivates people to dotheir best. Poor management demotivates people. All the great technology (CASE tools, techniques,
computers, word processors, and the like) will not compensate for poor
management. And good managementcanactually produce great results
even with meagerresources. Successful software startups do not become
successful because they have great processor great tools (or great products
for that matter!) Most have been successful because of great management
and great marketing. ‘As a manager, you havearesponsibility to be yourbest. There are no universally “right” styles of management. Managementstyle must be
adapted to the situation. It is not uncommonfor a successful leader to be
an autocratin onesituation and a consensus-based leader in another,just a
few minuteslater. Somestyles are innate. Others cabe learned. If neces- sary, read books and take short courses on managementstyle.
Ref: Fenton, N., “HowEffective Are Software Engineering Methods?” Journal of

Systents and Softzvare, 22, 2 (August 1993), pp. 141-146.
I

PRINCIPLE 128
USE APPROPRIATE SOLUTIONS
A technical problem needs a technical solution. A management problem needs a managementsolution. A political problem needsa political solu- tion. Do not try to throw an inappropriate solution at a problem.

W
PRINCIPLE 129
DON'T

BELIEVE EVERYTHING YOU READ
Asa generalrule, people whobelieve in a particular philosophy search for
data that supports that philosophy and discard data that does not.
Someone who wants to convince others of a position obviously uses supportive, not unsupportive, data. When youread, “Use method X. You too
can achieve up to 93 percentincreases in productivity (or quality),” the method mayreally have achieved suchresults. But it was probably the
exceptionalcase.In all likelihood, most projects experience far less dramatic results. And someprojects may even experience decreased productivity using method X.
Ref: Fenton, N., “HowEffective Are Software Engineering Methods?” Journal of

—————
Systems and Software, 22, 2 (August 1993), pp. 141-146.
I

PRINCIPLE 130
UNDERSTAND THE CUSTOMERS’ PRIORITIES
It is quite possible that the customers would rather have 90 percentofthe
system’s functionality late if they could just have 10 percentofit on time.
This corollary of Principle 8 is quite a bit more shocking,butit could very
well be the case. Find out!
If you are communicating with your customers, you should be sure
you knowtheir priorities. These can easily be recorded in the requirements
specification (Principle 50), but the real challenge is to understand the pos- sibly ever shifting priorities. In addition, you must understand the customers’ interpretation of “essential,” “desirable,” and “optional.” Will they
really be happy with a system that satisfies none of the desirable and
optional requirements?
Ref: Gilb, T,, “Deadline Pressure: How to Cope with Short Deadlines, Low Budgets and Insufficient Staffing Levels,” in Information Processing, HJ. Kugler, ed.,

Amsterdam:Elsevier Publishers, 1986.
Wy

Quality Managers

and Engineers
Yes No
Quality Processes, °° v x
Tools, Languages No
v x
PRINCIPLE 13]
PEOPLE ARE THE HEY 10 SUCCESS
Highly skilled people with appropriate experience, talent, and training are
key to producing software thatsatisfies user needs on time and within the
budget. The right people with insufficient tools, languages, and process
will succeed. The wrongpeople(or the right people with insufficient training or experience) with appropriate tools, languages, and process will
probably fail. According to COCOMO (Boehm, B., Software Engineering
Economics, EnglewoodCliffs, N.J.: Prentice Hall, 1984), the best people are
four times more productive than others. If the best people cost four times
the salary, you break even and probably end up with a better product
(Principle 82). If they cost less, you reduce costs and havea better product.
That's a win-win.
Wheninterviewing prospective employees, rememberthatthere is no
substitute for quality. Companiesoften say,after interviewing two people,
“Personx is better than person y, but person y is good enoughandless
expensive.” You can’t have an organization of all superstars, but, unless
you havean overabundanceof themnow,hire them!
Ref: Weinberg, G., Tie Psychology of Computer Programming, NewYork: Van Nostrand


Reinhold, 1971, Chapters 6-7.
bo

PRINCIPLE 132
A FEW GOOD PEOPLE ARE BETTER THAK MAKY LESS
SKILLED PEOPLE
This follows immediately from Principle 131, which says that you should
alwayshire the best engineers. This principle says that you are better off
allocating just a few good, experienced engineers ona critical task than to
put manyinexperienced engineersonit. This is Don Reifer’s “Management
Principle #6.” On the other hand, Manny Lehman warnsthat you can’t rely
too much on “a few good people”; whatif they quit? The best adviceis to
have the right mix of people on a project and take care not to gravitate
towardeither extreme.
Ref: Reifer, D., “The Nature of Software Management: A Primer,” Tutorial: Software Management, D. Reifer, ed., Washington, D.C.: IEEE ComputerSociety Press, 1986,

pp. 42-45.
n

PRINCIPLE 133
LISTEN 10 YOUR PEOPLE
The people who work for you mustbetrusted. If they’re not trustworthy
(or if you don’t trust them), your project willfail. If they don’t trust you,
your project will also fail. Your people can tell as quickly that you don’t
trust them as you can when yourboss doesn’ttrust you.
Thefirstrule of trustis listening. There are many opportunitiesto listen to your people: when they visit your office to tell you about a problem
they are having, when you need an estimate from them for a software
development, when you are managing by walking around (MBWA),
amongothers. Whenever your people are talking to you,listen and hear.
They consider what they are saying to be important or they wouldn’t be telling you. There are many waysto let them know you are listening: eye
contact, appropriate body language, “playing back” what you think you
heard them say, asking appropriate questions tosolicit more information,
and so on.

Ref: Francis, P, Principles of R&D Management, NewYork:AMACOM,1977,pp. 114-116
Qn

PRINCIPLE 134
TRUST YOUR PEDDLE
In general,if you trust people,they will be trustworthy. If youtreat people as if you don’t trust them, they will give you reason not to trust them. Whenyoutrust others and give them noreasonnotto trust you, they will trust you. Mutualtrustis essential for successful management. Whenoneof your employeessays, “CanI take off today at 2 P.M.? I'll work a few hoursextralater in the week,” you shouldsay, “Yes.” You lose nothing, and you gain the loyalty and respect of your employee. There are manymoreopportunities to be the bad guy than the good guy. Take every chance you can get to be the good guy. Who knows, maybein a few weeks you'll need to ask the employee to work a few extra hoursfor a job you need to have done.
Ref: McGregor, D., The HumanSideof Enterprise, New York: McGraw-Hill, 1960.
———
eee
B

PRINCIPLE 135
ERPECTEXCELLENCE
Your employeeswill do muchbetterif you have high expectationsof them.
Studies by Warren Bennis prove conclusively that, the more you expect, the
moreresults will be achieved (obviously with somelimit). In many experiments,heterogeneous groups were divided into two subgroupswith identical goals. One subgroup wastreated as if excellence was expected. The
other subgroup wastreated as if mediocrity was expected. In every experiment, the group for whom excellence was expected outperformed the
other group.
You can show in many waysthat you expect excellence: Be an exam- ple (work hard, be proud of yourefforts well done, don’t play computer
gamesonthejob). Provide educational benefits to your employees to help
them achievetheir best. Reward excellent behavior(but see Principle 138).
Coach,tutor, cajole, and attemptto inspire your poorer performers toward
better work products and habits. If you (or they) fail, find more suitable opportunities for them within your organization or your company. If all
else fails, help them find a job outside. You cannotallowthem to stay in an
inappropriate job, but you must also show compassion.If you leave them
where they are, your product will be of lower quality and your other
employees will assumethat poorperformanceis acceptable.
Ref: Bennis, W., The Unconscious Conspiracy: Why Leaders Can't Lead, New York: AMAeee
COM,1976.
——————————————_————— Dy
PRINCIPLE

136
COMMUNICATION SHILLS ARE ESSENTIAL
Whenrecruiting personnelfor yourproject, don’t underestimate the impor- tance of teamwork and communication. The best designer becomes a poor asset if he/she is unable to communicate, convince, listen, and compromise.
Ref: Curtis, B, H. Krasner, and N. Iscoe, “A Field Study of the Software Design Process for Large Systems,” Communications of the ACM, 31, 11 (November1988),
aa‘
pp. 1268-1287.
15

PRINCIDLE 137
CARRY THE WATER
Whenyourpeople are working long hours to get a software engineering job done, you should work the same hours.This sets the right example. Your employeeswill be more willing to work hard and do a good job if
they know youare in the predicament with them. Myfirst industrial manager, Tomlinson Rauscher, did precisely this. It madeall the difference in
our attitude. During crises, Tom took on the role of “working for his
employees.” It worked.
If you can’t help with the engineering workitself, let them know you are available to run errands, order a pizza, bring them sodas, carry the
water, whatever they need. Surprise them! Bring them a pizza at midnight.

Ref: Rauscher, T., private communication, 1977.

PRINCIPLE 138
PEOPLE ARE MOTIVATED BY DIFFERENT THINGS
This was perhaps the hardest lesson for me to learn as a manager. I
assumedincorrectly that my employees were motivated by the samethings that motivated me. I remember working hard oneyear with myraise pool to allocateraises fairly. | wanted especially to give very largeraises to spe- cific employees to reward them for a great job and to motivate them to work even harder. When I presented the first raise, the employee said, “Thanks, but whatI really need is a faster computer.”
Sometimesit is not so easy to find out which carrots and whichsticks motivate individuals. What is knownis that peopleareall different, that
negative and positive reinforcements both work, but that positive rein- forcements are more often neglected by management. A good wayto start figuring out what motivates individual people is to listen to them
(Principle 133). The rest mightbe by trial and error. But whatever youdo, don’t suppress rewardsoutof fear ofselecting the wrong one.
Ref: Herzberg, E, “One More Time: How Do You Motivate Employees?” Harvard
S88
Business Review(September-October 1987).
iW

PRINCIPLE 139
REED THE OFFICE QUIET
The most productive employees and companies have quiet and private offices. They have phonesthat can be silenced or diverted. Theyare insulated from regular, nonbusiness interruptions. Contrast this with the general industry movement toward open, landscaped offices, which reduce
physical plant cost but dramatically decrease productivity and quality. Of
course, the usual managementlineis that such an arrangement“facilitates
communication.” Nottrue.It “facilitates interruption and noise.”
——
Ref: DeMarco,T., andT.Lister, Peopleware, New York: Dorset House, 1987, Chapter 12.
18

PRINCIPLE TH0
PEOPLE AND TIME ARE NOT INTERCHANGEABLE
Measuringa project solely by person-months makeslittle sense. If a project could be completed in one year bysix people, does that mean that 72 peo- ple could completeit in one month? Of course not! Supposeyou have 10 people working ona projectthatis due for com- pletion in three months. You nowbelieve you are three months behind schedule;thatis, you estimate you need 60 more person-months(6 months x 10 people). You cannot add 10 more people and expect the project to be back on schedule. In fact, adding 10 more people would likely delay the project further due to additionaltraining and communications overhead. This principle is usually called Brooks’ Law.
Ref: Brooks, E, The Mythical Man-Month, Reading, Mass.: Addison-Wesley, 1975,
eee
Chapter2.
9

PRINCIDLE 141
THERE ARE HUGE DIFFERENCES AMONG SOFTWARE ENGINEERS
Productivity (measured bylines of code per person-month) can vary by as
much as a factor of 25 from the best to the worst software engineers.
Quality (measured by bugs found per thousand lines of code) can vary by
as muchasa factor of 10 from the best to the worst software engineers.
Ref: Sackman, H., et al., “Exploratory Experimental Studies Comparing Online and Offline Programming Performance,” Communications of the ACM, 11, 1 January

1968), pp. 3-11
_——
El
16

DRINCIDLE 142
YOU CAN OPTIMIZE WHATEVER YOU WAKT
Anyproject can optimize whateverfactorof “quality”it wantsto. In optimizing any onefactor, other “quality” factors are generally denigrated. In
a landmark experiment conducted by G. Weinberg and E. Schulman, five
teams of software developers were given identical requirements, but each
was told to optimize somethingdifferent: developmenttime, program size,
data space used, program clarity, and userfriendliness. In all cases except
one the programs produced by the teams wererated bestin terms of the
attribute they were told to optimize. :
If you tell your people that everything (such as schedule,size, maintainability, performance, and userfriendliness) is equally important, none
will be optimized. If you tell them that onlyone or two are important and
the rest unimportant, only the important ones will be addressed. If you
give them ana priorirelative ranking,the ranking may not be appropriate
in all situations on the project. The fact is that there are trade-offs—different trade-offs—to be madeconstantly during product development. Work
with your employees and help them understand yourpriorities and your
customers’.
Ref: Weinberg, G., and E. Schulman, “Goals and Performance in Computer
ee
Programming,” HumanFactors, 16 (1974), pp. 70-77.
————————————————
0Nuss
i}

PRINCIDLE 143
COLLECT DATA UNOBTRUSIVELY
Datacollection is extremely importantto help with future cost predictions, to assess the currentstate of a project or organization,to assess theeffect of a change in management, process,or technology, and so on. Onthe other hand,data collection in an obtrusive fashion—for example,if it requires software developers to do considerably extra work—is meaningless becauseits collection affects the data itself. Furthermore, data collected from developers who do not wantto provide such data will likely be use- less becauseit is unlikely that an uncooperative developer will provide meaningfuldata.
The best waytocollect data is automatically, with no developer-per- ceived interference. Obviously you cannotdothisall the timeforall data, but you should automate data collection whenever you can.
Ref: Pfleeger, S., “Lessons Learned in Building a Corporate Metrics Program,” IEEE Software, 10, 3 (May 1993), pp. 67-74.

Ia

PRINCIPLE Th4
COST DER LINE OF CODE 1S NOT USEFUL
Given a particular set of requirements, we may choose to implement the
program in any of numerouslanguages.If we choose a very high-level language, we will spend muchlesstime than if we choosea very low-levellanguage(Principle 152). Thus total developmentcosts will be far less when
using the high-level language. However, becauseofthefixed costs of software development(such as user documentation, requirements, and design),
the cost per line of code actually increases if we choose the high-level language! Capers Jones explains this well with an analogy to manufacturing:
As the numberof units produced decreases, the cost per unit increases
becausethefixed costs must now be absorbed by a smallersetofunits.

Ref: Jones, C., Programming Productivity, New York: McGraw-Hill, 1986, Chapter 1.
——————
1B

PRINCIDLE 145
THERE 15 NO PERFECT WAY TO MEASURE PRODUCTIVITY
The two most commonly used ways of defining productivity are source lines of code (SLOC)and function points (FP) per person-month.Both have problems. Measuring SLOCslooks good at first glance because, in most engineering or manufacturingfields, producing moreis better. However,if youhave twoprogramsthat do the samething, oneis twice the size of the other, and both exhibit the same qualities (exceptfor size, of course), then the smaller one is better. Function points seem to solve the problem because they measure the complexityof the problem (throughthe analysis of requirementsspecification) rather than the solution. But here toothereis a problem. Suppose two requirementsspecifications are identical in every way except one says, “If the system crashes, all of humanity will be destroyed” and the other says, “If the system crashes, twofive-year-olds will be slightly inconvenienced.” Clearly the former is a much morediffi- cult problem andthus should exhibit far lower productivity than thelatter. There are published techniques to convert a LOC estimateinto an FP esti- mate, and vice versa. Clearly, neither can have a consistent advantage over the other.
Accept the fact that perfection is impossible. Use productivity mea- sures and cost estimation models to confirm your intuition and your own experiences. Neverrely on them as your sole measure.
” 14th IEEE E Computer
Ref: Fairley, R., “Recent Advances in Software Estimation Techniques, International ConferenceonSoftware Engineering, Washington, D.C.:| Society Press, 1992.
 

PRINCIPLE Th6
TAILOR COST ESTIMATION METHODS
Numerouscost estimation methods are available commercially. Each is
based on data collected from a large set of completed projects. Any of these
methods can be used to generateball park estimates for your software
development.To use them to generate more accurate estimates, you must
tailor them to your work environment.This tailoring adapts the modelto
your type of people and your type of applications.It eliminates variables
that are invariant in your environment.It addsvariables that are productivity-influential in your environment.
Chapter 29 of Barry Boehm’s Software Engineering Economics explains
in detail how to tailor COCOMOto your environment. Similar tailoring
guidance is provided with other cost estimation methods. You mustfully
embracethespirit of suchtailoring, or you will end up with dismally inaccurate results.
Ref: Boehm, B., Software Engineering Economics, Englewood Cliffs, NJ.: Prentice Hall,
—
1981, Section 29.9.
16

PRINCIPLE 147
DON'T SET UNREALISTIC DEADLINES
It is a foregone conclusion that an unrealistic deadline will not be met. The establishmentof such deadlines erodes morale, causes yourfellow employeesto distrust you, creates high employee turnover, and has other undesirable effects. These factors then make the unrealistic deadline even more unachievable. A large majority of software projects are completed well over budget and well beyond the scheduled completion date. In an effort to
meet schedule constraints, quality is often reduced. This erodes the credibility of the entire software industry. The problem is generally not that the
software engineers have poor productivity or that managers do a poor job managing. Theproblem is that poor estimates are made up front.
Ref: DeMarco, T., “Why DoesSoftware Cost So Much?” IEEE Software, 10, 2 (March

1993), pp. 89-90.
—————————
I

PRINCIPLE THB
AVOID THE IMPOSSIBLE
This may seem like obvious advice. On the other hand, many projects com- mit to delivering their product on schedulesthat are 100 percent impossi- ble. Barry Boehm has defined the “impossible region”asa relationship
between the expected time to develop a product and the numberofpersonmonthsto be consumed.Specifically, the elapsed time from writing a software requirements specification to product delivery will not be less than
2.15 times the cube root of person-months,thatis,
T > 2.15VPM
Ninety-ninepercentof all completed projects have obeyedthis rule. What
makes you think you can dobetter?If youstill think you can,see Principles
3, 19, 158, and 159.
Ref: Boehm,B., Software Engineering Economics, EnglewoodCliffs, N.J.: Prentice Hall,

1981, Section 27.3.
1)

PRINCIPLE 149
ANOW BEFORE YOU COUNT
Gerald Weinberg (Rethinking Systems Analysis and Design, New York:
Dorset House, 1988,p. 32) states this principle beautifully: “Before you can
countanything, you've got to know something.” He is talking about the
many people whocountthingsin software but don’t know what they are counting. He provides a great example. We have data concerning what percentage ofthe software industry is involved with maintenance rather
than development. But can we recognize maintenance? Is a “new” devel- opment that completely replaces an existing system considered mainte- nanceor development?Is a “modification” to an existing system that dou- bles current functionality and removes 95 percentof old functionality considered maintenance or development?
Whenselecting metrics for your project, make sure that what you are measuringrelates to whatyouaretrying to achieve. (See the opening paragraphs of my Manager Column in the September 1993 IEEE Software for a
personaltestimony.) This often entails using multiple metrics. Remember:
Even if everybody is measuring something one way, that wayis not automatically right for you. Think about your metrics. Since everything can be
observed (and in most cases measured), carefully select what you want to
observe (and measure). Thearticle referenced belowis the best description
I’ve seen of an organization-tailored metrics program.
Ref: Stark, G., R. Durst, and C. Vowell, “Using Metrics in Management DecisionSe
Making,” IEEE Computer, 27, 9 (September 1994).
16

PRINCIPLE 150
COLLECT PRODUCTIVITY DATA
The accuracyof all cost estimation models is dependentonthetailoring of
those models for your workplace. But you cannottailor yourcost estimation models todayif you haven’t already collected detailed data from past
projects. You therefore have a great excuse not to do accurate cost estimations now. But what about tomorrow? You will not be able to tailor cost
estimation models then if you don’t start collecting detailed data today. So
whatare you waiting for? Also remember Manny Lehman’s advice:Alittle
data that is well understood and carefully collected, modeled, and interpretedis better than a vast amountof data without these properties.
Ref: Boehm, B., Software Engineering Economics, Englewood Cliffs, N.J.: Prentice Hall,
OO
1981, Section32.7.
——————
ee
19

PRINCIPLE 15]
DON'T FORGET ZEAM PRODUCTIVITY
It is relatively easy to decide on a set of productivity measures for individ- uals. (Of course, they may not yield accurate results, as highlighted by Principles 142, 144, and 145.) However, be aware that optimizing the pro- ductivity of all individuals does not necessarily result in optimal produc- tivityof the team. Comparethis to a basketball team.Everyplayer can opti- mize her/his own performance by alwaysshooting for the basket when in possessionofthe ball. However, the team will surely lose. Manny Lehman reports on one software developmenteffort in which individual produc- tivity tripled but corporate productivity actually decreased! There are two lessonsto be learned here: First, different measures are appropriate for different people. Second, measurethe overall effectiveness of the team by tracking such thingsas the team’s ability to resolve out- standing problem reports by problem difficulty, per time period.
Ref: Lehman,M., private communication, Colorado Springs, Col:: (January 25, 1994).
—————————————
eee

i

PRINCIPLE 152
{O¢/DM INDEPENDENT OF LANGUAGE
It is generally believed that a programmercan generate on the average x
lines of quality code per person-monthregardless of the language being
used. Thus, if a programmercan generate 500 lines of quality code per
monthin Ada, that person could also generate 500lines of quality code per month in assembly language. For an opposing viewpoint, see C. Jones,
Programming Productivity (New York: McGraw-Hill, 1986, Chapter 1). True productivity, of course, is greatly enhanced whenusing higher-level languages because 500 lines of Ada code do so much morethan 500 lines of
assembler. Furthermore, languageselection greatly affects maintainability (Principle 193).
Whenstarting a project you will need to have someidea of what language your programmerswill be using. This is necessary so that you can
estimate the lines of code. Lines of code can then be used to compute project effort and duration.
Ref: Bochm,B., Software Engineering Economics, Englewood Cliffs, N.J.: Prentice Hall,


1981, Section 33.4.
nl


Realism of Schedule

Realistic Constrained Very Constrained
Team ‘Yes: Hi Medium Low
Believes in
Schedule
No Low Low Low PRINCIPLE 153
BELIEVE THE SCHEDULE
Once feasible scheduleis established (Principles 146, 147, and 148) and
appropriateresourcesallocated (Principle 157), all parties mustbelieve the
schedule. Engineers will not succeed in meeting a scheduleif they don’t
believeit is realistic. The probability of success is more a function of faith
in the schedulethanits realism.
Thebestadviceis to have engineers set schedules. Unfortunately,this
is not always possible. The second best adviceis to involve engineers in the
tough trade-offs that occur between functionality, schedule, and project
abandonment. Few engineers wouldratherlose their job because a project
is canceled than strive to meet a tough schedule.
Ref: Lederer, A., and J. Prasad, “Nine Management Guidelines for Better Cost Estimating,” Communications of the ACM, 35, 2 (February 1992), pp. 51-59,


Guideline1.
Nn

PRINCIDLE 154
A DRECISION-CRAFTED COST ESTIMATE IS NOT FOOLPROOT
Suppose your organization has collected reams of data on past performance. Suppose you havetailored one of the manycostestimation models
to your organization’s capabilities based on this data. Suppose you are a
project manager. You have a new project and you usethistailored model.
The model reports that the software will cost $1 million. What does that
mean?It does not meanyoursoftwarewill cost $1 million.
There are three reasons:(1) you, (2) assumptions, and (3) probability.
First of all: You. Your leadership abilities will have a majoreffect on actual results. For example,in five seconds you can destroy the morale of your
group that took a year to build. Second,all the assumptions you madeto
generate theinitial estimate may not turn out to be accurate. For example,
what if youget less qualified people? Whatif requirements change? What
if your key person becomesill? Whatif half your workstations go down when you need them the most? Third, the estimate is just a peak in a probabilistic distribution. If I tell youI’m going to toss a coin 100 times and ask you to predict how manytimesit will be heads, you'll probably pick 50.
Doesthat mean 50 headswill appear? Of coursenot.In fact, you would be
amazedif 50 heads appeared!
Ref: Gilb, T., Principles of Software Engineering Management, Reading, Mass: Addison-

Wesley, 1988, Section 16.7.
————————————————
B

PRINCIPLE 155
REASSESS SCHEDULES REGULARLY
Schedules are usually set at projectinitiation. These include intermediate
deadlines as well as the productdelivery deadline. As each phase is completed, the schedule mustbe reassessed. A behind-schedule project rarely
recovers during subsequentphases. Thus,a project thatis, say, one month
late at completion of design will be at least one monthlate for delivery. In mostcases adding or removing peoplewill only delay the project further
(Principle 140). The most commontechniqueis not to change the product delivery date. (Afterall, we don’t wantto disappoint the customerjustyet,
do we?) As each intermediate milestone is missed by an increasing amount of time, the time allocated to testing is reduced more and more (Principle
119). At the end, one of two situations is inevitable: (1) The product is
shipped without the necessary quality, or (2) the customeris notified of a
very large scheduleslip very late in the project. Neither is acceptable. As a
manager, yourresponsibility is to prevent disasters.
Instead, establish a workingrelationship with customers and/or management levels above you. Report every possible date change (usually a
slip) and discussthe alternative strategies for overcoming them. Only early
intervention and involvementbyall parties can preventslippage escalation.
Ref: Gilb, T., Principles of Software Engineering Management, Reading, Mass.: Addison-

Se
Wesley, 1988, Section 7.14.
Ih

PRINCIPLE 156
MINOR UNDERESTIMATES ARE NOT ALWAYS BAD
Assuming morale has not been diminished, membersofa project that is
perceived as slightly behind schedule will tend to work hard at catching
up, thusincreasing productivity. Similarly, membersofa project that is per- ceived as slightly ahead of schedule often take vacation days, work less
hours, read their mail longer, and ease up in other ways, thus decreasing productivity. Thus, thecost estimationitself will affect the project outcome. Any specific project may expendlessresourcesif it is slightly underesti- matedthanif it is slightly overestimated. Be careful, though! If project
membersbelieve that the scheduleis ridiculously underestimated, morale
and productivity will decrease.
Ref: Abdel-Hamid, T., and S. Madnick, “Impact on Schedule Estimation on Software

Project Behavior,” IEEE Softzare, 3, 4 (July 1986), pp. 70-75.
5

Appropriate Schedules, Budgets and Resources
Yes No Quality re? Personnel, Y°S v x
Process, Tools, No x x
Languages
PRINCIPLE 157
ALLOCATE APPROPRIATE RESOURCES
Artificially constrained schedules and inappropriate budgets will doom a
project regardless of the quality of the people or the availability of tools,
languages, and process.
If you try to compresseither schedule or budget, the engineers working on the project will not workefficiently, there will be no “play” when the inevitable slippage occurs, morale will suffer, and, most importantly, the
project will probably cost more than what would otherwise be considered
reasonable anyway.
Ref: DeMarco, T., “Why Does Software Cost So Much?” IEEE Software, 10, 2 (March

1993), pp. 89-90.
6

PRINCIPLE 158
PLAN A PROJECT IN DETAIL
Every software project needs a plan. The level of detail should be appropriate for the size and complexity of the project. At an absolute minimum,
you will need:
A PERTchart showing the interdependencies amongtasks. AGANTT chart showing whenactivity will be underwayoneachtask.
Alist ofrealistic milestones (based onearlier projects, see Principle 150).
Asetof standards for writing documentation and code.
Anallocation of people to various tasks.
As projects increase in complexity, each of these requirements becomes
more detailed and more complex, and other documentation becomes nec- essary. A project withouta plan is out of controlbeforeit even starts. As the
Cheshire Cat said to Alice in Wonderland, “If you don’t know where you
are going, any road will get you there!”
Ref: Glaser, G., “Managing Projects in the Computer Industry,” IEEE Computer, 17, 10


(October 1984), pp. 45-53.
WW

PRINCIPLE 159
REED YOUR PLAN UP-TO-DATE
This is Don Reifer’s “ManagementPrinciple #3.” Principle 158 says that
you mustplan a software project. However, having an out-of-dateplanis
even worsethan havingnoplanatall. When you havenoplan, you should
know you areoutof control. When you have an out-of-date plan, you may
naively think you are undercontrol. So whenevercircumstances change,
update your plan. Such circumstances include changes to the requirements, a scheduleslippage, a changein direction,finding excessiveerrors,
or any deviation from the original conditions.
Awell-written plan should enumerate the risks, the warning signsthat
the potential risk is becoming a threat, and contingency plans to put into
place to reducethe threat (Principle 162). As a project progresses and predicted risks becomethreats, the contingency plans are implemented and the
project plan is updated.Thereal challenge occurs when unforeseen changes occur. For these times, oneoften needsto replan the remainderof a project inits entirety, with new assumptions, newrisks, new contingency plans,
newschedules, new milestones, new person powerloading, and so on.
Ref: Reifer, D., “The Nature of Software Management: A Primer,” Tutorial: Software Management, D. Reifer, ed., Washington, D.C.: IEEE ComputerSociety Press, 1986,


pp. 42-45
8

PRINCIPLE 160
AVOID STANDING WAVES
Oneofthe odd side-effects of following Principle 159 (Keep Your Plan Up- to-Date)is the standing wave.In this situation, you always plan the “get well”strategy to occur “over the next few weeks.” Since projects that are behind scheduletendto getfurther behind schedule,this “get well” strat- egy requires larger and larger resources(or miracles!) to be applied “over the next few weeks.” The wavegets larger and larger with no corrective action taken. Rescheduling and replanning in general require action, not just promisesthatthingswill be fixed soon.Just because youare only a few days behind, don’t think the problem will go away.Allprojects “fall behind one dayata time.”
Refi Brooks, F, The Mythical Man-Month, Reading, Mass.: Addison-Wesley, 1975, Chapter 4.
———_—————— 
PRINCIDLE

161
KNOW THE TOP 10 RISKS
Asyoustart a project as a project manager, becomefamiliar with the situations that mostoften cause software disasters. These are your mostlikely
risks, but probably not all of them. According to Boehm,they are:
= Personnel shortfalls (Principle 131).
Unrealistic schedules (Principle 148).
Not understandingthe requirements (Principle 40).
Building a pooruserinterface (Principle 42).
Trying to gold-plate when the customer doesn’t wantit (Principle 67).
Notcontrolling requirements changes(Principles 179 and 189).
Shortfalls of reusable or interfaced components.
Shortfalls in externally performed tasks.
Poorresponsetime.
Attempting to exceedthe capability of current computer technology.
Nowthat you know the most commonrisks, add to them risks unique
to your environmentand project, and develop plans on how to mitigate
them.(Principle 162.)
Ref: Boehm, B., “Software Risk Management:Principles and Practices,” IEEE Software,

9,1 January 1991), pp. 32-39.
——————
ito
PRINCIPLE 162
UNDERSTAND

RISKS UP FRONT
On any software project it is impossible to predict exactly what will go
wrong. However, somethingwill go wrong.In the early stages of planning, delineate the largest risks associated with your project. For each, quantify the extent of the damageif the risk potential becomesa projectreality and
also quantify the likelihood thatthis will come to pass. The productofthese
two numbersis your risk exposure with respectto that particular risk.
Atproject inception, construct a decision tree that delineates all the
things you could do to lower the exposure. Then either act on the results
immediately, or develop plans to implement various actions at points when the exposure exceeds youracceptable limits. (Of course, specify in advance how youwill recognize this situation so that you can implement the corrective action beforeit is too late.)
Ref: Charette, R., Software Engineering Risk Analysis and Management, NewYork:


McGraw-Hill, 1989, Section 2.2, Chapter 6.
iil

PRINCIPLE 163
USE AN APPROPRIATE PROCESS MODEL
Dozens of process models are available for software projects to utilize: waterfall, throwawayprototyping, incremental development, spiral model,
operational prototyping, to name but a few. There is no such thing as a
process modelthat worksforall projects in an organization. Every project
mustselect a process that makes the mostsenseforit. The selection should be based on corporate culture, risk willingness, application area,volatility
of requirements, and the extent to which requirementsare well understood.
Study yourproject's characteristics and select a process model that
makes the most sense. For example, when building a prototype, you
should follow a process that minimizes protocol,facilitates rapid development, and does not worryabout checks and balances. When buildinga lifecritical product, the oppositeis true.
Ref: Alexander, L., and A. Davis, “Criteria for the Selection of a Software Process
Model,” IEEE COMPSAC ‘91, Washington, D.C.: [IEEE ComputerSociety Press,


pp. 521-528.
I

PRINCIPLE 164
THE METHOD WON'T SAUE YOU
You haveall heard the preachings of “method zealots” whosay,“If youjust adopt my method, mostof your problemswill disappear.” Although many
methods have been the subject of such ravings, the majority during the
1970s and early 1980s contained the word “structured”in their names and
those during the late 1980s and 1990s contained “object” in their names.
Althoughboth of these wavesbring great insights, as well as quality-instilling software development constructs and steps, they are not panaceas.
Organizations that are really good at developing quality software were
good before the “structured” methods and are good now when using
“object-oriented” methods. Organizations with poorrecordswillstill have
poor records after adopting the latest fad method.
As a manager, bewareof false soothsayers whowill promise great
increasesin either quality or productivity based on a new method. Thereis
nothing wrong with adopting a new method,butif the organization has
“failed”in the past (eitherin termsof productivity or quality), try to uncover the source of that failure before you jump to a solution. It is highly
unlikely that your methodis to blame!
Ref: Loy, P, “The Method Won't Save You (But It Can Help),” ACM Software


Engineering Notes, 18, 1 (January 1993), pp. 30-34.
1B

PRINCIDLE 165
HO SECRETS FOR MIRACULOUS

PRODUCTIVITY INCREASES
This industry is saturated with salespeople whopreach the reduction of
developmentcostthroughtheuseofthis tool or that technique. We all hear
at business meetings and conferences about software managersclaiming 50
percent, 75 percent, even 100 percentincreases in productivity by applying
tool x or language y or methodz. Don’t believe it! This is hype. The software industry is experiencing moderate (3 to 5 percent/year) increases in
productivity. The fact is that we have trivial way to reduce the cost of
requirements engineering: Just don’t do it! The sameis true ofall other
phases.In fact, we can save lots of money by simply not buildingsoftware!
You should be happywith tools, languages, and methodsthat shave a few percentages off your cost or add a few percentages to your quality.
However, cost reduction makes no sense without an understandingofits
impact on customersatisfaction.


Ref: DeMarco,T., andT.Lister, Peopleware, NewYork: Dorset House, 1987, Chapter 6.
Ih

PRINCIPLE 166
ANOW WHAT PROGRESS MEANS
1 often hear project managers report, “We are 25 percent below budget” or “25 percentaheadof schedule.” Neitheris necessarily good news. “Below budget”usually means you spentless money than expected. Thatcould be good, but you don’t know unless you are also on or ahead of schedule. Similarly, “ahead of schedule” usually means you did more than you expected. Thatcould be good news, but you don’t know unless you are also on or belowbudget. There are meaningful measures of progress:
BCWP. “Budgeted cost of work performed” measures how much you expected to spend on worksofar completed. ACWP. “Actual cost of work performed” measures how much has actually been spenton the project.
BCWE “Budgeted cost of work expected” measures how much you expected to spend.
BCWP-BCWE This captures true technical status. Greater-than-zero BOWE valuesindicate the percentage you are ahead of sched- ule. Less-than-zero values indicate the percentage behind schedule.
BCWP-ACWP This captures true budgetary status. Greater-than-zero BCWP. values indicate the percentage under budget. Less- than-zero values indicate the percentage over budget.

Ref: US. Air Force, Cost/Schedule Management of Non-Major Contracts, Air Force Systems
ee
CommandPublication #178-3, Andrews AFB, Md.: (November1978).

185

PRINCIPLE 167
MANAGE BY VARIANCE
First of all, it is impossible to manage a project without a detailed plan
(Principle 158). Once you have a plan, update it as necessary (Principle
159). Now that you have an up-to-date plan, your responsibility is to manage the project accordingto that plan. As you report your progress (it doesn’t matterif this is written, oral, formal, or informal), report only discrepancies betweenthe plan and the actuals. Project managers typically spend
a large majority of the time reporting how well they are doing. There will
be plenty of time at project completion for kudos. While the project is
underway, a progress report shouldbe, “Everythingis as stated in the plan
except....” This wayattention and resources can be applied tothe problem areas.

lie
PRINCIPLE

168
DONT OVERSTRAIN YOUR HARDWARE
Be awareofthe astronomicaleffect hardwareconstraints will have on soft- ware developmentcosts.In particular, data showsthat, as you approach 90 percentutilizationofeither memory or CPUcycles, software development costs double! And as you approach 95 percent,it friples! With the astronom- ical decreasesin cost per instruction per second and cost per word of mem- ory, this tends to beless of a problem than it was15 years ago. On the other hand,thereis still a strong motivation to control hardware cost in many applications (such as low-cost products that will be sold in vast quantities). If memoryis easy to add andfaster processors areeasily incorporat- ed in your environment, do not worry aboutthis principle; just add more whenneeded. If your environmentis such that you must squeeze every word of memory and CPU cycle, then be sure to expand your schedules accordingly.
Ref: Bochm, B., “The High Cost of Software,” in Practical Strategies for Developing Large Software Systems, E. Horowitz, ed., Reading, Mass.: Addison-Wesley, 1975.

W

PRINCIPLE 169
BE OPTIMISTIC ABOUT HARDWARE EVOLUTION
In 1984, 13 major aerospace corporations predicted that 50 percent ofall
software development wouldstill be done on dumbterminals in 1988. By
1988, most software development had been taken off dumbterminals and
transferred to PCs and workstations. In the same survey, they predicted
only 15 percentof all software development environments would use
Ethernet, and there would be only a 27 percent penetration of UNIX-based
machines in software environments. Clearly, these predictions were all
wrong. Hardware speed, capability, standardization, and price/performanceall exceeded the predictions.
Ref: Davis, A., and E. Comer, “NoCrystal Ball in the Software Industry,” IEEE Software, 10, 4 (july 1993), pp. 91-94, 97.
——————————————
————————————— ——
——
SSS 0
8

PRINCIDLE 170
BE DESSIMISTIC ABOUT SOFTWARE EVOLUTION
In 1984, 13 major aerospace corporations predicted that, by 1988, 46 percent ofall their software development would bein Ada(andless than 4 percent in C), and that 54 percentofall their software would be reused from previ- ous applications. Also, by 1994, 70 percent ofall software development would beassisted by knowledge-based systems. Noneof these predictions has cometopass. In all cases, the technology either was too immature or wasovertakenby events.
Ref: Davis, A., and E. Comer, “No Crystal Ball in the Software Industry,” IEEE Software,
S|————
10, 4 July 1993), pp. 91-94, 97.
ip

PRINCIPLE 171
THE THOUGHT THAT DISASTER 1S IMPOSSIBLE OFTEN LEADS
TO DISASTER
This is Gerald Weinberg’s “Titanic Effect” principle. You must never
become so smug that you think everything is under control and will
remain that way. Overconfidenceis the primary cause of manydisasters.
It is the mountain climber whosays, “It’s just a small climb; I don’t need
a belay,” or the hiker whosays,“It’s just a short hike; I don’t need water,”
or the poker player whosays, “This handis a sure winner” whogets into
trouble. Principle 162 emphasizes the need to analyzeall your potential
disasters up front, develop contingency plans for them in advance, and
continually reassess new risks. This principle emphasizes the need to
expectthese risks to becomereal. Your biggest managementdisasters will
occur when you think they won’t.
Ref: Weinberg, G., Quality Software Management, Vol. 1: Systems Thinking, New York:

Dorset House, 1992, Section 15.3.5.
———
eee
SSS 0
i

PRINCIDLE 172
DOA PROVEPOSTMORTEM
Those who do not remember the past are condemned
to reliveit. George Santayana, 1908
Every project has problems.Principle 125 dealt with recording, analyzing, and learning from technical errors. This principle deals with doing the samefor managementoroverall technical errors. At the end of every pro- ject, give all the key project players a three- or four-day assignmentto ana- lyze every problem that occurred during the project. For example, “We were 10 dayslate starting integration testing; we should have told the cus- tomer.” Or, “We started the design long before we knew even the most basic of requirements.” Or, “The big boss demotivated the people with a
‘no raises’ announcementat just the wrong time.” In general,the ideais to document, analyze, and learn fromall the things that went wrong.Also, record what youbelieve could be donedifferently in the future to prevent it. Future projects will benefit greatly.
Ref: Chikofsky, E., “Changing Your EndgameStrategy,” IEEE Software, 7, 6 (November 1990), pp. 87, 112.
 
 

PRODUCT ASSURANCE PRINCIPLES
Product assuranceis the set of activities that ensuresthe quality of software
through the use of checks and balances. Product assurance generally
includes:
1. Software configuration management, the process of managing changes to
software.
2. Software quality assurance, the process of checkingthatall practices and
products conform toestablished procedures and standards.
3. Software verification and validation, the processes of verifying that each
intermediate productcorrectly builds upon the previous intermediate
product and validating that each intermediate productsatisfies the customer’s requirements appropriately.
4. Testing, covered in an earlier chapter.
B

PRINCIPLE 173
PRODUCT ASSURANCE 1S NOT @ LUBURY
Product assurance includes software configuration management, software quality assurance,verification and validation, andtesting. Of the four, the one whosenecessity is mostoften acknowledged(though underbudgeted) is testing and evaluation. The other three are quite often dismissed as lux- uries, as aspects of only large or expensive projects. The checks and bal- ancesthesedisciplines provideresult in a significantly higher probability of producing a productthatsatisfies customer expectations and that is completed closer to schedule and cost goals. The key is to tailor the prod- uct assurancedisciplines to the projectin size, form, and content.
Ref: Siegel, S., “Why We Need Checks and Balances to Assure Quality,” Quality Time
————
Column, IEEE Software, 9, 1 January 1992), pp. 102-103.

m

PRINCIDLE 174
ESTABLISH SCM PROCEDURES EARLY
Effective software configuration management (SCM)is not just having a
tool that records who madewhat changeto the code or documentation and
when.It is also the thoughtful creation of naming conventions,policies,
and procedures to ensurethatall relevant parties are involved in changes
to the software.It mustbetailored to each project. Its presence meansthat:
= We know how to report a software problem.
= Weknow howtorequest a new requirement.
= All stakeholders are informed of suggested changesand their opinions
are solicited.
= Aboard prioritizes and schedules change requests.
= All baselined intermediate orfinal products are undercontrol(that is,it
is impossible for them to be changed without following appropriate procedures).
The best place to recordall of this is in a document,typically called
thesoftware configuration management plan (SCMP). This document should
be written early in a project, typically getting approved around the same
time the software requirements specification is approved.
Ref: Bersoff, E., V. Henderson, and S. Siegel, Software Configuration Management,
SEE

EnglewoodCliffs, N.J.: Prentice Hall, 1980, Section 5.4.
WS

PRINCIPLE 175
ADAPT SCM TO SOFTWARE PROCESS
Software configuration management (SCM)is not a set of standard prac- tices that apply uniformlyto all projects. SCM mustbetailored to each pro- ject’s characteristics: size of the project, volatility, developmentprocess, extent of customer involvement, and so on. Onesize doesnotfit all. For example, the U.S. Federal Aviation Administration’s (FAA) National Airspace System (NAS) hasa seven-level configuration control board; obviously that would be inappropriate for a small project. A throw- away prototype developmentcould probably survive without a software requirements specification under configuration control; obviously a full- scale developmentproject could not.
Ref: Bersoff, E., and A. Davis, “Impacts of Life Cycle Models on Software Configuration Management,” Communications of the ACM, 34, 8 (August 1991),
eee
pp. 104-117.
196

PRINCIDLE 176
ORGANIZE SCM TO BE INDEPENDENT OF PROJECT MANAGEMENT
Software configuration management (SCM)can do its job properly only if
it is independentof project management. Often, due to schedule pressure,
a project manager maybe tempted to bypass the very controls that enable a project to thrive in the long term. For example, in timesof such schedule
problems, the temptation mightbe to accept a new version of the software
as a baseline even though no record was kept of which change requests
were satisfied by it. If SCM reports to the project manager, there is little
they can do but acceptit. If they are independent, then SCM can enforce the
rulesthatare best for everybody involved.
Ref: Bersoff, E., “Elementsof Software Configuration Management,” IEEE Transactions

on Software Engineering, 10, 1 (January1984), pp. 79-87.
»

PRINCIPLE 177
ROTATE PEOPLE THROWGH PRODUCT ASSURANCE
In manyorganizations, people are movedinto product assurance organiza- tions (1) as a first assignmentor(2) after they have demonstrated poor per- formance at engineering software. Product assurance, however,requires the samelevel of engineering quality and discipline as designing and coding. As analternative, rotate the best engineering talent through the product
assurance organization. A good guideline might be that every excellent engineer spendssix monthsin product assuranceevery twoto three years. The expectation of all such engineers is that they will make significant
improvements to productassurance during their “visit.” Such a policy must clearly state that the job rotation is a reward for excellent performance.
Ref: Mendis, K., “Personnel Requirements to Make Software Quality Assurance Work,” in Handbook of Software Quality Assurance, C.G. Schulmeyer, and J. McManus, eds., New York: Van Nostrand Reinhold, 1987, pp. 104-118.

1

DRINCIDLE 178
IVE ALL INTERMEDIATE PRODUCTS A NAME AND VERSION
There is a multitude of intermediate products of software development:
requirements specifications, design specifications, code, test plans, managementplans, user’s manuals, and so on. Every such product should be
given a unique name,version/revision number, and dateofcreation. If any
of them contain parts that can evolverelatively independently (suchas, the
software components in the program or the individual test plans in the
overall test planning document), these parts should also be given unique
names,version/revision numbers, and dates. “Partslists” should enumerate all the parts that go with each version/revision of the intermediate product so that you know which versions and revisions of which parts comprise a specific version andrevision of eachintermediate product.
Furthermore,as a final product is released to a customer, it must be
assigned a unique version/revision number(of the product) and dated. A
release “parts list” then enumeratesall the intermediate products (along
with their respective version and release numbers) that comprise the
product. It is only with such naming that you can control the inevitable
changes to a product(Principles 16 and 185).
Ref: Bersoff, E., V. Henderson, and S. Siegel, Software Configuration Management,


EnglewoodCliffs, NJ.: Prentice Hall, 1980, Chapter 4.
V7

PRINCIPLE 179
CONTROL BASELINES
It is the responsibility of software configuration managementto hold the agreed-uponspecifications and regulate changestothem. Whilerepairingor enhancing a software component, a software engineer will occasionally discover somethingelse that can be changed, perhapsto fix a yet unreported bug or to add some quick new feature. This
kind of uncontrolled changeis intolerable. See related Principle 187. SCM should avoid incorporating such changesinto the new baseline. Thecorrect procedureis for the software engineer to make a change request. This CR
is then processed along with the others from development, marketing,testing, and the customersby a configuration control board, whichprioritizes
and schedules the change requests. Only then can the engineer be allowed
to make the change and only then can SCM accept the change.
Ref: Bersoff, E.,, V. Henderson, and S. Siegel, Software Configuration Management,

EnglewoodCliffs, N.J.: Prentice Hall, 1980, Section 4.1
20

PRINCIPLE 180
SAVE EVERYTHING
Paul Erlich has said, “The first rule of intelligenttinkeringis to saveall the
parts.” Software by its very nature is constantly being tinkered with. Since
tinkering causes many errors (Principle 195), it is highly likely that any
software change will need to be undone. The only way to do this is to
ensure that everything is saved before a changeis made.It is the software
configuration managementorganization’sjob to save all copies of everything before an approved changeis madeto a baseline.

ich, P., as reported by Render, H., private communication, Colorado Springs,

Col: 1993.

PRINCIPLE 181
HEED TRACK OF EVERY CHANGE
Every change has the potential to cause problems. Three common prob- lemsare:
1. The change did not fix the problem for whichit was intended.
2. The changefixed the problem but caused others.
3. Ata future date, the changeis noticed and nobody can figure out whyit was made(or by whom).
In all three cases the preventionis to track every change.
Tracking entails recording:
= Theoriginal requestfor change (this might be a customer's requestfor a
newfeature, a customer’s complaint about a malfunction, a developer’s detection of a problem,or a developer’s desire to add a new feature).
= The approval process used to approve the change (who, when, why,in whatrelease).
= The changestoall intermediate products (who, what, when).
= Appropriate cross-references among the change request, change approval, and changes themselves.
Such an audittrail enables you to easily back out, redo, and/or understand changes.
Ref: Bersoff, E., V. Henderson, and S. Siegel, Software Configuration Management,
_—
Englewood Cliffs, NJ.: Prentice Hall, 1980, Section 7.1

m

PRINCIPLE 182
DON'T BYPASS CHANGE CONTROL
Everybody wins when changes are controlled. (“Controlled” does not
mean “prevented.”) Customers whohavedirect access to developers often
bypass changecontrol by asking individual developers to make specific
changesfor them. This is disastrous. It keeps project managementin the dark. It causes coststo escalate. It renders the requirementsspecification inaccurate. How much worsecould it get?
Ref: Curtis, B., H. Krasner, and N. Iscoe, “A Field Study of the Software Design Process for Large Systems,” Communications of the ACM, 31, 11 (November1988),

pp. 1268-1287.
1B

PRINCIPLE 183
RANK AND SCHEDULE CHANGE REQUESTS
Onany productbeing used, changerequests will funnel into the developmentorganization from users, developers, and marketing personnel. These
change requests mayreflect desires for new features, reports of slow performance, or complaints about system errors. A committee should be
formed,typically called a configuration control board (CCB), to regularly
reviewall change requests. Their responsibility is to prioritize all of them
and schedule when(or at least determine in which forthcoming release) they will be accommodated.
Ref: Whitgift, D., Methods and Tools for Software Configuration Management, New York:


John Wiley & Sons, 1991, Chapter 9.
Mh

PRINCIPLE 184
USE VALIDATION AND VERIFICATION (0&0) OX
LARGE DEVELOPMENTS
Large software system developments need as manychecks and balances as possible to ensure a quality product. One proventechniqueis the use of an organization independentof the developmentteam to conductvalidation and verification (V&V). Validation is the process of examining each inter- mediate productof software developmentto ensurethat it conformsto the previous product. For example, validation ensures that software require- ments meet system requirements,that high-level software design satisfies all the software requirements (and noneother), that algorithmssatisfy the component's external specification, that code implements the algorithms, and so on. Verification is the process of examining each intermediate prod- uct of software developmentto ensurethatit satisfies the requirements. You can think of V&V as a solution to the children’s gameoftele- phone.In telephone, a groupof children form a chain and a specific oral message is whispered downtheline. At the end, thelast child tells what he/sheheard, andit is rarely the sameas theinitial message. Validation would cause each child to ask the previous child, “Did you say x?” Verification would cause eachchild toaskthefirst child, “Did you say x?” Ona project, V&V should be plannedearly. It can be documented in the quality assurance planorit can exist in a separate V&V plan. In either case, its procedures, players, actions, and results should be approved at roughly the sametimethe software requirementsspecification is approved.
Ref: Wallace, D., and R. Fujii, “Software Verification and Validation: An Overview,”

IEEESoftware, 6, 3 (May 1989), pp. 10-17.

ri)
 

9 EVOLUTION PRINCIPLES
Evolutionis the setof activities dealing with modifying the software prod- uct to:
1. Meet new functions.
2. Work moreeffectively.
3. Workcorrectly (whenerrorsin the original productare detected).

M0)

PRINCIPLE 185
SOFTWARE WILL CONTINUE TO CHANGE
Any large software system that is being used will undergo continual
change because the system’s use will suggest additional functionality. It
will changeuntil it becomes more cost-effective to rewrite it from scratch.
This is Manny Lehman’s “Law of Continuing Change.”
Ref: Lehman, M., “Programs, Cities, and Students—Limits to Growth?” Inaugural Lecture, Imperial Collegeof Science and Technology, London(May14, 1974); also see Belady, L., and M. Lehman, “A Modelof Large Program Development,” IBM


Systems Journal, 15, 3 (March 1976), pp. 225-252.
208

PRINCIDLE 186
SOFTWARE’S ENTROPY INCREASES
Anysoftware system that undergoes continuous changewill grow in com- plexity and will become more and more disorganized. Since all software systemsbeing used will change(Principle 185) and changecausesinstabil- ity, all useful software systemswill migrate toward lower reliability and maintainability. This is Manny Lehman’s “Law of Increasing Entropy.”
Ref: Lehman, M., “Programs, Cities, and Students—Limits to Growth?” Inaugural Lecture, Imperial CollegeofScience and Technology, London (May 14, 1974); also see Lehman, M., “Laws of Program Evolution—Rules and Tools for Programming Management,” InfoTech State of the Art Conference on Why Software Projects Fail (April 1978), paper #11.

ny

PRINCIPLE 187
IFAT AIN'T BROKE, DON'T FIR IT
Ofcourse, this advice is applicable to many aspectsoflife, but it is particularly applicable to software. By its very name, software is considered malleable, easily modified. Don’t befooledinto thinking thatit is either easy to
see or repair a “break”in software.
Suppose you are maintaining a system. You are examiningthe source
code of a component. You areeither trying to enhanceit or seeking the
causeofan error. While examiningit, you detect whatyoubelieveis another error. Do nottry to “repair”it. The probability is very high that you will
introduceanerror, notfix one (Principle 190). Instead,file a change request.
Hopefully, the configuration control and associated technical reviews will
determineif it is an error and whatpriority its repair should be given
(Principles 175, 177, 178, and 179).
Ref: Reagan, R., as reported by Bentley, J., More Programming Pearls, Reading, Mass.:
SS
Addison-Wesley, 1988, Section 6.3.
1

PRINCIPLE 188
FHA PROBLEMS, NOT SYMDTOMS
Whensoftwarefails, you have an obligation to fully understand the cause ofthe failure, not just to do a cursory analysis and applyaquickfix to what youthink is the cause.
Suppose youare trying to trace the cause of a softwarefailure. You have noticed that every time a specific component transmits a value,it is exactly twice the desired value. A quick anddirty solution is to divide the generated value by twojustbeforeit is transmitted. This solutionis inap- propriate because(1) it may not workfor allcases, and(2) it leaves the pro- gram with whatis essentially two errors that compensate for each other, rendering the program virtually unmaintainable in the future (Principle 92). An even worse quick and dirty solutionis for the recipientto divide the value it receives by twobefore usingit. This solutionhasallthese prob- lemsassociated withthefirst one, plus it causesall future componentsthat invokethe faulty componentto receive the wrong value. Thecorrect solu- tion is to examine the program and determine whythevalueis consistent- ly doubled;then fix it.
ee
Ref: McConnell, S., Code Complete, Redmond, Wash.: Microsoft Press, 1993, Pp. 638.

Nl

PRINCIPLE 189
CHANGE REQUIREMENTS FIRST
If all parties agree that an enhancementis to be madeto the software, the
first thing to dois to update the software requirements specification and
get it approved. Only after this is doneis there a high probability that customers, marketing personnel, and developerswill really agree to what the
change is. Sometimestimerestrictions makeit impossible to do this (and
this should notbeall the time, or managementneedsto read the managementprinciples in this book!). In that case, initiate changes to the SRS
before starting changesto the design and code, and approvethe changes to
the SRS beforefinishing changesto the design and code.

Ref: Arthur, J., Software Evolution, NewYork: John Wiley & Sons, 1988, Chapter6.
——————— —
—
n

PRINCIPLE 190
PRERELEASE ERRORS YIELD POSTRELEASE ERRORS
Components with highrates of prerelease errors will also have high rates of postreleaseerrors. This is disappointing newsfor developers, but fully supported by empirical data (and by Principle 114, which impliesthat, the moreerrors youfind in a component, the more you will still find). The best adviceis to discard, replace, and recreate from scratch any componentwith a poorhistory. Don’t throw good moneyafter bad.
See
Ref: Dunn,R., Software Defect Removal, New York: McGraw-Hill, 1984, Section 10.2.
B
PRINCIPLE

191
THE OLDER A PROGRAM, THE MORE DIFFICULT IT 1S 10 MAINTAIN
As a changeis madeto a software system (whether for repair or enhancement), a certain number of componentsofthat system must be altered. As a
program getsolder, the percentageoftotal system components that must be
altered for each change grows. Every change makesall subsequent changes
moredifficult because the program’s structure necessarily deteriorates.
Ref: Belady, L., and B. Leavenworth, “Program Modifiability,” in Software Engineering,
Freeman, H., and P. Lewis, eds., New York: Academic Press, 1980, pp. 26-27.
 

PRINCIDLE 192
LANGUAGE AFFECTS MAINTAINABILITY
The programming language used for developmentsignificantly affects productivity during maintenance. Certain languages, such as APL,Basic, andLISP, facilitate the rapid developmentoffunctions, but they are inher- ently difficult to maintain. Other languages, such as AdaorPascal, offer challenges in development but are inherently easier to maintain. Languagesthattend to force high cohesion and low coupling (Principle 73), such as Eiffel, usually facilitate both development and subsequent maintenance. Languagesat very low levels, like assembler, usually inhibit productivity during both development and maintenance. Contrast this withPrinciple 99.
Ref: Boehm,B., Software Engineering Economics, Englewood Cliffs, N.J.: Prentice Hall,
See
1981, Section 30.4.
1h

PRINCIPLE 193
SOMETIMES IT 1S BETTER TO START QUE
There is so much talk these days about reengineering, renovation, and
reverse engineering that we mayall start believingit is easy to do. It is hard
to do. Sometimes it makes muchsense;it is worth the investment. Other
times it is a waste of scarce resources, and it would be betterto just design
and code from scratch. Ask yourselves, for example, will the maintainers
really use design documentation if you produceit?
Ref: Agresti, W., “Low-Tech Tips for High Quality Software,” Quality Time Column,

IEEESoftware, 9, 6 (November 1991), pp. 86, 87-89.
——————————————————————
a

DRINCIDLE 194
RENOUATE THE WORST FIRST
Principle 193 suggeststhat starting over may sometimesbethebestidea. Anotherless painful approach is to completely redesign and recode the worst components. Here “worst” means those that consume the most cor- rective maintenance dollars. Gerald Weinberg reports that on one system rewriting one 800-line module (that consumed30 percentofall corrective maintenance costs) saved considerable resources on the entire mainte- nanceeffort.
Ref: Weinberg, G., “Software Maintenance,” Datalink (May 14, 1979), as reported by Arthur, J., Software Evolution, New York: John Wiley & Sons, 1988, Chapter 12.
 

PRINCIPLE 195
MAINTENANCE CAUSES MORE ERRORS THAN DEVELOPMENT
Fixes to a program during maintenance (whether enhancement or defect
correction) introduce far more errors than initial development. Maintenance organizations report that between 20 and 50 percent ofall changes
made during maintenance introduce moreerrors.
It is for this reason that conformity to “the rules” is so important:
Establish an SCM plan(Principle 174), control baselines (Principle 179),
and don’t bypass changecontrol (Principle 182).
Ref: Humphrey, W,, “Quality From Both Developer and User Viewpoints,” Quality

Time Column, IEEE Software, 6, 5 (September 1989), pp- 84, 100.
OO
______
18

PRINCIPLE 196
REGRESSION TEST AFTER EVERY CHANGE
Regression testing is the testing of all previously tested features after a
change is made. Most people bypassregression testing because they think their changeis innocent.
You have just made a change to a moduleeither to repair an error (corrective maintenance), to add a new feature (adaptive maintenance), or to increase its performance (perfective maintenance). You musttest that what you did worked correctly. That is, you have to try out that which worked improperlybefore, see if the new feature works, or verify that per- formance is improved.If the test passes, are you done? Absolutely not! Software unfortunately does strange things. You mustalso do regression testing to verify that everything that workedcorrectly beforestill works.
Ref: McConnell, S., Code Complete, Redmond, Wash.: Microsoft Press, 1993, Section 25.6.
ee
eee
iy

PRINCIPLE 197
BELIEF THAT A CHANGE 1S EASY MARES IT LINELY IT WILL BE
MADE INCORRECTLY
This is Gerald Weinberg’s “Self-Invalidating Model”principle andrelates
strongly to the more generic situation describedin Principle 171. Since software is complex andits correct behavior depends upon “perfection,” the
implications of every changeto it mustbe considered seriously. As soon as
developers think a changeis simple, easy,orself-evident, their guard is
down,quality instilling approachesare disregarded, and in mostcases the
changeis madeincorrectly. This is manifesteither as an incorrect change or
as an unintendedside-effect.
To prevent this situation, be sure the change you are doing is
approved(Principles 182 and 183), desk-check every change (Principle 97),
andregressiontest after every set of changes (Principle 196).
Ref: Weinberg, G., Quality Software Management, Vol. 1: Systems Thinking, New York:

———
Dorset House, 1992, Section 15.2.3.
n

PRINCIPLE 198
STRUCTURING UNSTRUCTURED CODE DOES NOT NECESSARILY
IMPROVE IT
Let’s say you have to maintain a program that was written in an unstruc- tured manner. You could mechanically transform the codeinto an equiva- lent onethat is structured andthatstill performsthe samefunction. Such a
program is not necessarily better! Often such mechanical restructuring results in equally poor code. Instead, rethink the module and redesignit from scratch, using sound software engineering principles.
Ref: Arthur, J., Software Evolution, New York: John Wiley & Sons, 1988, Sections 7.2 and
ee
91

a

PRINCIPLE 199
USE DROFILER BEFORE OPTIMIZING
Whenit is time to optimize a program to makeit faster, rememberthat 80
percent of the CPU cycles will be consumed by 20 percent of the code
(Pareto). Therefore,first find the 20 percentof the code whose optimization
willyield results. The best wayto dothis is to use any commercially available profiler. A profiler monitors your program whileit is executing and
identifies the “hot spots,” that is, sections that consume the most CPU
cycles. Optimize these.
Ref: Morton, M., as reported by Bentley, J., More Programming Pearls, Reading, Mass.: Addison-Wesley, 1988, Section 6.4.
 

PRINCIPLE 200
CONSERVE FAMILIARITY
This is Manny Lehman’s “Law of Conservation of Familiarity.” As a soft- ware product is maintained, incremental releases are made. Each new release contains some amountof growth (that is, divergence from the familiar behavior of earlier releases). Releases that display larger-than- average new growth will tend to have “poorperformance,poorreliability, high fault rates, and cost and time overruns.” Furthermore,the greater the growth from the average, the highertherisk. The reason for this phenom- enon appearsto be the stabilization effect of releasing software to users. Since software changetends to causeinstability (Principles 184 and 190), a
large numberof changes betweenreleasescan cause a degreeofinstability that cannot be compensated for by a release. In addition, the amount of psychological familiarity that developersfeel for a product decreases dur- ing the time between releases; that is, the longer the software is modified, the strangerit “feels” to the developers. Upon product release, a major relearning process occurs and developers once again feel comfortable.If too many changes are made betweenreleases, too many changes get made to “unfamiliar” code and quality suffers.
Bottom line: Be relatively consistent with the amount of changes made between productreleases.
Ref: Lehman, M., “On Understanding Laws, Evolution, and Conservation in the Large-Program Life Cycle,” Journal of Systems and Software, 1, 3 (September 1980), pp. 213-221.
—————————————————__.._
B
PRINCIPLE

201
THE SYSTEM'S EXISTENCE PROMOTES EVOLUTION
Let’s assume for a momentthat we could do a “perfect”job of requirements
specification upfront. Let’s further assume for a momentthat requirements
didn’t change during development, so that when the system is createdit
actuallysatisfies the needsthatexist. Even if these assumptions werevalid,
evolution wouldstill go on becausetheinsertion of the system in its problem environmentchangesthat environmentandthus causes new problems.
Whatthis meansis that, no matter how good a handle you think you
have onthe requirements, you mustplan for the changesthatwill be necessary after deployment.
Ref: Lehman, M., “Software Engineering, the Software Process, and Their Support,”

Software Engineering Journal, 6, 5 (September 1991), pp. 243-258.
——————————————
eee
am

REFERENCES INDER
Abdel-Hamid,T,, and S. Madnick, “Impact on Schedule Estimation on SoftwareProject
Behavior,” IEEE Software, 3, 4 (July 1986), pp. 70-75. (Principle 156)
Agresti, W., “Low-Tech Tips for High Quality Software,” Quality Time Column,IEEE
Software, 9, 6 (November1991), pp. 86, 87-89. (Principle 193)
Akao, Y. Quality Function Deployment, Cambridge, Mass.: Productivity Press, 1990.
(Principle 112)
Alexander, L., and A. Davis, “Criteria for theSelection of a Software Process Model,”
IEEE COMPSAC ‘91, Washington, D.C.: IEEE ComputerSociety Press, pp. 521-
528. (Principle 163)
Andriole, S., “Storyboard Prototyping for Requirements Verification,” Large Scale
Systems, 12 (1987), pp. 231-247. (Principle 42)
Andriole, S., Rapid Application Prototyping, Wellesley, Mass.: QED, 1992. (Principle 13)
Arthur, J., Software Evolution, NewYork: John Wiley & Sons, 1988, Chapter 6; Sections
7.2, 9.1. (Principles 189, 198)
Basili, V., and J. Musa, “The Future Engineering of Software: A Management
Perspective,” IEEE Computer, 24, 9 (September1991), pp. 90-96. (Principle 36)
Belady, L,, and B. Leavenworth, “Program Modifiability,” in Software Engineering, Freeman,
H., and P. Lewis, eds., New York: Academic Press, 1980, pp. 26-27. (Principle 191)
Belady, L., and M. Lehman, “A Modelof Large Program Development,” IBM Systems
Journal, 15, 3 (March 1976), pp. 225-252. (Principle 185)
Bennis, W., The Unconscious Conspiracy: Why Leaders Can't Lead, New York: AMACOM,

1976. (Principle 135)
DB
Bersoff,

E., “Elements of Software Configuration Management,” [EEE Transactions on Software Engineering, 10, 1 January 1984), pp. 79-87. (Principle 176)
Bersoff, E., and A. Davis, “Impacts of Life Cycle Models on Software Configuration Management,” Communications of the ACM, 34, 8 (August 1991), pp. 104-117. (Principle 175) Bersoff, E., V. Henderson,andS. Siegel, Software Configuration Management, Englewood Cliffs, N.J.: Prentice Hall, 1980, Chapter 4, Sections2.2, 4.1, 5.4, 7.1. (Principles 16, 174, 178, 179, 181) Berzins, V,, and Lugi, Software Engineering with Abstractions, Reading, Mass.: Addison- Wesley, 1991, Section 1.5. (Principle 106) Boehm, B., “The High Cost of Software,” in Practical Strategies for Developing Large Software Systems, E. Horowitz, ed., Reading, Mass.: Addison-Wesley, 1975. (Principle 168)
Boehm,B., “Software Engineering,” [EEE Transactions on Computers, 25, 12 (December 1976), pp. 1226-1241. (Principle 41)
Boehm,B., Software Engineering Economics, EnglewoodCliffs, N.J.: Prentice Hall, 1981, Sections 26.5, 27.3, 29.9, 30.4, 32.7, 33.4. (Principles 104, 131, 146, 148, 150, 152, 192) Boehm, B., “Seven Basic Principles of Software Engineering,” Journal of Systems and Software, 3, 1 (March 1983), pp. 3-24. (Preface) Boehm, B., “Verifying and Validating Software Requirements and Design Specifica- tions,” IEEE Software, 1, 1 (January 1984), pp. 75-88. (Principles 40, 45)
Boehm,B., “Software Risk Management:Principles and Practices,” IEEE Software, 9,1 (anuary 1991), pp. 32-39. (Principle 161)
Brooks, F, The Mythical Man-Month, Reading, Mass.: Addison-Wesley, 1975, Chapters2, 4.(Principles 10, 140, 160)
Brooks, F., “NoSilver Bullet: Essence and Accidents of Software Engineering,” IEEE Computer, 20, 4 (April 1987), pp. 10-19. (Principles 17, 72, 82) Charette, R., Software Engineering Risk Analysis and Management, New York: McGraw- Hill, 1989, Section 2.2, Chapter6. (Principles 162) Cherry, G., Software Construction by Object-Oriented Pictures, Canadaigua, New York: ThoughtTools, 1990, p. 39. (Principle 61) Chikofsky, E., “Changing Your EndgameStrategy,” IEEE Software, 7, 6 (November

1990), pp. 87, 112. (Principle 172)
26

Constantine, L., and E. Yourdon, Structured Design, Englewood Cliffs, N.J.: Prentice
Hall, 1979. (Principle 73)
Curtis, B., H. Krasner, and N. Iscoe, “A Field Study of the Software Design Process for Large Systems,” Communications of the ACM,31, 11 (November1988), pp. 1268-
1287. (Principles 15, 83, 136, 182)
Davis A., “A Comparison of Techniques for the Specification of External System
Behavior,” Communications of the ACM, 31, 9 (September 1988), pp. 1098-1115.
(Principle 47) Davis, A., “Operational Prototyping: A New Development Approach,” IEEE Software, 9,
5 (September1992), pp. 70-78. (Principles 11, 12)
Davis, A., Software Requirements: Objects, Functions and States, Englewood Cliffs, NJ:
Prentice Hall, 1993, Sections 3.1, 3.4.2, .6, 3.4.11, 5.3.2. (Principles 46, 49, 50, 53,
56, 58)
Davis, A., “Software Lemmingineering,” IEEE Software, 10, 6 (September 1993), pp. 79-81,
84. (Principles 30, 149)
Davis, A., and E. Comer, “NoCrystal Ball in the Software Industry,” IEEE Software, 10,
4 (July 1993), pp. 91-94, 97. (Principles 169, 170)
DeMarco,T., “Why Does Software Cost So Much?” IEEE Software, 10, 2 (March 1993), pp. 89-90. (Principles 147, 157)
DeMarco,T., and T.Lister, Peopleware, New York: Dorset House, 1987, Chapters 6, 12.
(Principles 139, 165)
Dijkstra, E., “Notes on Structured Programming,” in Structured Programming, Dahl, O.,
et al., eds., New York: Academic Press, 1972. (Principle 111)
Dunn,R., Software Defect Removal, New York: McGraw-Hill, 1984, Sections7.2,7.4, 10.2,
10.3. (Principles 115, 121, 123, 190)
Endres, A., “An Analysis of Errors and Their Causes in System Programs,” [EEE Transactions on Software Engineering, 1, 2 (June 1975), pp. 140-149. (Principle
114)
Erlich, P, as reported by Render, H., private communication, Colorado Springs, Col.:
1993. (Principle 180)
Fagan, M., “Design and CodeInspections to Reduce Errors in Program Development,” IBM Systems Journal, 15, 3 July 1976), pp. 182-211. (Principle 98)

yy

Fairley, R., Software Engineering

Concepts, New York: McGraw-Hill, 1985. (Principle 69)
Fairley, R., “Recent Advances in Software Estimation Techniques,” 14th IEEE
International Conference on Software Engineering, Washington, D.C.: IEEE Computer
Society Press, 1992. (Principle 145)
Farbman,D., “Myths That Miss,” Datamation (November 1980), pp. 109-112. (Principle 8) Fenton, N., “HowEffective Are Software Engineering Methods?” Journal of Systems and
Software, 22, 2 (August 1993), pp. 141-146. (Principles 127, 129) Floyd, C., “A Systematic Look at Prototyping,” in Approaches to Prototyping, R. Budde, et al., Berlin, Germany: Springer Verlag, 1983, pp. 1-18, Section 3.1. (Principle 5)
Fleckenstein, W., “Challenges in Software Development,” IEEE Computer, 16, 3 (March 1983), pp. 60-64. (Principle 3) Francis, P., Principles of R&D Management, New York: AMACOM,1977, pp. 114-116. (Principle 133)
Gause, D., and G. Weinberg, Are Your Lights On? New York: Dorset House, 1990.
(Principle 39)
Gerhart, S., and L. Yelowitz, “Observations of Fallibility in Applications of Modern Programming Methodologies,” IEEE Transactions on Software Engineering, 2, 3
(September 1976), pp. 195-207, Section I. (Principle 126)
Gilb, T., “Deadline Pressure: How to Cope with Short Deadlines, Low Budgets and Insufficient Staffing Levels,” in Information Processing, HJ. Kugler, ed.,
Amsterdam:Elsevier Publishers, 1986. (Principle 130) Gilb, T., Principles of Software Engineering Management, Reading, Mass.: Addison-Wesley,
1988, Sections 7.14, 8.10, 9.11, 16.7.(Principles 43, 52, 154, 155) Glaser, G., “Managing Projects in the Computer Industry,” IEEE Computer, 17, 10
(October 1984), pp. 45-53. (Principle 158)
Glass,R., Building Quality Software, Englewood Cliffs, N.J.: Prentice Hall, 1992, Section
2.2.2.5. (Principle 62) Gomaa, H., and D. Scott, “Prototyping as a Tool in the Specification of User Requirements,”Fifth International ConferenceonSoftware Engineering, Washington, D.C.: IEEE ComputerSociety Press, 1981, pp. 333-342. (Principle 7)


8
Goodenough,J., and S. Gerhart, “Toward a Theory of Test Data Selection,” IEEE Transactions on Software Engineering, 1, 2 (June 1975), pp. 156-173, Section TIC.
(Principles 108, 113)
Grady, R., and T. VanSlack, “Key Lessons in Achieving Widespread Inspection Use,” IEEE Software, 11, 4 (July 1994), pp. 46-57.(Principle 98)
Hall, A., “Seven Mythsof Formal Methods,” IEEE Software, 7, 5 (September 1990), pp.
11-19. (Principle 28)
Herzberg, F., “One More Time: How Do You Motivate Employees?” Harvard Business
Review (September-October1987). (Principle 138)
Hoare, C.A.R., “Software Engineering: A Keynote Address,” IEEE 3rd International Conference on Software Engineering, 1978, pp. 1-4. (Principle 37)
Hoare, C.AR., “Programming: Sorcery or Science?” IEEE Software, 1,2 (April 1984), pp14-15. (Principle 18) Horowitz, E., and $. Sahni, Fundamentals of Computer Algorithms, Potomac, Md.: ComputerScience Press, 1978. (Principle 79)
Huang,J., “Program Instrumentation and SoftwareTesting,” IEEE Computer, 11, 4 (April 1978), pp. 25-32. (Principle 124)
Huff, C., “Elements of a Realistic CASE Tool Adoption Budget,” Communications of the
ACM,35, 4 (April 1992), pp. 45-54. (Principle25)
Humphrey, W.,, “Quality From Both Developer and User Viewpoints,” Quality Time Column,IEEESoftware, 6, 5 (September 1989), pp. 84, 100. (Principle 195)
IEEE ComputerSociety, Software Engineering Standards Collection, Washington, D.C.: IEEE ComputerSociety Press, 1993. (Principle 32)
TEEE, ANSI/IEEE Guide to Software Requirements Specifications, Standard 830-1994, Washington, D.C.: IEEE ComputerSociety Press, 1994. (Principle59)
Incorvaia,A. J., A. Davis, and R. Fairley, “Case Studies in Software Reuse,” Fourteenth IEEE International Conference on Computer Software and Applications, Washington,
D.C.: IEEE ComputerSociety Press, 1990, pp. 301-306.(Principle 84)
Jones, C., Programming Pioductivity, New York: McGraw-Hill, 1986, Chapter 1.
(Principles 144, 152)

Joyce, E., “Is Error-Free Software Achievable?” Datamation (February 15, 1989). (Principle 4)
nN

Kajihara, J., G. Amamiya, and T. Saya, “Learning from Bugs,” IEEE Software, 10, 5
(September 1993), pp. 46-54. (Principle 125)
Kemerer, C., “Howthe Learning CurveAffects Tool Adoption,” IEEE Software, 9,3 (May 1992), pp. 23-28. (Principles 22, 23)
Kernighan,B., and P. Plauger, The Elements of Programming Style, New York: McGrawHill, 1978, pp. 20-37, 52, 67, 124-134, 141-144. (Principles 89, 93-95)
Lederer, A., and J. Prasad, “Nine Management Guidelines for Better Cost Estimating,”
Communications of the ACM, 35, 2 (February 1992), pp. 51-59, Guideline 1.
(Principles 38, 153)
Ledgard, H., Programming Proverbs, Rochelle Park, N.J.; Hayden Book Company, 1975, Proverbs8, 21; pp. 94-98. (Principles 90, 91, 97)
Ledgard,H., Programming Practice, Vol. Il, Reading, Mass.: Addison-Wesley, 1987, Chap. 4. (Principle 88)
Lehman,M., “Programs,Cities, and Students—Limits to Growth?” InauguralLecture, Imperial College of Science and Technology, London (May 14, 1974). (Principles
185, 186)
Lehman, M., “Laws of Program Evolution—Rules and Tools for Programming Management,” InfoTech State of the Art Conference on Why Softwvare Projects Fail (April 1978), paper#11. (Principle 186)
Lehman, M., “On Understanding Laws, Evolution, and Conservation in the Large- Program Life Cycle,” Journal of Systems andSoftware, 1, 3 (July 1980), pp. 213-221. (Preface)
Lehman, M., “On Understanding Laws, Evolution, and Conservation in the Large- Program Life Cycle,” Journal of Systems and Software, 1, 3 (September 1980), pp.
213-221. (Principle 200)
Lehman, M., “Programming Productivity—A Life Cycle Concept,” COMPCON 81,
Washington, D.C.: IEEE ComputerSociety Press, 1981, Section 1.1. (Principle 3) Lehman, M., “Software Engineering, the Software Process and Their Support,” Software Engineering Journal, 6, 5 (September 1991), pp. 243-258, Section 3.6.
(Principles 20, 201)
Lehman, M., private communication, Colorado Springs, Col.: (January 24, 1994).
(Principle 110)
Lehman, M., private communication, Colorado Springs, Col.: (January 25, 1994).


(Principle 151)
Bo
Leveson.N., “Software

Safety: What, Why and How,” ACM Computing Surveys, 18, 2
(June 1986), pp. 125-163. (Principle 76)
Lindstrom, D., “Five Ways to Destroy a DevelopmentProject,” IEEE Software, 10, 5
(September1992), pp. 55-58. (Principle 107)
Loy, P, “The Method Won't Save You (But It Can Help),” ACM Soffzvare Engineering Notes, 18, 1 (January 1993), pp. 30-34.(Principle 164) Macro, A., Software Engineering: Concepts and Management, Englewood Cliffs, NJ.:
Prentice-Hall International, 1990, p. 247.(Principle 87)
Matsubara, T., “Bringing up Software Designers,” American Programmer, 3, 7 (July- August 1990), pp. 15-18. (Principle 21)
McCabe, T., “A Complexity Measure,” IEEE Transactions on Software Engineering, 2, 12 (December 1976), pp. 308-320. (Principle 120)
McConnell, S., Code Complete, Redmond, Wash.: Microsoft Press, 1993, Chapter 18; p.
638; Sections 3.5, 4.2-4.4, 5.6, 17.4, 17.6, 25.6, 32.3. (Principles 85, 92, 96, 99, 101, 102,
105, 188, 196)
McGregor, D., The HumanSide of Enterprise, New York: McGraw-Hill, 1960. (Principle 134)
Mendis, K., “Personnel Requirements to Make Software Quality Assurance Work,” in Handbookof Software Quality Assurance, C.G. Schulmeyer, and J. McManus,eds.,
NewYork: Van Nostrand Reinhold, 1987, pp. 104-118. (Principle 177)
Meyer, B., “On Formalismin Specifications,” IEEE Software, 2, 1 (January 1985), pp. 6-26.
(Principles 35, 54)
Miller, G., “The Magical NumberSeven, Plus or Minus Two,” The Psychological Review, 63,2 (March 1956), pp. 81-97. (Principle 67)
Mills, H., et al., “Cleanroom Software Engineering,” IEEE Software, 4, 5 (September
1987), pp 19-25. (Principle 109) Mills, H., “Top-Down Programmingin Large Systems,” in Debugging Techniques in Large
Systems, R. Ruskin, ed., EnglewoodCliffs, N.J.: Prentice Hall, 1971. (Principle 14)
Mizuno,Y., “Software Quality Improvement,” IEEE Computer, 16, 3 (March 1983), pp.
66-72. (Principle 29)
Morton, M., as reported by Bentley, J., More Programming Pearls, Reading, Mass.:
Addison-Wesley, 1988, Section 6.4. (Principle 199)
Musa,J., A. Iannino, and K. Okumoto, Software Reliability, New York: McGraw-Hill,
1987, Section 4.2.2. (Principle 86)


BI
Myers, G., The Art

of Software Testing, New York: John Wiley & Sons, 1979, pp. 12, 14,
113-114. (Principles 109, 116-118)
Parnas, D., “A Technique for Software Module Specification with Examples,” Communications of the ACM, 15, 5 (May 1972), pp. 330-336. (Principle 80)
Parnas, D., “On the Criteria to Be Used in Decomposing Systems into Modules,”
Communications of the ACM, 15, 12 (December 1972), pp. 1053-1058. (Principle 65)
Parnas, D., “Designing Software for Ease of Extension and Contraction,” IEEE Transactions on Software Engineering, 5, 2 (March 1979), pp. 128-138. (Principles 44,
77,78)
Pfleeger, S., “Lessons Learnedin Building a Corporate Metrics Program,”IEEESoftware, 10,3 (May 1993), pp. 67-74. (Principle 143)
Ramamoorthy, C. V., V. Garg, and A. Prakash, “Programming in the Large,” IEEE Transactions on Software Engineering, 12, 7 (uly 1986), pp. 769-783. (Principle 66)
Rauscher, T., private communication, 1977. (Principle 137) Reagan, R., as reported by Bentley, J., More Programming Pearls, Reading, Mass.: Addison-Wesley, 1988, Section 6.3. (Principle 187)
Reifer, D., “The Nature of Software Management: A Primer,” Tutorial: Software Management, D. Reifer, ed., Washington,D.C.: IEEE ComputerSocietyPress, 1986, pp. 42-45. (Principles 132, 159)
Romach, H. D., “Design Measurement: Some Lessons Learned,” IEEE Software, 7, 2
(March 1990), pp. 17-25. (Principle 75)
Royce, W., “Managing the Developmentof Large Software Systems,” WESCON ‘70,
1970; reprinted in 9thInternational Conference on Software Engineering, Washington, D.C.: IEEE ComputerSocietyPress, 1987, pp. 328-338. (Preface, Principles 10, 64)
Sackman,H., et al., “Exploratory Experimental Studies Comparing Online and Offline Programming Performance,” Communicationsof the ACM, 11, 1 January 1968), pp.
3-11. (Principle 141)
Siddigi, J., “Challenging Universal Truths of Requirements Engineering,” IEEE Software, 11, 2 (March 1994), pp. 18-19.(Principle 69)
Siegel, S., “Why We Need Checks and Balances to Assure Quality,” Quality Time
Column,IEEESoftware, 9, 1 (January 1992), pp. 102-103. (Principle 173) Sommerville, L., Software Engineering, Reading, Mass.: Addison-Wesley, 1992, Sections
20.0, 20.1. (Principles 6, 57)
B

Stark, G., R. Durst, and C. Vowell, “Using Metrics in ManagementDecision-Making,”
IEEE Computer, 27, 9 (September 1994). (Principle 149)
Turski, W., oral comments madeat a conferencein the late 1970s. (Principle 19)
US. Air Force, Cost/Schedule Management of Non-Major Contracts, Air Force Systems
CommandPublication #178-3, Andrews AFB, Md.: (November 1978). (Principle
166)
Wallace, D., and R. Fujii, “Software Verification and Validation: An Overview,” IEEE Software, 6, 3 (May 1989), pp. 10-17. (Principle 184) Weinberg, G., The Psychology of Computer Programming, New York: Van Nostrand
Reinhold, 1971, Chapters 6-7. (Principle 131)
Weinberg, G., “Software Maintenance,” Datalink (May 14, 1979), as reported by
Arthur,J., Software Evolution, New York: John Wiley & Sons, 1988, Chapter 12.
(Principle 194)
Weinberg, G., Rethinking Systems Analysis and Design, New York: Dorset House, 1988, PartV. (Principle 63)
Weinberg, G., Quality Software Management, Vol. 1: Systems Thinking, New York:
Dorset House, 1992, Sections 1.2, 12.1.2, 13.2.3, 15.2.3, 15.3.5. (Principles 2, 112,
119, 171, 197)
Weinberg,G., and E. Schulman, “Goals and Performancein Computer Programming,”
HumanFactors, 16 (1974), pp. 70-77. (Principle 142)
Weiser, M., J. Gannon, and P. McMullin, “Comparison of Structural Test Coverage Metrics,” IEEE Software, 2, 2 (March 1985), pp. 80-85. (Principle 122)
Whitgift, D., Methods and Tools for Software Configuration Management, New York: John
Wiley & Sons, 1991, Chapter9. (Principle 183)
Witt, B., F. Baker, and E. Merritt, Softevare Architecture and Design, New York: Van Nostrand
Reinhold, 1994, Sections 1.1, 1.3,2.5, 2.6, 6.4.2.6.(Principles 70, 71, 74, 76, 81)
Yeh, R., P. Zave, A. Conn,and G. Cole, Jr., “Software Requirements: NewDirections and Perspectives,” in Handbookof Software Engineering, C. Vick and C. Ramamoorthy,
eds., New York: Van Nostrand Reinhold, 1984, pp. 519-543. (Principle 48)
Yourdon, E., How to Manage Structured Programming, NewYork: Yourdon,Inc., 1976,
Sections5.2.2, 5.2.5. (Principles 100, 103)
Yourdon, E., Decline andFallof the American Programmer, EnglewoodCliffs, N.J.: Prentice
Hall, 1992 (Chapter8). (Principle 1)


B

ave, P., “An Insider’s Evaluation of PAISLey,” IEEE Transactions on Software
Engineering, 17, 3 (March 1991), pp. 212-225. (Principle 45)
rouni, C., as reported by Bentley, J., More Programming Pearls, Reading, Mass.:
Addison-Wesley, 1988, Section 6.1. (Principle 68)
 
SUBJECT INDER
Algorithms, 92, 108 Ambiguity, in requirements, 63, 64 Assumptions, 27 Availability, 68, 99
Bell Labs, 10 Big bang, 136 Black-box testing, 132 Brooks’ law, 159
Carry the water, 156
CASE,30-32
costs, 32,
fad, 37 indexing, 41 productivitygains, 30-31
realism, 30 Change:
continuous, 208 designing for, 87 managing, 22, 23, 202-204
Coding, 101-121 comments,110-111
defined, 101 inspections, 113
Coding (Cont.): languageselection, 117-119 naming conventions, 106 nesting, 116 programminglanguage,114 structured programming, 114-116
tricks, 102 understandability, 104
whentostart, 121 Cohesion, 86
Comments, 110-111
Communication
with customers, 15 employees, 155
with users, 15 Conceptual integrity, 84 Conciseness, in requirements, 61
Configuration management, 22,23, 48, 195-204
baselines, 200 changecontrol, 202-204
configuration identification, 199 controlling baselines, 200 customizing, 196
defined, 193 during development, 23

independentof project management, 197
Configuration management(Cont.): naming,199
versions, 199
whentostart, 195 Consistency: naming concepts, 42
Cost estimation:
accuracy, 173
reassessing, 174 roleof requirements, 48 tailoring, 165 underestimating, 175
unrealistic deadlines, 166, 167 Coupling, 86 Cross-referencing:
requirements to design, 75
requirements to source, 53 requirementsto tests, 124
Customers, 14-16, 149
Datastructureselection, 108 Design, 73-99 algorithms, 92 avoiding in requirements,56 change, 87
conceptual integrity, 84, 85 coupling and cohesion, 86
defined, 73
documentation,role of, 77
efficiency, 92
encapsulation, 78
errors, 85, 89 evaluatingalternatives, 76 flexibility, 91 generality, 90
intellectual control, 83
intellectual distance, 82
maintenance, 88 multiple views, 94

Design (Cont.): reinventing the wheel, 79 simplicity, 80-83 special cases, 81 tracing to requirements, 75 transitioning from requirements, 74 Designers, 95
Documentation standards (see Standards,
documentation)
Efficiency, 92 vs. reliability, 13 Encapsulation, 78 Entropy, 209 Environment, 68 Errors: analyzing, 141
causes, 142 conceptual vs. syntactic, 85 designing for, 89 distribution, 131, 213 during maintenance, 218, 220 egoless, 143 finding, 128-130 fixing, 211
Evolution, 207-224 defined, 207
existence causes evolution, 224 Excellence, expecting, 154
Fads, 37, 148 Familiarity, 223 Flexibility, 91 Formal methods, 35 Formatting programs, 120
Garbage in, garbage out, 98 Generality, 90 Global variables, 103

Glossaries, 40
Hardware: evolution, 188 overstraining, 187
Incompleteness, in requirements, 69 Incremental development, 21 Index, 41 Inspections: code, 113 requirements, 55 Instrumenting software, 141 Integration testing, 137, 140 Intellectual control, 83 Intellectual distance, 82
Japan vs. US.software industry, 36
Know-whenvs. know-how, 33
Languages: defined, xiii, 3
fordifferent phases, 28 for maintenance, 215 productivity, 171 selecting, 117-119 Lemmings, 37 Linesof code, 163, 171
Maintenance: and ageof program,214 designing for, 88 errorcreation, 218, 220 languages, 215 regression testing, 219 Make/buy decision, 24
Management, 145-191 allocating resources, 176 carry the water, 156
communicationskills, 155 defined, 145 expecting excellence, 154 importance, 146
listening skills, 152 motivating employees, 157 optimizinga project, 161
process modelselection, 182 project planning, 177-182 project postmortem, 191 style, 146
trust, 153 by variance, 186 vs, technology, 146
(see also Cost estimation, Personnel, Risk management, and Schedule) McCabe complexity measure, 137
Measurement, 168
collecting data, 162, 169
fad, 37
lines of code, 163 McCabe complexity, 137
productivity, 163, 164, 169-171 test completion, 138 test complexity, 137 Methods(see Techniques) Module specifications(see Specifications, module)
Motivationskills, 157
Multiple views: design, 76, 94 requirements, 58 Mythical person-month,159
Naming conventions, 106

NASA, 11
Natural Nesting
Notations
languages, code,
(see
116
Languages)
64

Object-orientation, fad, 37
Office noise, 158
Optimization: of a program, 222 of a project, 161
Personnel:
communication skills, 155
expecting excellence, 154
listening to, 152 and motivation, 157 and productassurance, 198 andproject success, 150 quality, 151, 160
rotating assignments, 198
trust, 153
vs. time, 159 Phases, languagesfor, 28 Planning projects, 177-182
Political dilemma, 9
Postmortems, 191
Pretty-printing (sce Formatting programs) Principle:
defined, xiii, 3
software engineering vs. otherdisciplines,
xiv, 3
Prioritizing requirements,16, 60, 149
Problemsvs. solutions, 26
Process maturity, fad, 37
Process models, 182
Productassurance, 193-205
defined, 193 not luxury, 194
Productivity, 10
collecting data, 162, 169 increasing, 184 and languageselection, 117-119
measuring, 163, 164, 169-171
team, 170 vs. quality, 10
Profilers, 222
Programming languages(see Languages
Progress tracking, 185, 186 Project planning, 177-182 Project postmortems,191 Prototyping, 11-12, 14, 17-20, 48, 50
fad, 37
features, 19
techniques, 20 throwawayvs. evolutionary, 18, 19
user interfaces, 63
Quality, 8-13
cost of, 11 retrofitting, 12 vs. productivity, 10
Quality assurance, defined, 193
Reengineering (see Renovation) Regression testing, 219
Reinventing the wheel, 79 Reliability: redundancy, 99 specifying, 67 vs.efficiency, 13
Renovation, 217, 221
Reputations, 36 Requirements engineering, 47-70 ambiguity, 63, 64
availability, 68


BE

Requirements engineering (Cont.): avoiding design, 56 changing,212
conciseness, 61
cost estimation, 48
database, 70
defined, 47 environment, 68
errors, 51 incompleteness, 69 inspecting, 55 multiple views, 58 natural language, role of, 64-66 numbering, 62 organizing, 59
prioritization, 16, 60, 149
problem vs. solution, 49
reliability, 67 requirementscreep, 22, 224 techniques, 57
tracing to design, 75
tracing to source, 53
tracingto tests, 124
understandability, 64-66 vs. design, 56, 74 Responsibility, taking, 44
Reuse, 97 Reviews, see Inspections Risk management: knowingtop 10 risks, 180
role of requirements, 48
understanding risks, 181, 190
user interfaces, 52
Scaffolding software, 140
Schedule: believing, 172
progresstracking, 185, 186 reassessing, 174
Schedule (Cont.): underestimating, 175
unrealistic deadlines, 166, 167 vs. staffing, 159
Sideeffects, 105 Simplicity, 80, 81
Software configuration management(see Configuration management)
Softwareengineering, defined, xiii
Software engineers:
communication skills, 155 expecting excellence, 154 listeningto, 152
and motivation, 157 and project success, 150
quality, 151, 160
trust, 153
vs. time, 159 Software quality assurance (see Quality assurance)
Softwareverification and validation (see
Verification and validation)
Specifications, module, 93
Standards, documentation, 39-41, 70 Standing waves, 179 Stress testing, 135 Structured programming,114-116, 221
Subsets, 54
Techniques: before tools, 29 blindly following, 34 defined, 3
effectiveness, 183 right, 57 Technology: hardware capability, 187, 188 software, 37-38, 189

vs. management,146
Technologytransfer, 43
Test cases, 133, 134 Testing, 123-143 big bang, 136
black-box, 132
completion measures, 138
complexity measures, 137 coverage, 139
defined, 123 expectedresults, 133 integration testing, 137, 140
planning, 125, 127 purpose,128-130 regression, 219
stress, 135
test cases, 133, 134 tracing to requirements, 124
unit testing, 137, 140
white-box, 132
Test planning, 125, 127
“To be determined,” 69
Tools:
defined, 4

Tools (Cont.): and techniques, 29 (see also CASE) Tracing(see Cross-referencing) Trade-off analysis:
between changes, 202, 203
between design alternatives, 76 between making and buying, 24
Tricks, role of, 102

Understandability:
of code, 104, 106, 107 ofrequirements, 64-66
Unit testing, 137, 140 US.vs. Japan software industry, 36
User interfaces, 25, 52
Users, 14-16
Users’ manuals, 25
Verification and validation, 205
defined, 193
White-boxtesting, 132

MO

